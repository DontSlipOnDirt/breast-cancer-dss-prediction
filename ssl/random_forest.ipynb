{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Import"
      ],
      "metadata": {
        "id": "Lb1gsFNTbxac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lifelines\n",
        "!pip install scikit-learn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.regularizers import l1_l2\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "from google.colab import drive\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdexOscBbwsY",
        "outputId": "73b4394a-3d06-4b77-86dc-7cbc7b10bfc2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lifelines in /usr/local/lib/python3.10/dist-packages (0.30.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from lifelines) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from lifelines) (1.13.1)\n",
            "Requirement already satisfied: pandas>=2.1 in /usr/local/lib/python3.10/dist-packages (from lifelines) (2.2.2)\n",
            "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.10/dist-packages (from lifelines) (3.8.0)\n",
            "Requirement already satisfied: autograd>=1.5 in /usr/local/lib/python3.10/dist-packages (from lifelines) (1.7.0)\n",
            "Requirement already satisfied: autograd-gamma>=0.3 in /usr/local/lib/python3.10/dist-packages (from lifelines) (0.5.0)\n",
            "Requirement already satisfied: formulaic>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from lifelines) (1.0.2)\n",
            "Requirement already satisfied: interface-meta>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=0.2.2->lifelines) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=0.2.2->lifelines) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=0.2.2->lifelines) (1.17.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (4.55.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.1->lifelines) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.1->lifelines) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0->lifelines) (1.17.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read Data"
      ],
      "metadata": {
        "id": "zqwswCTQ8JwT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74YfKoxEuo9R",
        "outputId": "edb0e910-54a6-4562-caa5-df469142689a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# connect to goodle drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/Colab Notebooks') # to import our custom module from this path later\n",
        "\n",
        "read_path = '/content/drive/My Drive/AIIM/Final/' # modify this line according to your path"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "TRAIN_DATA_PATH = read_path + 'train_data.csv'\n",
        "UNLABELED_DATA_PATH = read_path + 'unlabelled_data.csv'\n",
        "\n",
        "train_data = pd.read_csv(TRAIN_DATA_PATH)\n",
        "unlabeled_data = pd.read_csv(UNLABELED_DATA_PATH)\n",
        "\n",
        "train_data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkJlhzOBzszH",
        "outputId": "1ae410d3-8cff-4ac4-e733-ed3cb45590d1"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['ESR1', 'PGR', 'ERBB2', 'MKI67', 'PLAU', 'ELAVL1', 'EGFR', 'BTRC',\n",
              "       'FBXO6', 'SHMT2', 'KRAS', 'SRPK2', 'YWHAQ', 'PDHA1', 'EWSR1', 'ZDHHC17',\n",
              "       'ENO1', 'DBN1', 'PLK1', 'GSK3B', 'Age', 'Menopausal State', 'Size',\n",
              "       'Radio Therapy', 'Chemotherapy', 'Hormone Therapy',\n",
              "       'Neoplasm Histologic Grade', 'Cellularity', 'Surgery-breast conserving',\n",
              "       'Surgery-mastectomy', 'Label', 'DssTime', 'Event'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Preprocessing\n",
        "\n",
        "x_train = train_data.drop(columns=['Label', 'DssTime', 'Event'])\n",
        "y_train = train_data['Label']\n",
        "\n",
        "x_ul = unlabeled_data\n",
        "\n",
        "x_train.insert(0, 'ID', range(1, len(x_train) + 1))\n",
        "x_ul.insert(0, 'ID', range(len(x_train) + 1, len(x_train) + len(x_ul) + 1))"
      ],
      "metadata": {
        "id": "kQ4d8Qp-DSVj"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_ul"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "YzqDotl1beuW",
        "outputId": "52850f6e-20d2-43e9-8b35-e36ecf91626c"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        ID       ESR1       PGR      ERBB2     MKI67       PLAU    ELAVL1  \\\n",
              "0      466  10.047059  7.505424   9.729606  5.451007   8.474830  6.412419   \n",
              "1      467  10.404685  6.815637  10.334979  5.488309   9.994894  6.525927   \n",
              "2      468  10.793832  7.720952   9.276507  5.478224   8.184773  5.949741   \n",
              "3      469  10.440667  5.592522   8.613192  5.436625   8.210389  6.203913   \n",
              "4      470  12.521038  5.325554  10.678267  5.623786   7.786509  6.153012   \n",
              "...    ...        ...       ...        ...       ...        ...       ...   \n",
              "1163  1629  11.628490  5.570690  10.475695  6.032211   9.944405  5.865408   \n",
              "1164  1630  10.879891  6.431113  10.219154  5.435795   9.224122  5.699195   \n",
              "1165  1631   9.591235  7.984515   9.935179  5.605596   9.799519  5.808704   \n",
              "1166  1632  11.055114  8.282737   9.892589  5.753274   8.687667  5.475813   \n",
              "1167  1633  10.696475  5.533486  10.227787  5.588965  10.212643  6.633792   \n",
              "\n",
              "          EGFR      BTRC     FBXO6  ...    Age  Menopausal State  Size  \\\n",
              "0     5.899440  7.069394  7.100058  ...  43.19                 0  10.0   \n",
              "1     5.585357  6.071653  7.810600  ...  47.68                 0  25.0   \n",
              "2     5.743395  7.244882  7.781876  ...  56.45                 1  10.0   \n",
              "3     5.852012  6.219653  7.560101  ...  89.08                 1  29.0   \n",
              "4     5.502281  7.278257  7.674681  ...  86.41                 1  16.0   \n",
              "...        ...       ...       ...  ...    ...               ...   ...   \n",
              "1163  5.703147  6.649948  7.272166  ...  66.48                 1  25.0   \n",
              "1164  5.825643  6.404899  7.385644  ...  56.90                 1  45.0   \n",
              "1165  5.905282  6.491419  7.865526  ...  43.10                 0  25.0   \n",
              "1166  5.587906  6.830579  8.468221  ...  61.16                 1  25.0   \n",
              "1167  5.504219  6.468054  8.391464  ...  60.02                 1  20.0   \n",
              "\n",
              "      Radio Therapy  Chemotherapy  Hormone Therapy  Neoplasm Histologic Grade  \\\n",
              "0                 1             0                1                        3.0   \n",
              "1                 1             1                1                        2.0   \n",
              "2                 1             1                1                        2.0   \n",
              "3                 1             0                1                        2.0   \n",
              "4                 1             0                1                        3.0   \n",
              "...             ...           ...              ...                        ...   \n",
              "1163              0             0                1                        3.0   \n",
              "1164              0             0                1                        3.0   \n",
              "1165              1             0                1                        3.0   \n",
              "1166              0             0                1                        2.0   \n",
              "1167              1             0                1                        3.0   \n",
              "\n",
              "      Cellularity  Surgery-breast conserving  Surgery-mastectomy  \n",
              "0             1.0                        1.0                 0.0  \n",
              "1             0.5                        0.0                 1.0  \n",
              "2             0.5                        1.0                 0.0  \n",
              "3             0.5                        1.0                 0.0  \n",
              "4             0.5                        1.0                 0.0  \n",
              "...           ...                        ...                 ...  \n",
              "1163          1.0                        0.0                 1.0  \n",
              "1164          1.0                        0.0                 1.0  \n",
              "1165          1.0                        1.0                 0.0  \n",
              "1166          0.5                        0.0                 1.0  \n",
              "1167          1.0                        1.0                 0.0  \n",
              "\n",
              "[1168 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e14a53d2-ad3e-4eb3-abe5-722d3d66a125\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>ESR1</th>\n",
              "      <th>PGR</th>\n",
              "      <th>ERBB2</th>\n",
              "      <th>MKI67</th>\n",
              "      <th>PLAU</th>\n",
              "      <th>ELAVL1</th>\n",
              "      <th>EGFR</th>\n",
              "      <th>BTRC</th>\n",
              "      <th>FBXO6</th>\n",
              "      <th>...</th>\n",
              "      <th>Age</th>\n",
              "      <th>Menopausal State</th>\n",
              "      <th>Size</th>\n",
              "      <th>Radio Therapy</th>\n",
              "      <th>Chemotherapy</th>\n",
              "      <th>Hormone Therapy</th>\n",
              "      <th>Neoplasm Histologic Grade</th>\n",
              "      <th>Cellularity</th>\n",
              "      <th>Surgery-breast conserving</th>\n",
              "      <th>Surgery-mastectomy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>466</td>\n",
              "      <td>10.047059</td>\n",
              "      <td>7.505424</td>\n",
              "      <td>9.729606</td>\n",
              "      <td>5.451007</td>\n",
              "      <td>8.474830</td>\n",
              "      <td>6.412419</td>\n",
              "      <td>5.899440</td>\n",
              "      <td>7.069394</td>\n",
              "      <td>7.100058</td>\n",
              "      <td>...</td>\n",
              "      <td>43.19</td>\n",
              "      <td>0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>467</td>\n",
              "      <td>10.404685</td>\n",
              "      <td>6.815637</td>\n",
              "      <td>10.334979</td>\n",
              "      <td>5.488309</td>\n",
              "      <td>9.994894</td>\n",
              "      <td>6.525927</td>\n",
              "      <td>5.585357</td>\n",
              "      <td>6.071653</td>\n",
              "      <td>7.810600</td>\n",
              "      <td>...</td>\n",
              "      <td>47.68</td>\n",
              "      <td>0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>468</td>\n",
              "      <td>10.793832</td>\n",
              "      <td>7.720952</td>\n",
              "      <td>9.276507</td>\n",
              "      <td>5.478224</td>\n",
              "      <td>8.184773</td>\n",
              "      <td>5.949741</td>\n",
              "      <td>5.743395</td>\n",
              "      <td>7.244882</td>\n",
              "      <td>7.781876</td>\n",
              "      <td>...</td>\n",
              "      <td>56.45</td>\n",
              "      <td>1</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>469</td>\n",
              "      <td>10.440667</td>\n",
              "      <td>5.592522</td>\n",
              "      <td>8.613192</td>\n",
              "      <td>5.436625</td>\n",
              "      <td>8.210389</td>\n",
              "      <td>6.203913</td>\n",
              "      <td>5.852012</td>\n",
              "      <td>6.219653</td>\n",
              "      <td>7.560101</td>\n",
              "      <td>...</td>\n",
              "      <td>89.08</td>\n",
              "      <td>1</td>\n",
              "      <td>29.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>470</td>\n",
              "      <td>12.521038</td>\n",
              "      <td>5.325554</td>\n",
              "      <td>10.678267</td>\n",
              "      <td>5.623786</td>\n",
              "      <td>7.786509</td>\n",
              "      <td>6.153012</td>\n",
              "      <td>5.502281</td>\n",
              "      <td>7.278257</td>\n",
              "      <td>7.674681</td>\n",
              "      <td>...</td>\n",
              "      <td>86.41</td>\n",
              "      <td>1</td>\n",
              "      <td>16.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1163</th>\n",
              "      <td>1629</td>\n",
              "      <td>11.628490</td>\n",
              "      <td>5.570690</td>\n",
              "      <td>10.475695</td>\n",
              "      <td>6.032211</td>\n",
              "      <td>9.944405</td>\n",
              "      <td>5.865408</td>\n",
              "      <td>5.703147</td>\n",
              "      <td>6.649948</td>\n",
              "      <td>7.272166</td>\n",
              "      <td>...</td>\n",
              "      <td>66.48</td>\n",
              "      <td>1</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1164</th>\n",
              "      <td>1630</td>\n",
              "      <td>10.879891</td>\n",
              "      <td>6.431113</td>\n",
              "      <td>10.219154</td>\n",
              "      <td>5.435795</td>\n",
              "      <td>9.224122</td>\n",
              "      <td>5.699195</td>\n",
              "      <td>5.825643</td>\n",
              "      <td>6.404899</td>\n",
              "      <td>7.385644</td>\n",
              "      <td>...</td>\n",
              "      <td>56.90</td>\n",
              "      <td>1</td>\n",
              "      <td>45.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1165</th>\n",
              "      <td>1631</td>\n",
              "      <td>9.591235</td>\n",
              "      <td>7.984515</td>\n",
              "      <td>9.935179</td>\n",
              "      <td>5.605596</td>\n",
              "      <td>9.799519</td>\n",
              "      <td>5.808704</td>\n",
              "      <td>5.905282</td>\n",
              "      <td>6.491419</td>\n",
              "      <td>7.865526</td>\n",
              "      <td>...</td>\n",
              "      <td>43.10</td>\n",
              "      <td>0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1166</th>\n",
              "      <td>1632</td>\n",
              "      <td>11.055114</td>\n",
              "      <td>8.282737</td>\n",
              "      <td>9.892589</td>\n",
              "      <td>5.753274</td>\n",
              "      <td>8.687667</td>\n",
              "      <td>5.475813</td>\n",
              "      <td>5.587906</td>\n",
              "      <td>6.830579</td>\n",
              "      <td>8.468221</td>\n",
              "      <td>...</td>\n",
              "      <td>61.16</td>\n",
              "      <td>1</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1167</th>\n",
              "      <td>1633</td>\n",
              "      <td>10.696475</td>\n",
              "      <td>5.533486</td>\n",
              "      <td>10.227787</td>\n",
              "      <td>5.588965</td>\n",
              "      <td>10.212643</td>\n",
              "      <td>6.633792</td>\n",
              "      <td>5.504219</td>\n",
              "      <td>6.468054</td>\n",
              "      <td>8.391464</td>\n",
              "      <td>...</td>\n",
              "      <td>60.02</td>\n",
              "      <td>1</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1168 rows × 31 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e14a53d2-ad3e-4eb3-abe5-722d3d66a125')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e14a53d2-ad3e-4eb3-abe5-722d3d66a125 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e14a53d2-ad3e-4eb3-abe5-722d3d66a125');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8cd00a44-8b6a-4dd9-977f-77f445cca6f3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8cd00a44-8b6a-4dd9-977f-77f445cca6f3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8cd00a44-8b6a-4dd9-977f-77f445cca6f3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_3354b6e3-438a-4fa4-b0bd-9dc2a0981922\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('x_ul')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_3354b6e3-438a-4fa4-b0bd-9dc2a0981922 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('x_ul');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "x_ul"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # labeled data\n",
        "# x_train = data_l[\"x_train\"] # genetic data\n",
        "# c_train = data_l[\"c_train\"] # clinical data\n",
        "# y_train = data_l[\"y_train\"]\n",
        "\n",
        "# x_test = data_l[\"x_test\"]\n",
        "# c_test = data_l[\"c_test\"]\n",
        "# y_test = data_l[\"y_test\"]\n",
        "\n",
        "# # unlabeled data\n",
        "# x_ul = data_ul[\"x_w_full\"]\n",
        "# c_ul = data_ul[\"c_w_full\"]\n",
        "\n",
        "# # info\n",
        "# gene_name = data_l[\"gene_name\"]\n",
        "# clinical_feature = data_l[\"clinical_feature\"]"
      ],
      "metadata": {
        "id": "nSnSxvqS0Q-l"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oTlfmqM2_mD",
        "outputId": "6067e56a-60a4-4b4f-f852-50fcd22e6698"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(465, 31)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_ul.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "be7E2bp_3Cq-",
        "outputId": "8e1fb4a8-d87f-441a-8cf9-6003511d4768"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1168, 31)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Semi-Supervised Learning (SSL)"
      ],
      "metadata": {
        "id": "FePUSut2YYdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Basic SSL with 10 Loops Limitation"
      ],
      "metadata": {
        "id": "oslRddrUaOGX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model**\n",
        "```\n",
        "base_model = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"clf\", RandomForestClassifier(n_estimators=100, random_state=42))\n",
        "])\n",
        "```\n",
        "\n",
        "**Explination**\n",
        "- `(\"scaler\", StandardScaler())`\n",
        "    \n",
        "    Standardizes the features\n",
        "\n",
        "- `(\"clf\", RandomForestClassifier(n_estimators=100, random_state=42))`\n",
        "\n",
        "  - Random Forest Classifier\n",
        "  - `n_estimators=100`: Specifies the number of decision trees in the forest.\n",
        "  - `random_state=42`: Ensures reproducibility of results by fixing the random seed.\n"
      ],
      "metadata": {
        "id": "Uu_XeYc9gLQY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Combine gene expression and clinical data\n",
        "def combine_features(gene_data, clinical_data):\n",
        "    return np.hstack((gene_data, clinical_data))\n",
        "\n",
        "# Convert labels from True/False to 1/0\n",
        "y_train = np.array([1 if label else 0 for label in y_train])\n",
        "\n",
        "# Combine labeled data\n",
        "X = combine_features(x_train, c_train)\n",
        "y = y_train\n",
        "\n",
        "# Split labeled data into a training set and a test set\n",
        "X_train, X_test, y_train_split, y_test_split = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Create a pipeline with scaling and a classifier\n",
        "base_model = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"clf\", RandomForestClassifier(n_estimators=100, random_state=42))\n",
        "])\n",
        "\n",
        "# Self-training\n",
        "max_iterations = 10\n",
        "confidence_threshold = 0.9\n",
        "X_labeled = X_train.copy()\n",
        "y_labeled = y_train_split.copy()\n",
        "X_unlabeled = combine_features(x_ul, c_ul)\n",
        "pseudo_labels = []\n",
        "\n",
        "for iteration in range(max_iterations):\n",
        "    print(f\"Iteration {iteration + 1}...\")\n",
        "\n",
        "    # Train the model on the labeled dataset\n",
        "    base_model.fit(X_labeled, y_labeled)\n",
        "\n",
        "    # Predict probabilities on the unlabeled dataset\n",
        "    probs = base_model.predict_proba(X_unlabeled)\n",
        "    pseudo_labels = np.argmax(probs, axis=1)  # Predicted labels\n",
        "    confidence_scores = np.max(probs, axis=1)  # Max probabilities\n",
        "\n",
        "    # Select confident predictions\n",
        "    confident_indices = np.where(confidence_scores >= confidence_threshold)[0]\n",
        "    if len(confident_indices) == 0:\n",
        "        print(\"No confident predictions in this iteration. Stopping...\")\n",
        "        break\n",
        "\n",
        "    # Add confident predictions to the labeled dataset\n",
        "    X_labeled = np.vstack((X_labeled, X_unlabeled[confident_indices]))\n",
        "    y_labeled = np.hstack((y_labeled, pseudo_labels[confident_indices]))\n",
        "    X_unlabeled = np.delete(X_unlabeled, confident_indices, axis=0)\n",
        "\n",
        "    print(f\"Added {len(confident_indices)} pseudo-labeled samples.\")\n",
        "\n",
        "# Evaluate on split test set\n",
        "y_test_pred = base_model.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test_split, y_test_pred)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "# Combine original and pseudo-labeled data\n",
        "labeled_data = pd.DataFrame(np.hstack((X_train, y_train_split.reshape(-1, 1))),\n",
        "                            columns=[*gene_name, *clinical_feature, 'Label'])\n",
        "\n",
        "pseudo_labeled_data = pd.DataFrame(\n",
        "    np.hstack((X_labeled[len(X_train):], y_labeled[len(X_train):].reshape(-1, 1))),\n",
        "    columns=[*gene_name, *clinical_feature, 'Label']\n",
        ")\n",
        "\n",
        "# Ensure labels are stored as 0/1\n",
        "labeled_data['Label'] = labeled_data['Label'].astype(int)\n",
        "pseudo_labeled_data['Label'] = pseudo_labeled_data['Label'].astype(int)\n",
        "\n",
        "combined_data = pd.concat([labeled_data, pseudo_labeled_data], ignore_index=True)\n",
        "\n",
        "# Save to CSV\n",
        "output_file = \"/content/drive/My Drive/AIIM/Final/combined_labeled_data.csv\"\n",
        "combined_data.to_csv(output_file, index=False)\n",
        "print(f\"Combined labeled data saved to {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrkGZ_H3t9fQ",
        "outputId": "87d55ac1-b045-4a4f-8a84-2797175b17e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1...\n",
            "Added 18 pseudo-labeled samples.\n",
            "Iteration 2...\n",
            "Added 15 pseudo-labeled samples.\n",
            "Iteration 3...\n",
            "Added 13 pseudo-labeled samples.\n",
            "Iteration 4...\n",
            "Added 14 pseudo-labeled samples.\n",
            "Iteration 5...\n",
            "Added 21 pseudo-labeled samples.\n",
            "Iteration 6...\n",
            "Added 25 pseudo-labeled samples.\n",
            "Iteration 7...\n",
            "Added 29 pseudo-labeled samples.\n",
            "Iteration 8...\n",
            "Added 33 pseudo-labeled samples.\n",
            "Iteration 9...\n",
            "Added 25 pseudo-labeled samples.\n",
            "Iteration 10...\n",
            "Added 16 pseudo-labeled samples.\n",
            "Test Accuracy: 0.6989\n",
            "Combined labeled data saved to /content/drive/My Drive/AIIM/Final/combined_labeled_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Basic SSL with No Loop Limitation (USE THIS ONE)"
      ],
      "metadata": {
        "id": "cMPrjUfiaTjy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "****\n",
        "**Model**\n",
        "```\n",
        "base_model = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"clf\", RandomForestClassifier(n_estimators=100, random_state=42))\n",
        "])\n",
        "```\n",
        "\n",
        "**Explination**\n",
        "- `(\"scaler\", StandardScaler())`\n",
        "    \n",
        "    - Standardizes the features\n",
        "\n",
        "- `(\"clf\", RandomForestClassifier(n_estimators=100, random_state=42))`\n",
        "\n",
        "  - Random Forest Classifier\n",
        "  - `n_estimators=100`: Specifies the number of decision trees in the forest.\n",
        "  - `random_state=42`: Ensures reproducibility of results by fixing the random seed.\n",
        "\n",
        "****\n",
        "\n",
        "**Method**\n",
        "\n",
        "Train an initail model using labeled data to predict the label for unlabeled data. Add those with high confidence to labeled data and re-train the model. Iterate until no more data meet the confidence threshold.\n",
        "\n",
        "The remaining unlabeled data would be added to the final dataset too, with confidence set to 0.5 (or the real confidence).\n",
        "\n",
        "****"
      ],
      "metadata": {
        "id": "da6umdQSePV9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Method for semi-supervised learning\n",
        "def semi_supervised_learning(x_train, y_train, x_ul, base_model, confidence_threshold=0.9):\n",
        "    x_train = x_train.copy()\n",
        "    x_train[\"Confidence\"] = 1.0\n",
        "\n",
        "    y_train = y_train.copy()\n",
        "    x_ul = x_ul.copy()\n",
        "\n",
        "    iteration = 0\n",
        "    while not x_ul.empty:\n",
        "        # Train the model on labeled data\n",
        "        base_model.fit(x_train.drop(columns=[\"Confidence\"]), y_train)\n",
        "\n",
        "        # Predict probabilities for unlabeled data\n",
        "        probas = base_model.predict_proba(x_ul)\n",
        "        predictions = base_model.predict(x_ul)\n",
        "\n",
        "        # Select high-confidence predictions\n",
        "        max_probas = np.max(probas, axis=1)\n",
        "        high_conf_indices = np.where(max_probas >= confidence_threshold)[0]\n",
        "\n",
        "        if len(high_conf_indices) == 0:\n",
        "            print(f\"No more high-confidence predictions at iteration {iteration}.\")\n",
        "            break\n",
        "\n",
        "        # Add high-confidence predictions to the labeled dataset\n",
        "        x_high_conf = x_ul.iloc[high_conf_indices]\n",
        "        y_high_conf = predictions[high_conf_indices]\n",
        "        high_conf_values = max_probas[high_conf_indices]\n",
        "\n",
        "        # x_high_conf.loc[\"Confidence\"] = high_conf_values\n",
        "        x_high_conf = pd.concat([x_high_conf, pd.Series(high_conf_values, index=x_high_conf.index, name=\"Confidence\")], axis=1)\n",
        "\n",
        "        x_train = pd.concat([x_train, x_high_conf], axis=0)\n",
        "        y_train = pd.concat([y_train, pd.Series(y_high_conf, index=x_high_conf.index)], axis=0)\n",
        "\n",
        "        # Remove high-confidence data from the unlabeled dataset\n",
        "        x_ul = x_ul.drop(index=x_high_conf.index)\n",
        "\n",
        "        iteration += 1\n",
        "        print(f\"Iteration {iteration}: Added {len(high_conf_indices)} samples to labeled data.\")\n",
        "\n",
        "    # Add remaining unlabeled data with their final predicted probabilities\n",
        "    if not x_ul.empty:\n",
        "        final_probas = base_model.predict_proba(x_ul)\n",
        "        final_predictions = base_model.predict(x_ul)\n",
        "        max_confidences = np.max(final_probas, axis=1)\n",
        "\n",
        "        # Combine the data, labels, and confidence into a single DataFrame\n",
        "        remaining_data = x_ul.copy()\n",
        "        remaining_data[\"Label\"] = final_predictions\n",
        "        # remaining_data[\"Confidence\"] = 0.5\n",
        "        remaining_data[\"Confidence\"] = max_confidences\n",
        "\n",
        "    else:\n",
        "        remaining_data = pd.DataFrame(columns=list(x_ul.columns) + [\"Label\", \"Confidence\"])\n",
        "\n",
        "    # Combine the (psuedo) labeled data with remaining data\n",
        "\n",
        "    x_train[\"Label\"] = y_train\n",
        "    pseudo_labeled_data = pd.concat([x_train, remaining_data], axis=0)\n",
        "\n",
        "    return base_model, pseudo_labeled_data"
      ],
      "metadata": {
        "id": "XiKCEWUMK59t"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Split labeled data into a training set and a test set\n",
        "# x_train_split, x_test_split, y_train_split, y_test_split = train_test_split(\n",
        "#     x_train, y_train, test_size=0.2, random_state=42, stratify=y\n",
        "# )\n",
        "\n",
        "# Create a pipeline with scaling and a classifier\n",
        "base_model = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"clf\", RandomForestClassifier(n_estimators=100, random_state=42))\n",
        "])\n",
        "\n",
        "# Run semi-supervised learning\n",
        "model, pseudo_labeled_data = semi_supervised_learning(\n",
        "    x_train, y_train, x_ul, base_model, confidence_threshold=0.85\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7QBCrHcaLsm",
        "outputId": "3a3c6f20-5ba9-4a0f-f1cd-ff5566e23640"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1: Added 41 samples to labeled data.\n",
            "Iteration 2: Added 70 samples to labeled data.\n",
            "Iteration 3: Added 120 samples to labeled data.\n",
            "Iteration 4: Added 161 samples to labeled data.\n",
            "Iteration 5: Added 155 samples to labeled data.\n",
            "Iteration 6: Added 136 samples to labeled data.\n",
            "Iteration 7: Added 97 samples to labeled data.\n",
            "Iteration 8: Added 41 samples to labeled data.\n",
            "Iteration 9: Added 34 samples to labeled data.\n",
            "Iteration 10: Added 16 samples to labeled data.\n",
            "Iteration 11: Added 15 samples to labeled data.\n",
            "Iteration 12: Added 13 samples to labeled data.\n",
            "Iteration 13: Added 5 samples to labeled data.\n",
            "Iteration 14: Added 7 samples to labeled data.\n",
            "Iteration 15: Added 3 samples to labeled data.\n",
            "Iteration 16: Added 2 samples to labeled data.\n",
            "Iteration 17: Added 2 samples to labeled data.\n",
            "Iteration 18: Added 1 samples to labeled data.\n",
            "Iteration 19: Added 1 samples to labeled data.\n",
            "Iteration 20: Added 1 samples to labeled data.\n",
            "No more high-confidence predictions at iteration 20.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Concat x_train and y_train column-wise\n",
        "# pseudo_labeled_data = pd.concat([x_final_train, y_final_train], axis=1)\n",
        "\n",
        "# Sort data by 'ID' column\n",
        "pseudo_labeled_data = pseudo_labeled_data.sort_values(by='ID')\n",
        "# Delete the 'ID' column\n",
        "pseudo_labeled_data = pseudo_labeled_data.drop(columns=['ID'])"
      ],
      "metadata": {
        "id": "eEnPV0tmZs8P"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pseudo_labeled_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "k2pqwN-2qGCm",
        "outputId": "6188be1b-8587-4239-8693-34c04fc74e0e"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           ESR1       PGR      ERBB2     MKI67       PLAU    ELAVL1  \\\n",
              "0     10.041281  7.376123   9.725825  5.427919   9.300307  6.219375   \n",
              "1     11.276581  7.331223   9.956267  5.629876   8.119906  5.665620   \n",
              "2      7.536847  5.587666  11.514514  5.722951   6.741081  6.321480   \n",
              "3     10.395644  6.531288   9.075396  5.440774   7.861422  5.973844   \n",
              "4      6.204958  5.172111   8.881671  5.861609   8.530361  6.671294   \n",
              "...         ...       ...        ...       ...        ...       ...   \n",
              "1163  11.628490  5.570690  10.475695  6.032211   9.944405  5.865408   \n",
              "1164  10.879891  6.431113  10.219154  5.435795   9.224122  5.699195   \n",
              "1165   9.591235  7.984515   9.935179  5.605596   9.799519  5.808704   \n",
              "1166  11.055114  8.282737   9.892589  5.753274   8.687667  5.475813   \n",
              "1167  10.696475  5.533486  10.227787  5.588965  10.212643  6.633792   \n",
              "\n",
              "           EGFR      BTRC     FBXO6      SHMT2  ...  Size  Radio Therapy  \\\n",
              "0      6.125355  5.888779  7.893369   9.007343  ...  15.0              0   \n",
              "1      5.775809  6.251167  8.242063  10.871432  ...  40.0              1   \n",
              "2      5.466188  6.956486  7.673015   9.837096  ...  28.0              0   \n",
              "3      5.757120  6.026611  7.666777   9.455256  ...  13.0              1   \n",
              "4     11.724683  6.046692  7.401715  10.481299  ...  39.0              1   \n",
              "...         ...       ...       ...        ...  ...   ...            ...   \n",
              "1163   5.703147  6.649948  7.272166   9.750208  ...  25.0              0   \n",
              "1164   5.825643  6.404899  7.385644   9.271953  ...  45.0              0   \n",
              "1165   5.905282  6.491419  7.865526   9.741103  ...  25.0              1   \n",
              "1166   5.587906  6.830579  8.468221   9.482622  ...  25.0              0   \n",
              "1167   5.504219  6.468054  8.391464   9.812163  ...  20.0              1   \n",
              "\n",
              "      Chemotherapy  Hormone Therapy  Neoplasm Histologic Grade  Cellularity  \\\n",
              "0                1                1                        2.0          1.0   \n",
              "1                1                1                        3.0          1.0   \n",
              "2                0                0                        2.0          1.0   \n",
              "3                0                1                        2.0          0.5   \n",
              "4                1                0                        3.0          0.0   \n",
              "...            ...              ...                        ...          ...   \n",
              "1163             0                1                        3.0          1.0   \n",
              "1164             0                1                        3.0          1.0   \n",
              "1165             0                1                        3.0          1.0   \n",
              "1166             0                1                        2.0          0.5   \n",
              "1167             0                1                        3.0          1.0   \n",
              "\n",
              "      Surgery-breast conserving  Surgery-mastectomy  Confidence  Label  \n",
              "0                           0.0                 1.0        1.00      0  \n",
              "1                           0.0                 1.0        1.00      1  \n",
              "2                           0.0                 1.0        1.00      1  \n",
              "3                           1.0                 0.0        1.00      0  \n",
              "4                           0.0                 1.0        1.00      1  \n",
              "...                         ...                 ...         ...    ...  \n",
              "1163                        0.0                 1.0        0.86      0  \n",
              "1164                        0.0                 1.0        0.85      0  \n",
              "1165                        1.0                 0.0        0.85      0  \n",
              "1166                        0.0                 1.0        0.89      0  \n",
              "1167                        1.0                 0.0        0.86      0  \n",
              "\n",
              "[1633 rows x 32 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c69a73e1-2249-414a-b156-abcbcc463f76\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ESR1</th>\n",
              "      <th>PGR</th>\n",
              "      <th>ERBB2</th>\n",
              "      <th>MKI67</th>\n",
              "      <th>PLAU</th>\n",
              "      <th>ELAVL1</th>\n",
              "      <th>EGFR</th>\n",
              "      <th>BTRC</th>\n",
              "      <th>FBXO6</th>\n",
              "      <th>SHMT2</th>\n",
              "      <th>...</th>\n",
              "      <th>Size</th>\n",
              "      <th>Radio Therapy</th>\n",
              "      <th>Chemotherapy</th>\n",
              "      <th>Hormone Therapy</th>\n",
              "      <th>Neoplasm Histologic Grade</th>\n",
              "      <th>Cellularity</th>\n",
              "      <th>Surgery-breast conserving</th>\n",
              "      <th>Surgery-mastectomy</th>\n",
              "      <th>Confidence</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10.041281</td>\n",
              "      <td>7.376123</td>\n",
              "      <td>9.725825</td>\n",
              "      <td>5.427919</td>\n",
              "      <td>9.300307</td>\n",
              "      <td>6.219375</td>\n",
              "      <td>6.125355</td>\n",
              "      <td>5.888779</td>\n",
              "      <td>7.893369</td>\n",
              "      <td>9.007343</td>\n",
              "      <td>...</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11.276581</td>\n",
              "      <td>7.331223</td>\n",
              "      <td>9.956267</td>\n",
              "      <td>5.629876</td>\n",
              "      <td>8.119906</td>\n",
              "      <td>5.665620</td>\n",
              "      <td>5.775809</td>\n",
              "      <td>6.251167</td>\n",
              "      <td>8.242063</td>\n",
              "      <td>10.871432</td>\n",
              "      <td>...</td>\n",
              "      <td>40.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.536847</td>\n",
              "      <td>5.587666</td>\n",
              "      <td>11.514514</td>\n",
              "      <td>5.722951</td>\n",
              "      <td>6.741081</td>\n",
              "      <td>6.321480</td>\n",
              "      <td>5.466188</td>\n",
              "      <td>6.956486</td>\n",
              "      <td>7.673015</td>\n",
              "      <td>9.837096</td>\n",
              "      <td>...</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10.395644</td>\n",
              "      <td>6.531288</td>\n",
              "      <td>9.075396</td>\n",
              "      <td>5.440774</td>\n",
              "      <td>7.861422</td>\n",
              "      <td>5.973844</td>\n",
              "      <td>5.757120</td>\n",
              "      <td>6.026611</td>\n",
              "      <td>7.666777</td>\n",
              "      <td>9.455256</td>\n",
              "      <td>...</td>\n",
              "      <td>13.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6.204958</td>\n",
              "      <td>5.172111</td>\n",
              "      <td>8.881671</td>\n",
              "      <td>5.861609</td>\n",
              "      <td>8.530361</td>\n",
              "      <td>6.671294</td>\n",
              "      <td>11.724683</td>\n",
              "      <td>6.046692</td>\n",
              "      <td>7.401715</td>\n",
              "      <td>10.481299</td>\n",
              "      <td>...</td>\n",
              "      <td>39.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1163</th>\n",
              "      <td>11.628490</td>\n",
              "      <td>5.570690</td>\n",
              "      <td>10.475695</td>\n",
              "      <td>6.032211</td>\n",
              "      <td>9.944405</td>\n",
              "      <td>5.865408</td>\n",
              "      <td>5.703147</td>\n",
              "      <td>6.649948</td>\n",
              "      <td>7.272166</td>\n",
              "      <td>9.750208</td>\n",
              "      <td>...</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1164</th>\n",
              "      <td>10.879891</td>\n",
              "      <td>6.431113</td>\n",
              "      <td>10.219154</td>\n",
              "      <td>5.435795</td>\n",
              "      <td>9.224122</td>\n",
              "      <td>5.699195</td>\n",
              "      <td>5.825643</td>\n",
              "      <td>6.404899</td>\n",
              "      <td>7.385644</td>\n",
              "      <td>9.271953</td>\n",
              "      <td>...</td>\n",
              "      <td>45.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1165</th>\n",
              "      <td>9.591235</td>\n",
              "      <td>7.984515</td>\n",
              "      <td>9.935179</td>\n",
              "      <td>5.605596</td>\n",
              "      <td>9.799519</td>\n",
              "      <td>5.808704</td>\n",
              "      <td>5.905282</td>\n",
              "      <td>6.491419</td>\n",
              "      <td>7.865526</td>\n",
              "      <td>9.741103</td>\n",
              "      <td>...</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1166</th>\n",
              "      <td>11.055114</td>\n",
              "      <td>8.282737</td>\n",
              "      <td>9.892589</td>\n",
              "      <td>5.753274</td>\n",
              "      <td>8.687667</td>\n",
              "      <td>5.475813</td>\n",
              "      <td>5.587906</td>\n",
              "      <td>6.830579</td>\n",
              "      <td>8.468221</td>\n",
              "      <td>9.482622</td>\n",
              "      <td>...</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.89</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1167</th>\n",
              "      <td>10.696475</td>\n",
              "      <td>5.533486</td>\n",
              "      <td>10.227787</td>\n",
              "      <td>5.588965</td>\n",
              "      <td>10.212643</td>\n",
              "      <td>6.633792</td>\n",
              "      <td>5.504219</td>\n",
              "      <td>6.468054</td>\n",
              "      <td>8.391464</td>\n",
              "      <td>9.812163</td>\n",
              "      <td>...</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1633 rows × 32 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c69a73e1-2249-414a-b156-abcbcc463f76')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c69a73e1-2249-414a-b156-abcbcc463f76 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c69a73e1-2249-414a-b156-abcbcc463f76');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6c5c247a-18bf-4fcc-89fa-ddaa35a8dc71\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6c5c247a-18bf-4fcc-89fa-ddaa35a8dc71')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6c5c247a-18bf-4fcc-89fa-ddaa35a8dc71 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_73eb0d54-e599-4cf8-83d2-5e9882ac3d5e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('pseudo_labeled_data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_73eb0d54-e599-4cf8-83d2-5e9882ac3d5e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('pseudo_labeled_data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "pseudo_labeled_data"
            }
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save to CSV\n",
        "output_file = \"/content/drive/My Drive/AIIM/Final/pseudo_labeled_rf_full_real_conf.csv\"\n",
        "pseudo_labeled_data.to_csv(output_file, index=False)"
      ],
      "metadata": {
        "id": "dmys3srAc9K_"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradient Boosting - XGBoost"
      ],
      "metadata": {
        "id": "HA92ReeSesxX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- with Hyperparameter Tuning\n",
        "- the result is terrible haha\n",
        "- dump!"
      ],
      "metadata": {
        "id": "swZNZ02K4sM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from xgboost import XGBClassifier\n",
        "from scipy.stats import uniform, randint\n",
        "\n",
        "# Combine gene expression and clinical data\n",
        "def combine_features(gene_data, clinical_data):\n",
        "    return np.hstack((gene_data, clinical_data))\n",
        "\n",
        "# Convert labels from True/False to 1/0\n",
        "y_train = np.array([1 if label else 0 for label in y_train])\n",
        "\n",
        "# Combine labeled data\n",
        "X = combine_features(x_train, c_train)\n",
        "y = y_train\n",
        "\n",
        "# Split labeled data into a training set and a test set\n",
        "X_train, X_test, y_train_split, y_test_split = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Prepare the unlabeled data\n",
        "X_unlabeled = combine_features(x_ul, c_ul)\n",
        "X_unlabeled = scaler.transform(X_unlabeled)\n",
        "\n",
        "# Define the hyperparameter grid for RandomizedSearchCV\n",
        "param_dist = {\n",
        "    'n_estimators': randint(100, 500),               # Number of boosting rounds\n",
        "    'max_depth': randint(3, 10),                      # Depth of trees\n",
        "    'learning_rate': uniform(1e-3, 1e-1),              # Learning rate\n",
        "    'subsample': uniform(0.6, 0.2),                   # Subsample ratio\n",
        "    'colsample_bytree': uniform(0.6, 0.2),            # Column sampling\n",
        "    'scale_pos_weight': uniform(1, 10),               # Class imbalance weight\n",
        "}\n",
        "\n",
        "# Initialize the XGBoost model\n",
        "model = XGBClassifier(\n",
        "    # use_label_encoder=False,\n",
        "    eval_metric=\"logloss\"\n",
        ")\n",
        "\n",
        "# Set up RandomizedSearchCV with cross-validation\n",
        "random_search = RandomizedSearchCV(\n",
        "    model,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=50,  # Number of parameter settings to try\n",
        "    scoring='accuracy',\n",
        "    cv=3,        # 3-fold cross-validation\n",
        "    random_state=42,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "# Fit the RandomizedSearchCV to the training data\n",
        "random_search.fit(X_train, y_train_split)\n",
        "\n",
        "# Get the best parameters and model\n",
        "best_params = random_search.best_params_\n",
        "best_model = random_search.best_estimator_\n",
        "\n",
        "# Output the best parameters\n",
        "print(\"Best parameters found: \", best_params)\n",
        "\n",
        "# Self-training\n",
        "confidence_threshold = 0.9\n",
        "X_labeled = X_train.copy()\n",
        "y_labeled = y_train_split.copy()\n",
        "confidence_labeled = np.ones(len(y_labeled))  # Confidence for labeled data is 1\n",
        "pseudo_labels = []\n",
        "confidence_scores_pseudo = []\n",
        "\n",
        "total_added = 0  # Counter to track total number of pseudo-labeled data added\n",
        "\n",
        "while True:\n",
        "    print(\"Starting new iteration...\")\n",
        "\n",
        "    # Train the best model on the labeled dataset\n",
        "    best_model.fit(X_labeled, y_labeled)\n",
        "\n",
        "    # Predict probabilities on the unlabeled dataset\n",
        "    probs = best_model.predict_proba(X_unlabeled)\n",
        "    pseudo_labels = np.argmax(probs, axis=1)  # Predicted labels\n",
        "    confidence_scores = np.max(probs, axis=1)  # Max probabilities\n",
        "\n",
        "    # Select confident predictions\n",
        "    confident_indices = np.where(confidence_scores >= confidence_threshold)[0]\n",
        "    if len(confident_indices) == 0:\n",
        "        print(\"No confident predictions left. Stopping...\")\n",
        "        break\n",
        "\n",
        "    # Add confident predictions to the labeled dataset\n",
        "    X_labeled = np.vstack((X_labeled, X_unlabeled[confident_indices]))\n",
        "    y_labeled = np.hstack((y_labeled, pseudo_labels[confident_indices]))\n",
        "    confidence_labeled = np.hstack((confidence_labeled, confidence_scores[confident_indices]))\n",
        "    X_unlabeled = np.delete(X_unlabeled, confident_indices, axis=0)\n",
        "\n",
        "    total_added += len(confident_indices)  # Update the total added counter\n",
        "\n",
        "    print(f\"Added {len(confident_indices)} pseudo-labeled samples.\")\n",
        "\n",
        "# Output the total number of pseudo-labeled data added\n",
        "print(f\"Total pseudo-labeled data added: {total_added}\")\n",
        "\n",
        "# Combine original and pseudo-labeled data\n",
        "labeled_data = pd.DataFrame(np.hstack((X_train, y_train_split.reshape(-1, 1), np.ones((len(y_train_split), 1)))),\n",
        "                            columns=[*gene_name, *clinical_feature, 'Label', 'Confidence'])\n",
        "\n",
        "pseudo_labeled_data = pd.DataFrame(\n",
        "    np.hstack((X_labeled[len(X_train):], y_labeled[len(X_train):].reshape(-1, 1), confidence_labeled[len(X_train):].reshape(-1, 1))),\n",
        "    columns=[*gene_name, *clinical_feature, 'Label', 'Confidence']\n",
        ")\n",
        "\n",
        "# Ensure labels are stored as 0/1\n",
        "labeled_data['Label'] = labeled_data['Label'].astype(int)\n",
        "pseudo_labeled_data['Label'] = pseudo_labeled_data['Label'].astype(int)\n",
        "\n",
        "combined_data = pd.concat([labeled_data, pseudo_labeled_data], ignore_index=True)\n",
        "\n",
        "# Save to CSV\n",
        "output_file = \"/content/drive/My Drive/AIIM/Final/combined_labeled_data_xgboost_tuned.csv\"\n",
        "combined_data.to_csv(output_file, index=False)\n",
        "print(f\"Combined labeled data saved to {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYi3XoP0eqp2",
        "outputId": "218ef073-1da1-4e44-f437-09f199c7c03e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
            "[CV] END colsample_bytree=0.6749080237694725, learning_rate=0.09607143064099162, max_depth=5, n_estimators=171, scale_pos_weight=6.986584841970366, subsample=0.6312037280884872; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.6749080237694725, learning_rate=0.09607143064099162, max_depth=5, n_estimators=171, scale_pos_weight=6.986584841970366, subsample=0.6312037280884872; total time=   1.5s\n",
            "[CV] END colsample_bytree=0.6749080237694725, learning_rate=0.09607143064099162, max_depth=5, n_estimators=171, scale_pos_weight=6.986584841970366, subsample=0.6312037280884872; total time=   3.2s\n",
            "[CV] END colsample_bytree=0.6311989040672406, learning_rate=0.006808361216819946, max_depth=7, n_estimators=199, scale_pos_weight=2.428668179219408, subsample=0.7301776945897706; total time=   0.8s\n",
            "[CV] END colsample_bytree=0.6311989040672406, learning_rate=0.006808361216819946, max_depth=7, n_estimators=199, scale_pos_weight=2.428668179219408, subsample=0.7301776945897706; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.6311989040672406, learning_rate=0.006808361216819946, max_depth=7, n_estimators=199, scale_pos_weight=2.428668179219408, subsample=0.7301776945897706; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.61128231580542, learning_rate=0.07319987722668247, max_depth=8, n_estimators=393, scale_pos_weight=1.0077876584101433, subsample=0.7984423118582435; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.61128231580542, learning_rate=0.07319987722668247, max_depth=8, n_estimators=393, scale_pos_weight=1.0077876584101433, subsample=0.7984423118582435; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.61128231580542, learning_rate=0.07319987722668247, max_depth=8, n_estimators=393, scale_pos_weight=1.0077876584101433, subsample=0.7984423118582435; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.7234963019255433, learning_rate=0.06216531604882809, max_depth=7, n_estimators=335, scale_pos_weight=1.2306242504141576, subsample=0.7049549320516778; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.7234963019255433, learning_rate=0.06216531604882809, max_depth=7, n_estimators=335, scale_pos_weight=1.2306242504141576, subsample=0.7049549320516778; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.7234963019255433, learning_rate=0.06216531604882809, max_depth=7, n_estimators=335, scale_pos_weight=1.2306242504141576, subsample=0.7049549320516778; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.6799721943430511, learning_rate=0.005666566321361543, max_depth=6, n_estimators=370, scale_pos_weight=5.56069984217036, subsample=0.7570351922786027; total time=   1.0s\n",
            "[CV] END colsample_bytree=0.6799721943430511, learning_rate=0.005666566321361543, max_depth=6, n_estimators=370, scale_pos_weight=5.56069984217036, subsample=0.7570351922786027; total time=   1.0s\n",
            "[CV] END colsample_bytree=0.6799721943430511, learning_rate=0.005666566321361543, max_depth=6, n_estimators=370, scale_pos_weight=5.56069984217036, subsample=0.7570351922786027; total time=   1.0s\n",
            "[CV] END colsample_bytree=0.639934756431672, learning_rate=0.05242344384136116, max_depth=3, n_estimators=230, scale_pos_weight=9.599404067363206, subsample=0.736061507717556; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.639934756431672, learning_rate=0.05242344384136116, max_depth=3, n_estimators=230, scale_pos_weight=9.599404067363206, subsample=0.736061507717556; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.639934756431672, learning_rate=0.05242344384136116, max_depth=3, n_estimators=230, scale_pos_weight=9.599404067363206, subsample=0.736061507717556; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.6900998503939086, learning_rate=0.002326496115986653, max_depth=3, n_estimators=415, scale_pos_weight=6.632882178455393, subsample=0.6770833005079833; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.6900998503939086, learning_rate=0.002326496115986653, max_depth=3, n_estimators=415, scale_pos_weight=6.632882178455393, subsample=0.6770833005079833; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.6900998503939086, learning_rate=0.002326496115986653, max_depth=3, n_estimators=415, scale_pos_weight=6.632882178455393, subsample=0.6770833005079833; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.6031932504440428, learning_rate=0.024089382562214903, max_depth=6, n_estimators=466, scale_pos_weight=7.832635188254582, subsample=0.7219993315565242; total time=   0.8s\n",
            "[CV] END colsample_bytree=0.6031932504440428, learning_rate=0.024089382562214903, max_depth=6, n_estimators=466, scale_pos_weight=7.832635188254582, subsample=0.7219993315565242; total time=   2.3s\n",
            "[CV] END colsample_bytree=0.6031932504440428, learning_rate=0.024089382562214903, max_depth=6, n_estimators=466, scale_pos_weight=7.832635188254582, subsample=0.7219993315565242; total time=   3.7s\n",
            "[CV] END colsample_bytree=0.7666389823472328, learning_rate=0.01833646535077721, max_depth=3, n_estimators=149, scale_pos_weight=7.62522284353982, subsample=0.6623422152178822; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.7666389823472328, learning_rate=0.01833646535077721, max_depth=3, n_estimators=149, scale_pos_weight=7.62522284353982, subsample=0.6623422152178822; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.7666389823472328, learning_rate=0.01833646535077721, max_depth=3, n_estimators=149, scale_pos_weight=7.62522284353982, subsample=0.6623422152178822; total time=   0.1s\n",
            "[CV] END colsample_bytree=0.7040136042355621, learning_rate=0.05567102793432797, max_depth=8, n_estimators=290, scale_pos_weight=9.422847745949985, subsample=0.6899508266739531; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.7040136042355621, learning_rate=0.05567102793432797, max_depth=8, n_estimators=290, scale_pos_weight=9.422847745949985, subsample=0.6899508266739531; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.7040136042355621, learning_rate=0.05567102793432797, max_depth=8, n_estimators=290, scale_pos_weight=9.422847745949985, subsample=0.6899508266739531; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.6790300472003629, learning_rate=0.09366588657937942, max_depth=9, n_estimators=403, scale_pos_weight=4.265407688058354, subsample=0.7140887948810799; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.6790300472003629, learning_rate=0.09366588657937942, max_depth=9, n_estimators=403, scale_pos_weight=4.265407688058354, subsample=0.7140887948810799; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.6790300472003629, learning_rate=0.09366588657937942, max_depth=9, n_estimators=403, scale_pos_weight=4.265407688058354, subsample=0.7140887948810799; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.7041668520051647, learning_rate=0.09711720243493492, max_depth=7, n_estimators=307, scale_pos_weight=8.473201101373808, subsample=0.7079384264778159; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.7041668520051647, learning_rate=0.09711720243493492, max_depth=7, n_estimators=307, scale_pos_weight=8.473201101373808, subsample=0.7079384264778159; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.7041668520051647, learning_rate=0.09711720243493492, max_depth=7, n_estimators=307, scale_pos_weight=8.473201101373808, subsample=0.7079384264778159; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.7173502331327697, learning_rate=0.0975255307264138, max_depth=6, n_estimators=479, scale_pos_weight=3.7599918202254337, subsample=0.6592547011408164; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.7173502331327697, learning_rate=0.0975255307264138, max_depth=6, n_estimators=479, scale_pos_weight=3.7599918202254337, subsample=0.6592547011408164; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.7173502331327697, learning_rate=0.0975255307264138, max_depth=6, n_estimators=479, scale_pos_weight=3.7599918202254337, subsample=0.6592547011408164; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.6330533878126005, learning_rate=0.002563640674119393, max_depth=3, n_estimators=443, scale_pos_weight=4.948815181755697, subsample=0.6586976349436076; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.6330533878126005, learning_rate=0.002563640674119393, max_depth=3, n_estimators=443, scale_pos_weight=4.948815181755697, subsample=0.6586976349436076; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.6330533878126005, learning_rate=0.002563640674119393, max_depth=3, n_estimators=443, scale_pos_weight=4.948815181755697, subsample=0.6586976349436076; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.6028159645430169, learning_rate=0.020884240408880518, max_depth=5, n_estimators=388, scale_pos_weight=7.059599747810114, subsample=0.7852601757026698; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.6028159645430169, learning_rate=0.020884240408880518, max_depth=5, n_estimators=388, scale_pos_weight=7.059599747810114, subsample=0.7852601757026698; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.6028159645430169, learning_rate=0.020884240408880518, max_depth=5, n_estimators=388, scale_pos_weight=7.059599747810114, subsample=0.7852601757026698; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.7302154051003888, learning_rate=0.09249596755437808, max_depth=3, n_estimators=427, scale_pos_weight=5.494506741382034, subsample=0.6190820232980823; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.7302154051003888, learning_rate=0.09249596755437808, max_depth=3, n_estimators=427, scale_pos_weight=5.494506741382034, subsample=0.6190820232980823; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.7302154051003888, learning_rate=0.09249596755437808, max_depth=3, n_estimators=427, scale_pos_weight=5.494506741382034, subsample=0.6190820232980823; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.6741636504396532, learning_rate=0.06788412526636073, max_depth=7, n_estimators=198, scale_pos_weight=6.912977877077271, subsample=0.6549443585980128; total time=   1.9s\n",
            "[CV] END colsample_bytree=0.6741636504396532, learning_rate=0.06788412526636073, max_depth=7, n_estimators=198, scale_pos_weight=6.912977877077271, subsample=0.6549443585980128; total time=   1.9s\n",
            "[CV] END colsample_bytree=0.6741636504396532, learning_rate=0.06788412526636073, max_depth=7, n_estimators=198, scale_pos_weight=6.912977877077271, subsample=0.6549443585980128; total time=   1.2s\n",
            "[CV] END colsample_bytree=0.7122486851695402, learning_rate=0.039292687475378986, max_depth=9, n_estimators=230, scale_pos_weight=8.607850486168974, subsample=0.7122554395138992; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.7122486851695402, learning_rate=0.039292687475378986, max_depth=9, n_estimators=230, scale_pos_weight=8.607850486168974, subsample=0.7122554395138992; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.7122486851695402, learning_rate=0.039292687475378986, max_depth=9, n_estimators=230, scale_pos_weight=8.607850486168974, subsample=0.7122554395138992; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.7541934359909122, learning_rate=0.05037955963643908, max_depth=3, n_estimators=306, scale_pos_weight=5.275410183585496, subsample=0.605083825348819; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.7541934359909122, learning_rate=0.05037955963643908, max_depth=3, n_estimators=306, scale_pos_weight=5.275410183585496, subsample=0.605083825348819; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.7541934359909122, learning_rate=0.05037955963643908, max_depth=3, n_estimators=306, scale_pos_weight=5.275410183585496, subsample=0.605083825348819; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.6215782853986609, learning_rate=0.004142918568673425, max_depth=9, n_estimators=340, scale_pos_weight=4.143559810763267, subsample=0.7017141382329406; total time=   1.1s\n",
            "[CV] END colsample_bytree=0.6215782853986609, learning_rate=0.004142918568673425, max_depth=9, n_estimators=340, scale_pos_weight=4.143559810763267, subsample=0.7017141382329406; total time=   1.0s\n",
            "[CV] END colsample_bytree=0.6215782853986609, learning_rate=0.004142918568673425, max_depth=9, n_estimators=340, scale_pos_weight=4.143559810763267, subsample=0.7017141382329406; total time=   1.0s\n",
            "[CV] END colsample_bytree=0.7815132947852186, learning_rate=0.025929222914887497, max_depth=7, n_estimators=242, scale_pos_weight=8.555511385430487, subsample=0.6457596330983245; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.7815132947852186, learning_rate=0.025929222914887497, max_depth=7, n_estimators=242, scale_pos_weight=8.555511385430487, subsample=0.6457596330983245; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.7815132947852186, learning_rate=0.025929222914887497, max_depth=7, n_estimators=242, scale_pos_weight=8.555511385430487, subsample=0.6457596330983245; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.6153959819657586, learning_rate=0.029975145291376806, max_depth=8, n_estimators=383, scale_pos_weight=10.29697652342573, subsample=0.7616240759128834; total time=   0.8s\n",
            "[CV] END colsample_bytree=0.6153959819657586, learning_rate=0.029975145291376806, max_depth=8, n_estimators=383, scale_pos_weight=10.29697652342573, subsample=0.7616240759128834; total time=   0.8s\n",
            "[CV] END colsample_bytree=0.6153959819657586, learning_rate=0.029975145291376806, max_depth=8, n_estimators=383, scale_pos_weight=10.29697652342573, subsample=0.7616240759128834; total time=   0.8s\n",
            "[CV] END colsample_bytree=0.7266807513020846, learning_rate=0.08814605901877177, max_depth=6, n_estimators=207, scale_pos_weight=2.865700588860358, subsample=0.7785117996979956; total time=   1.1s\n",
            "[CV] END colsample_bytree=0.7266807513020846, learning_rate=0.08814605901877177, max_depth=6, n_estimators=207, scale_pos_weight=2.865700588860358, subsample=0.7785117996979956; total time=   1.1s\n",
            "[CV] END colsample_bytree=0.7266807513020846, learning_rate=0.08814605901877177, max_depth=6, n_estimators=207, scale_pos_weight=2.865700588860358, subsample=0.7785117996979956; total time=   1.7s\n",
            "[CV] END colsample_bytree=0.7078684483831301, learning_rate=0.08174401551640625, max_depth=6, n_estimators=330, scale_pos_weight=10.06828441545754, subsample=0.654426449876927; total time=   1.8s\n",
            "[CV] END colsample_bytree=0.7078684483831301, learning_rate=0.08174401551640625, max_depth=6, n_estimators=330, scale_pos_weight=10.06828441545754, subsample=0.654426449876927; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.7078684483831301, learning_rate=0.08174401551640625, max_depth=6, n_estimators=330, scale_pos_weight=10.06828441545754, subsample=0.654426449876927; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.7295380241082725, learning_rate=0.001052037699531582, max_depth=7, n_estimators=332, scale_pos_weight=4.04781258158029, subsample=0.6329311706285883; total time=   0.9s\n",
            "[CV] END colsample_bytree=0.7295380241082725, learning_rate=0.001052037699531582, max_depth=7, n_estimators=332, scale_pos_weight=4.04781258158029, subsample=0.6329311706285883; total time=   0.9s\n",
            "[CV] END colsample_bytree=0.7295380241082725, learning_rate=0.001052037699531582, max_depth=7, n_estimators=332, scale_pos_weight=4.04781258158029, subsample=0.6329311706285883; total time=   0.9s\n",
            "[CV] END colsample_bytree=0.7068178838750884, learning_rate=0.04948299713589832, max_depth=3, n_estimators=406, scale_pos_weight=3.6941233379852148, subsample=0.6488251044495548; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.7068178838750884, learning_rate=0.04948299713589832, max_depth=3, n_estimators=406, scale_pos_weight=3.6941233379852148, subsample=0.6488251044495548; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.7068178838750884, learning_rate=0.04948299713589832, max_depth=3, n_estimators=406, scale_pos_weight=3.6941233379852148, subsample=0.6488251044495548; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.6336582084345861, learning_rate=0.022876421957307026, max_depth=3, n_estimators=279, scale_pos_weight=4.63629602379294, subsample=0.7943564165441921; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.6336582084345861, learning_rate=0.022876421957307026, max_depth=3, n_estimators=279, scale_pos_weight=4.63629602379294, subsample=0.7943564165441921; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.6336582084345861, learning_rate=0.022876421957307026, max_depth=3, n_estimators=279, scale_pos_weight=4.63629602379294, subsample=0.7943564165441921; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.7924894589884223, learning_rate=0.02617822958253642, max_depth=4, n_estimators=486, scale_pos_weight=4.008783098167696, subsample=0.6569680988754935; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.7924894589884223, learning_rate=0.02617822958253642, max_depth=4, n_estimators=486, scale_pos_weight=4.008783098167696, subsample=0.6569680988754935; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.7924894589884223, learning_rate=0.02617822958253642, max_depth=4, n_estimators=486, scale_pos_weight=4.008783098167696, subsample=0.6569680988754935; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.6073773894709066, learning_rate=0.06195643339798969, max_depth=4, n_estimators=319, scale_pos_weight=1.5147875124998935, subsample=0.6557292928473223; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.6073773894709066, learning_rate=0.06195643339798969, max_depth=4, n_estimators=319, scale_pos_weight=1.5147875124998935, subsample=0.6557292928473223; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.6073773894709066, learning_rate=0.06195643339798969, max_depth=4, n_estimators=319, scale_pos_weight=1.5147875124998935, subsample=0.6557292928473223; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.7816531771933307, learning_rate=0.024956189066697245, max_depth=4, n_estimators=152, scale_pos_weight=5.89452760277563, subsample=0.7971300908221202; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.7816531771933307, learning_rate=0.024956189066697245, max_depth=4, n_estimators=152, scale_pos_weight=5.89452760277563, subsample=0.7971300908221202; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.7816531771933307, learning_rate=0.024956189066697245, max_depth=4, n_estimators=152, scale_pos_weight=5.89452760277563, subsample=0.7971300908221202; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.6484110543023001, learning_rate=0.06821355474058786, max_depth=5, n_estimators=283, scale_pos_weight=3.3763754399239967, subsample=0.7456432697223719; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.6484110543023001, learning_rate=0.06821355474058786, max_depth=5, n_estimators=283, scale_pos_weight=3.3763754399239967, subsample=0.7456432697223719; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.6484110543023001, learning_rate=0.06821355474058786, max_depth=5, n_estimators=283, scale_pos_weight=3.3763754399239967, subsample=0.7456432697223719; total time=   1.7s\n",
            "[CV] END colsample_bytree=0.6735566265438506, learning_rate=0.06423058305935796, max_depth=8, n_estimators=494, scale_pos_weight=9.16431873219384, subsample=0.7596690249969102; total time=   3.6s\n",
            "[CV] END colsample_bytree=0.6735566265438506, learning_rate=0.06423058305935796, max_depth=8, n_estimators=494, scale_pos_weight=9.16431873219384, subsample=0.7596690249969102; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.6735566265438506, learning_rate=0.06423058305935796, max_depth=8, n_estimators=494, scale_pos_weight=9.16431873219384, subsample=0.7596690249969102; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.6301435087930859, learning_rate=0.05181987767407187, max_depth=7, n_estimators=358, scale_pos_weight=6.908929431882418, subsample=0.7355128723684565; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.6301435087930859, learning_rate=0.05181987767407187, max_depth=7, n_estimators=358, scale_pos_weight=6.908929431882418, subsample=0.7355128723684565; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.6301435087930859, learning_rate=0.05181987767407187, max_depth=7, n_estimators=358, scale_pos_weight=6.908929431882418, subsample=0.7355128723684565; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.6033175657855712, learning_rate=0.0522093058299281, max_depth=5, n_estimators=247, scale_pos_weight=7.451727904094499, subsample=0.6348732858009982; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.6033175657855712, learning_rate=0.0522093058299281, max_depth=5, n_estimators=247, scale_pos_weight=7.451727904094499, subsample=0.6348732858009982; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.6033175657855712, learning_rate=0.0522093058299281, max_depth=5, n_estimators=247, scale_pos_weight=7.451727904094499, subsample=0.6348732858009982; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.7381875476204932, learning_rate=0.03967353463005374, max_depth=4, n_estimators=459, scale_pos_weight=2.3752094414599325, subsample=0.6682132702100517; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.7381875476204932, learning_rate=0.03967353463005374, max_depth=4, n_estimators=459, scale_pos_weight=2.3752094414599325, subsample=0.6682132702100517; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.7381875476204932, learning_rate=0.03967353463005374, max_depth=4, n_estimators=459, scale_pos_weight=2.3752094414599325, subsample=0.6682132702100517; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.6226947042481178, learning_rate=0.09346936182785628, max_depth=8, n_estimators=397, scale_pos_weight=3.579416277151556, subsample=0.7319968092068359; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.6226947042481178, learning_rate=0.09346936182785628, max_depth=8, n_estimators=397, scale_pos_weight=3.579416277151556, subsample=0.7319968092068359; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.6226947042481178, learning_rate=0.09346936182785628, max_depth=8, n_estimators=397, scale_pos_weight=3.579416277151556, subsample=0.7319968092068359; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.7634444400402431, learning_rate=0.05652008115994624, max_depth=6, n_estimators=468, scale_pos_weight=3.418522909004517, subsample=0.6186205535611798; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.7634444400402431, learning_rate=0.05652008115994624, max_depth=6, n_estimators=468, scale_pos_weight=3.418522909004517, subsample=0.6186205535611798; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.7634444400402431, learning_rate=0.05652008115994624, max_depth=6, n_estimators=468, scale_pos_weight=3.418522909004517, subsample=0.6186205535611798; total time=   0.5s\n",
            "[CV] END colsample_bytree=0.7794431515906654, learning_rate=0.09104180571633305, max_depth=5, n_estimators=108, scale_pos_weight=3.7887135259218185, subsample=0.7400715659945543; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.7794431515906654, learning_rate=0.09104180571633305, max_depth=5, n_estimators=108, scale_pos_weight=3.7887135259218185, subsample=0.7400715659945543; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.7794431515906654, learning_rate=0.09104180571633305, max_depth=5, n_estimators=108, scale_pos_weight=3.7887135259218185, subsample=0.7400715659945543; total time=   0.2s\n",
            "[CV] END colsample_bytree=0.7693322284476611, learning_rate=0.08663242918780925, max_depth=8, n_estimators=219, scale_pos_weight=9.877700987609598, subsample=0.7701856897535025; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.7693322284476611, learning_rate=0.08663242918780925, max_depth=8, n_estimators=219, scale_pos_weight=9.877700987609598, subsample=0.7701856897535025; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.7693322284476611, learning_rate=0.08663242918780925, max_depth=8, n_estimators=219, scale_pos_weight=9.877700987609598, subsample=0.7701856897535025; total time=   0.4s\n",
            "[CV] END colsample_bytree=0.7871269988441895, learning_rate=0.07953406511139437, max_depth=6, n_estimators=353, scale_pos_weight=1.0919705161662965, subsample=0.6202943085732064; total time=   1.7s\n",
            "[CV] END colsample_bytree=0.7871269988441895, learning_rate=0.07953406511139437, max_depth=6, n_estimators=353, scale_pos_weight=1.0919705161662965, subsample=0.6202943085732064; total time=   1.9s\n",
            "[CV] END colsample_bytree=0.7871269988441895, learning_rate=0.07953406511139437, max_depth=6, n_estimators=353, scale_pos_weight=1.0919705161662965, subsample=0.6202943085732064; total time=   2.1s\n",
            "[CV] END colsample_bytree=0.7327003538216111, learning_rate=0.0015061583846218687, max_depth=8, n_estimators=437, scale_pos_weight=5.856137535862266, subsample=0.6896848285972494; total time=   1.5s\n",
            "[CV] END colsample_bytree=0.7327003538216111, learning_rate=0.0015061583846218687, max_depth=8, n_estimators=437, scale_pos_weight=5.856137535862266, subsample=0.6896848285972494; total time=   1.5s\n",
            "[CV] END colsample_bytree=0.7327003538216111, learning_rate=0.0015061583846218687, max_depth=8, n_estimators=437, scale_pos_weight=5.856137535862266, subsample=0.6896848285972494; total time=   1.5s\n",
            "[CV] END colsample_bytree=0.7988914925221642, learning_rate=0.018592525267734538, max_depth=6, n_estimators=388, scale_pos_weight=5.938937151834346, subsample=0.6357645418442658; total time=   0.9s\n",
            "[CV] END colsample_bytree=0.7988914925221642, learning_rate=0.018592525267734538, max_depth=6, n_estimators=388, scale_pos_weight=5.938937151834346, subsample=0.6357645418442658; total time=   0.8s\n",
            "[CV] END colsample_bytree=0.7988914925221642, learning_rate=0.018592525267734538, max_depth=6, n_estimators=388, scale_pos_weight=5.938937151834346, subsample=0.6357645418442658; total time=   0.9s\n",
            "[CV] END colsample_bytree=0.673293756916572, learning_rate=0.07541705230565623, max_depth=5, n_estimators=227, scale_pos_weight=6.683086033354716, subsample=0.6187349535656185; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.673293756916572, learning_rate=0.07541705230565623, max_depth=5, n_estimators=227, scale_pos_weight=6.683086033354716, subsample=0.6187349535656185; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.673293756916572, learning_rate=0.07541705230565623, max_depth=5, n_estimators=227, scale_pos_weight=6.683086033354716, subsample=0.6187349535656185; total time=   0.3s\n",
            "[CV] END colsample_bytree=0.6735431606118867, learning_rate=0.027520236768172546, max_depth=8, n_estimators=257, scale_pos_weight=10.730105547524456, subsample=0.6786195449333521; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.6735431606118867, learning_rate=0.027520236768172546, max_depth=8, n_estimators=257, scale_pos_weight=10.730105547524456, subsample=0.6786195449333521; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.6735431606118867, learning_rate=0.027520236768172546, max_depth=8, n_estimators=257, scale_pos_weight=10.730105547524456, subsample=0.6786195449333521; total time=   0.8s\n",
            "[CV] END colsample_bytree=0.7784093110354227, learning_rate=0.06411386259972629, max_depth=4, n_estimators=376, scale_pos_weight=6.026370931051921, subsample=0.7153807769252718; total time=   1.9s\n",
            "[CV] END colsample_bytree=0.7784093110354227, learning_rate=0.06411386259972629, max_depth=4, n_estimators=376, scale_pos_weight=6.026370931051921, subsample=0.7153807769252718; total time=   1.9s\n",
            "[CV] END colsample_bytree=0.7784093110354227, learning_rate=0.06411386259972629, max_depth=4, n_estimators=376, scale_pos_weight=6.026370931051921, subsample=0.7153807769252718; total time=   2.0s\n",
            "[CV] END colsample_bytree=0.6985035387637728, learning_rate=0.020524298779804453, max_depth=7, n_estimators=403, scale_pos_weight=3.807723624408558, subsample=0.6048631932862908; total time=   0.8s\n",
            "[CV] END colsample_bytree=0.6985035387637728, learning_rate=0.020524298779804453, max_depth=7, n_estimators=403, scale_pos_weight=3.807723624408558, subsample=0.6048631932862908; total time=   0.8s\n",
            "[CV] END colsample_bytree=0.6985035387637728, learning_rate=0.020524298779804453, max_depth=7, n_estimators=403, scale_pos_weight=3.807723624408558, subsample=0.6048631932862908; total time=   0.8s\n",
            "[CV] END colsample_bytree=0.7290944591814336, learning_rate=0.018711067940704897, max_depth=6, n_estimators=257, scale_pos_weight=10.539285770025874, subsample=0.7829728780440897; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.7290944591814336, learning_rate=0.018711067940704897, max_depth=6, n_estimators=257, scale_pos_weight=10.539285770025874, subsample=0.7829728780440897; total time=   0.7s\n",
            "[CV] END colsample_bytree=0.7290944591814336, learning_rate=0.018711067940704897, max_depth=6, n_estimators=257, scale_pos_weight=10.539285770025874, subsample=0.7829728780440897; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.6740317400510889, learning_rate=0.002545661652886743, max_depth=7, n_estimators=401, scale_pos_weight=10.666548190436696, subsample=0.7927239954178505; total time=   1.3s\n",
            "[CV] END colsample_bytree=0.6740317400510889, learning_rate=0.002545661652886743, max_depth=7, n_estimators=401, scale_pos_weight=10.666548190436696, subsample=0.7927239954178505; total time=   1.4s\n",
            "[CV] END colsample_bytree=0.6740317400510889, learning_rate=0.002545661652886743, max_depth=7, n_estimators=401, scale_pos_weight=10.666548190436696, subsample=0.7927239954178505; total time=   1.3s\n",
            "[CV] END colsample_bytree=0.770601891093472, learning_rate=0.03044488920695857, max_depth=7, n_estimators=260, scale_pos_weight=4.169220051562776, subsample=0.6338985493372185; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.770601891093472, learning_rate=0.03044488920695857, max_depth=7, n_estimators=260, scale_pos_weight=4.169220051562776, subsample=0.6338985493372185; total time=   0.6s\n",
            "[CV] END colsample_bytree=0.770601891093472, learning_rate=0.03044488920695857, max_depth=7, n_estimators=260, scale_pos_weight=4.169220051562776, subsample=0.6338985493372185; total time=   2.0s\n",
            "[CV] END colsample_bytree=0.71136025249167, learning_rate=0.0946154774160781, max_depth=4, n_estimators=422, scale_pos_weight=6.700611700893649, subsample=0.6194352987541537; total time=   2.1s\n",
            "[CV] END colsample_bytree=0.71136025249167, learning_rate=0.0946154774160781, max_depth=4, n_estimators=422, scale_pos_weight=6.700611700893649, subsample=0.6194352987541537; total time=   1.9s\n",
            "[CV] END colsample_bytree=0.71136025249167, learning_rate=0.0946154774160781, max_depth=4, n_estimators=422, scale_pos_weight=6.700611700893649, subsample=0.6194352987541537; total time=   0.4s\n",
            "Best parameters found:  {'colsample_bytree': 0.673293756916572, 'learning_rate': 0.07541705230565623, 'max_depth': 5, 'n_estimators': 227, 'scale_pos_weight': 6.683086033354716, 'subsample': 0.6187349535656185}\n",
            "Starting new iteration...\n",
            "Added 494 pseudo-labeled samples.\n",
            "Starting new iteration...\n",
            "Added 267 pseudo-labeled samples.\n",
            "Starting new iteration...\n",
            "Added 104 pseudo-labeled samples.\n",
            "Starting new iteration...\n",
            "Added 55 pseudo-labeled samples.\n",
            "Starting new iteration...\n",
            "Added 24 pseudo-labeled samples.\n",
            "Starting new iteration...\n",
            "Added 13 pseudo-labeled samples.\n",
            "Starting new iteration...\n",
            "Added 14 pseudo-labeled samples.\n",
            "Starting new iteration...\n",
            "Added 10 pseudo-labeled samples.\n",
            "Starting new iteration...\n",
            "Added 5 pseudo-labeled samples.\n",
            "Starting new iteration...\n",
            "Added 4 pseudo-labeled samples.\n",
            "Starting new iteration...\n",
            "Added 9 pseudo-labeled samples.\n",
            "Starting new iteration...\n",
            "Added 4 pseudo-labeled samples.\n",
            "Starting new iteration...\n",
            "Added 2 pseudo-labeled samples.\n",
            "Starting new iteration...\n",
            "Added 3 pseudo-labeled samples.\n",
            "Starting new iteration...\n",
            "Added 1 pseudo-labeled samples.\n",
            "Starting new iteration...\n",
            "Added 3 pseudo-labeled samples.\n",
            "Starting new iteration...\n",
            "Added 1 pseudo-labeled samples.\n",
            "Starting new iteration...\n",
            "No confident predictions left. Stopping...\n",
            "Total pseudo-labeled data added: 1013\n",
            "Combined labeled data saved to combined_labeled_data_xgboost_tuned.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Co-Training"
      ],
      "metadata": {
        "id": "zBty86Ch5Cpc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.autograd import Variable\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "metadata": {
        "id": "PwoJgoVg5LQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VAE(nn.Module):\n",
        "    def __init__(self, input_dim, latent_dim):\n",
        "        super(VAE, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 400)\n",
        "        self.fc21 = nn.Linear(400, latent_dim)  # Mean of latent variable\n",
        "        self.fc22 = nn.Linear(400, latent_dim)  # Log-variance of latent variable\n",
        "        self.fc3 = nn.Linear(latent_dim, 400)\n",
        "        self.fc4 = nn.Linear(400, input_dim)\n",
        "\n",
        "    def encode(self, x):\n",
        "        h1 = F.relu(self.fc1(x))\n",
        "        return self.fc21(h1), self.fc22(h1)  # Returns mean and log-variance\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5*logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps*std\n",
        "\n",
        "    def decode(self, z):\n",
        "        h3 = F.relu(self.fc3(z))\n",
        "        return torch.sigmoid(self.fc4(h3))  # Sigmoid to squash output between 0 and 1\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decode(z), mu, logvar\n",
        "\n",
        "    def loss_function(self, recon_x, x, mu, logvar):\n",
        "        BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
        "        # KL divergence between the learned distribution and a unit Gaussian\n",
        "        MSE = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "        return BCE + MSE"
      ],
      "metadata": {
        "id": "_7jMalplIV6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassifierWithVariationalDropout(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, dropout_rate=0.5):\n",
        "        super(ClassifierWithVariationalDropout, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 128)\n",
        "        self.fc2 = nn.Linear(128, output_dim)\n",
        "        self.dropout_rate = torch.nn.Parameter(torch.tensor([dropout_rate]))  # Learnable dropout rate\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, p=self.dropout_rate.item(), training=self.training)\n",
        "        return self.fc2(x)\n"
      ],
      "metadata": {
        "id": "R4bRgZheIZFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### DATA PREPARATION ####\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Normalize gene and clinical data using MinMaxScaler\n",
        "scaler_gene = MinMaxScaler()\n",
        "X_gene_scaled = scaler_gene.fit_transform(x_train)  # Normalize labeled gene data\n",
        "X_gene_ul_scaled = scaler_gene.transform(x_ul)                # Unlabeled data\n",
        "\n",
        "scaler_clinical = MinMaxScaler()\n",
        "X_clinical_scaled = scaler_clinical.fit_transform(c_train)  # Normalize labeled clinical data\n",
        "\n",
        "# Convert labels (True/False) to integers (1/0)\n",
        "Y_train = (y_train == 'True').astype(int)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_gene_tensor = torch.tensor(X_gene_scaled, dtype=torch.float32)\n",
        "X_clinical_tensor = torch.tensor(X_clinical_scaled, dtype=torch.float32)\n",
        "Y_tensor = torch.tensor(Y_train, dtype=torch.long)  # Use long for classification targets\n",
        "\n",
        "# Split labeled data into training and testing sets\n",
        "X_gene_train, X_gene_test, Y_train, Y_test = train_test_split(X_gene_tensor, Y_tensor, test_size=0.2, random_state=42)\n",
        "X_clinical_train, X_clinical_test = train_test_split(X_clinical_tensor, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create DataLoaders for training and validation\n",
        "train_data_gene = TensorDataset(X_gene_train, Y_train)\n",
        "test_data_gene = TensorDataset(X_gene_test, Y_test)\n",
        "\n",
        "train_data_clinical = TensorDataset(X_clinical_train, Y_train)\n",
        "test_data_clinical = TensorDataset(X_clinical_test, Y_test)\n",
        "\n",
        "train_loader_gene = DataLoader(train_data_gene, batch_size=32, shuffle=True)\n",
        "test_loader_gene = DataLoader(test_data_gene, batch_size=32, shuffle=False)\n",
        "\n",
        "train_loader_clinical = DataLoader(train_data_clinical, batch_size=32, shuffle=True)\n",
        "test_loader_clinical = DataLoader(test_data_clinical, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "id": "tISk4IFxgpVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### TRAINING ####\n",
        "\n",
        "# Initialize models\n",
        "vae = VAE(input_dim=X_gene_train.shape[1], latent_dim=10)  # VAE for gene data\n",
        "classifier_gene = ClassifierWithVariationalDropout(input_dim=10, output_dim=2)  # Classifier for VAE latent space\n",
        "classifier_clinical = ClassifierWithVariationalDropout(input_dim=X_clinical_train.shape[1], output_dim=2)  # Classifier for clinical data\n",
        "\n",
        "# Loss functions and optimizers\n",
        "vae_optimizer = torch.optim.Adam(list(vae.parameters()) + list(classifier_gene.parameters()), lr=0.1)\n",
        "classifier_optimizer = torch.optim.Adam(classifier_clinical.parameters(), lr=0.0001)\n",
        "\n",
        "\n",
        "# Training Loop for VAE + Classifier on Gene Data\n",
        "for epoch in range(100):  # Adjust epochs as needed\n",
        "    vae.train()\n",
        "    classifier_gene.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader_gene):\n",
        "        vae_optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass through VAE and classifier\n",
        "        recon_batch, mu, logvar = vae(data)\n",
        "        output = classifier_gene(mu)  # Use latent space representation\n",
        "\n",
        "        # Compute VAE loss and classification loss\n",
        "        vae_loss = vae.loss_function(recon_batch, data, mu, logvar)\n",
        "        classification_loss = torch.nn.functional.cross_entropy(output, target)\n",
        "\n",
        "        # Total loss\n",
        "        loss = vae_loss + classification_loss\n",
        "        loss.backward()\n",
        "        vae_optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch} | VAE Loss: {vae_loss.item()} | Classification Loss: {classification_loss.item()}\")\n",
        "\n",
        "print('##---------------------------------------------------------##')\n",
        "\n",
        "# Training Loop for Classifier on Clinical Data\n",
        "for epoch in range(100):  # Adjust epochs as needed\n",
        "    classifier_clinical.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader_clinical):\n",
        "        classifier_optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass through classifier\n",
        "        output = classifier_clinical(data)\n",
        "\n",
        "        # Compute classification loss\n",
        "        classification_loss = torch.nn.functional.cross_entropy(output, target)\n",
        "\n",
        "        classification_loss.backward()\n",
        "        classifier_optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch} | Clinical Classification Loss: {classification_loss.item()}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M01Q6fOAIcWc",
        "outputId": "654f8726-7c74-499f-ec7c-7f8143217a53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 | VAE Loss: 1121.533447265625 | Classification Loss: 0.0\n",
            "Epoch 1 | VAE Loss: 963.0816040039062 | Classification Loss: 0.0\n",
            "Epoch 2 | VAE Loss: 1478.345947265625 | Classification Loss: 0.0\n",
            "Epoch 3 | VAE Loss: 1292.28125 | Classification Loss: 0.0\n",
            "Epoch 4 | VAE Loss: 899.00341796875 | Classification Loss: 0.0\n",
            "Epoch 5 | VAE Loss: 819.0283813476562 | Classification Loss: 0.0\n",
            "Epoch 6 | VAE Loss: 771.4208374023438 | Classification Loss: 0.0\n",
            "Epoch 7 | VAE Loss: 523.0353393554688 | Classification Loss: 0.0\n",
            "Epoch 8 | VAE Loss: 350.8897705078125 | Classification Loss: 0.0\n",
            "Epoch 9 | VAE Loss: 298.42315673828125 | Classification Loss: 0.0\n",
            "Epoch 10 | VAE Loss: 315.5010681152344 | Classification Loss: 0.0\n",
            "Epoch 11 | VAE Loss: 749.5999755859375 | Classification Loss: 0.0\n",
            "Epoch 12 | VAE Loss: 687.9379272460938 | Classification Loss: 0.0\n",
            "Epoch 13 | VAE Loss: 602.1236572265625 | Classification Loss: 0.0\n",
            "Epoch 14 | VAE Loss: 472.87994384765625 | Classification Loss: 0.0\n",
            "Epoch 15 | VAE Loss: 374.14471435546875 | Classification Loss: 0.0\n",
            "Epoch 16 | VAE Loss: 937.9301147460938 | Classification Loss: 0.0\n",
            "Epoch 17 | VAE Loss: 401.3939514160156 | Classification Loss: 0.0\n",
            "Epoch 18 | VAE Loss: 375.0379638671875 | Classification Loss: 0.0\n",
            "Epoch 19 | VAE Loss: 397.80755615234375 | Classification Loss: 0.0\n",
            "Epoch 20 | VAE Loss: 397.4534912109375 | Classification Loss: 0.0\n",
            "Epoch 21 | VAE Loss: 328.1979675292969 | Classification Loss: 0.0\n",
            "Epoch 22 | VAE Loss: 293.8639221191406 | Classification Loss: 0.0\n",
            "Epoch 23 | VAE Loss: 314.25146484375 | Classification Loss: 0.0\n",
            "Epoch 24 | VAE Loss: 278.0353698730469 | Classification Loss: 0.0\n",
            "Epoch 25 | VAE Loss: 287.36968994140625 | Classification Loss: 0.0\n",
            "Epoch 26 | VAE Loss: 316.92767333984375 | Classification Loss: 0.0\n",
            "Epoch 27 | VAE Loss: 310.2543640136719 | Classification Loss: 0.0\n",
            "Epoch 28 | VAE Loss: 278.2579345703125 | Classification Loss: 0.0\n",
            "Epoch 29 | VAE Loss: 271.23773193359375 | Classification Loss: 0.0\n",
            "Epoch 30 | VAE Loss: 284.28839111328125 | Classification Loss: 0.0\n",
            "Epoch 31 | VAE Loss: 264.8668518066406 | Classification Loss: 0.0\n",
            "Epoch 32 | VAE Loss: 269.5000305175781 | Classification Loss: 0.0\n",
            "Epoch 33 | VAE Loss: 265.6475830078125 | Classification Loss: 0.0\n",
            "Epoch 34 | VAE Loss: 263.0876159667969 | Classification Loss: 0.0\n",
            "Epoch 35 | VAE Loss: 259.5146484375 | Classification Loss: 0.0\n",
            "Epoch 36 | VAE Loss: 258.50341796875 | Classification Loss: 0.0\n",
            "Epoch 37 | VAE Loss: 259.3909912109375 | Classification Loss: 0.0\n",
            "Epoch 38 | VAE Loss: 258.1694641113281 | Classification Loss: 0.0\n",
            "Epoch 39 | VAE Loss: 261.0873107910156 | Classification Loss: 0.0\n",
            "Epoch 40 | VAE Loss: 258.79498291015625 | Classification Loss: 0.0\n",
            "Epoch 41 | VAE Loss: 258.1961669921875 | Classification Loss: 0.0\n",
            "Epoch 42 | VAE Loss: 261.55438232421875 | Classification Loss: 0.0\n",
            "Epoch 43 | VAE Loss: 258.8401184082031 | Classification Loss: 0.0\n",
            "Epoch 44 | VAE Loss: 258.6800842285156 | Classification Loss: 0.0\n",
            "Epoch 45 | VAE Loss: 259.6057434082031 | Classification Loss: 0.0\n",
            "Epoch 46 | VAE Loss: 259.49072265625 | Classification Loss: 0.0\n",
            "Epoch 47 | VAE Loss: 261.42071533203125 | Classification Loss: 0.0\n",
            "Epoch 48 | VAE Loss: 258.27911376953125 | Classification Loss: 0.0\n",
            "Epoch 49 | VAE Loss: 259.72210693359375 | Classification Loss: 0.0\n",
            "Epoch 50 | VAE Loss: 260.9978332519531 | Classification Loss: 0.0\n",
            "Epoch 51 | VAE Loss: 259.0782775878906 | Classification Loss: 0.0\n",
            "Epoch 52 | VAE Loss: 258.9190979003906 | Classification Loss: 0.0\n",
            "Epoch 53 | VAE Loss: 260.6502990722656 | Classification Loss: 0.0\n",
            "Epoch 54 | VAE Loss: 256.8946838378906 | Classification Loss: 0.0\n",
            "Epoch 55 | VAE Loss: 257.3929748535156 | Classification Loss: 0.0\n",
            "Epoch 56 | VAE Loss: 258.5143737792969 | Classification Loss: 0.0\n",
            "Epoch 57 | VAE Loss: 257.4735412597656 | Classification Loss: 0.0\n",
            "Epoch 58 | VAE Loss: 257.4132080078125 | Classification Loss: 0.0\n",
            "Epoch 59 | VAE Loss: 260.1673583984375 | Classification Loss: 0.0\n",
            "Epoch 60 | VAE Loss: 257.8996276855469 | Classification Loss: 0.0\n",
            "Epoch 61 | VAE Loss: 259.0160217285156 | Classification Loss: 0.0\n",
            "Epoch 62 | VAE Loss: 257.319580078125 | Classification Loss: 0.0\n",
            "Epoch 63 | VAE Loss: 258.53955078125 | Classification Loss: 0.0\n",
            "Epoch 64 | VAE Loss: 260.91827392578125 | Classification Loss: 0.0\n",
            "Epoch 65 | VAE Loss: 257.9657897949219 | Classification Loss: 0.0\n",
            "Epoch 66 | VAE Loss: 260.8412780761719 | Classification Loss: 0.0\n",
            "Epoch 67 | VAE Loss: 255.37362670898438 | Classification Loss: 0.0\n",
            "Epoch 68 | VAE Loss: 263.3577575683594 | Classification Loss: 0.0\n",
            "Epoch 69 | VAE Loss: 258.55914306640625 | Classification Loss: 0.0\n",
            "Epoch 70 | VAE Loss: 257.2968444824219 | Classification Loss: 0.0\n",
            "Epoch 71 | VAE Loss: 258.95654296875 | Classification Loss: 0.0\n",
            "Epoch 72 | VAE Loss: 256.4480895996094 | Classification Loss: 0.0\n",
            "Epoch 73 | VAE Loss: 261.4436950683594 | Classification Loss: 0.0\n",
            "Epoch 74 | VAE Loss: 257.9643859863281 | Classification Loss: 0.0\n",
            "Epoch 75 | VAE Loss: 257.44366455078125 | Classification Loss: 0.0\n",
            "Epoch 76 | VAE Loss: 257.4886779785156 | Classification Loss: 0.0\n",
            "Epoch 77 | VAE Loss: 261.0364074707031 | Classification Loss: 0.0\n",
            "Epoch 78 | VAE Loss: 258.3114013671875 | Classification Loss: 0.0\n",
            "Epoch 79 | VAE Loss: 258.49188232421875 | Classification Loss: 0.0\n",
            "Epoch 80 | VAE Loss: 260.2555236816406 | Classification Loss: 0.0\n",
            "Epoch 81 | VAE Loss: 256.6293029785156 | Classification Loss: 0.0\n",
            "Epoch 82 | VAE Loss: 260.4599304199219 | Classification Loss: 0.0\n",
            "Epoch 83 | VAE Loss: 256.3936462402344 | Classification Loss: 0.0\n",
            "Epoch 84 | VAE Loss: 258.6105651855469 | Classification Loss: 0.0\n",
            "Epoch 85 | VAE Loss: 259.6563415527344 | Classification Loss: 0.0\n",
            "Epoch 86 | VAE Loss: 258.17047119140625 | Classification Loss: 0.0\n",
            "Epoch 87 | VAE Loss: 260.69384765625 | Classification Loss: 0.0\n",
            "Epoch 88 | VAE Loss: 260.4607238769531 | Classification Loss: 0.0\n",
            "Epoch 89 | VAE Loss: 261.0035400390625 | Classification Loss: 0.0\n",
            "Epoch 90 | VAE Loss: 257.6528015136719 | Classification Loss: 0.0\n",
            "Epoch 91 | VAE Loss: 259.18609619140625 | Classification Loss: 0.0\n",
            "Epoch 92 | VAE Loss: 253.83335876464844 | Classification Loss: 0.0\n",
            "Epoch 93 | VAE Loss: 258.8448181152344 | Classification Loss: 0.0\n",
            "Epoch 94 | VAE Loss: 259.8407287597656 | Classification Loss: 0.0\n",
            "Epoch 95 | VAE Loss: 258.992919921875 | Classification Loss: 0.0\n",
            "Epoch 96 | VAE Loss: 262.1825256347656 | Classification Loss: 0.0\n",
            "Epoch 97 | VAE Loss: 258.609130859375 | Classification Loss: 0.0\n",
            "Epoch 98 | VAE Loss: 256.9396057128906 | Classification Loss: 0.0\n",
            "Epoch 99 | VAE Loss: 257.1072082519531 | Classification Loss: 0.0\n",
            "##---------------------------------------------------------##\n",
            "Epoch 0 | Clinical Classification Loss: 0.8766263723373413\n",
            "Epoch 1 | Clinical Classification Loss: 0.8353144526481628\n",
            "Epoch 2 | Clinical Classification Loss: 0.785819411277771\n",
            "Epoch 3 | Clinical Classification Loss: 0.6818218231201172\n",
            "Epoch 4 | Clinical Classification Loss: 0.7220350503921509\n",
            "Epoch 5 | Clinical Classification Loss: 0.6374942064285278\n",
            "Epoch 6 | Clinical Classification Loss: 0.6190637350082397\n",
            "Epoch 7 | Clinical Classification Loss: 0.6245428323745728\n",
            "Epoch 8 | Clinical Classification Loss: 0.5347668528556824\n",
            "Epoch 9 | Clinical Classification Loss: 0.47971826791763306\n",
            "Epoch 10 | Clinical Classification Loss: 0.4798188805580139\n",
            "Epoch 11 | Clinical Classification Loss: 0.45243892073631287\n",
            "Epoch 12 | Clinical Classification Loss: 0.46492934226989746\n",
            "Epoch 13 | Clinical Classification Loss: 0.39304691553115845\n",
            "Epoch 14 | Clinical Classification Loss: 0.43648314476013184\n",
            "Epoch 15 | Clinical Classification Loss: 0.37396976351737976\n",
            "Epoch 16 | Clinical Classification Loss: 0.3268654942512512\n",
            "Epoch 17 | Clinical Classification Loss: 0.3175543248653412\n",
            "Epoch 18 | Clinical Classification Loss: 0.3658387064933777\n",
            "Epoch 19 | Clinical Classification Loss: 0.28382372856140137\n",
            "Epoch 20 | Clinical Classification Loss: 0.2512471675872803\n",
            "Epoch 21 | Clinical Classification Loss: 0.26217585802078247\n",
            "Epoch 22 | Clinical Classification Loss: 0.23923084139823914\n",
            "Epoch 23 | Clinical Classification Loss: 0.2844129502773285\n",
            "Epoch 24 | Clinical Classification Loss: 0.21873632073402405\n",
            "Epoch 25 | Clinical Classification Loss: 0.20736877620220184\n",
            "Epoch 26 | Clinical Classification Loss: 0.20659542083740234\n",
            "Epoch 27 | Clinical Classification Loss: 0.17611007392406464\n",
            "Epoch 28 | Clinical Classification Loss: 0.14994975924491882\n",
            "Epoch 29 | Clinical Classification Loss: 0.1782732605934143\n",
            "Epoch 30 | Clinical Classification Loss: 0.14712785184383392\n",
            "Epoch 31 | Clinical Classification Loss: 0.1606287807226181\n",
            "Epoch 32 | Clinical Classification Loss: 0.16131646931171417\n",
            "Epoch 33 | Clinical Classification Loss: 0.13334618508815765\n",
            "Epoch 34 | Clinical Classification Loss: 0.12960085272789001\n",
            "Epoch 35 | Clinical Classification Loss: 0.09203805029392242\n",
            "Epoch 36 | Clinical Classification Loss: 0.09288166463375092\n",
            "Epoch 37 | Clinical Classification Loss: 0.09662120044231415\n",
            "Epoch 38 | Clinical Classification Loss: 0.11883624643087387\n",
            "Epoch 39 | Clinical Classification Loss: 0.11174635589122772\n",
            "Epoch 40 | Clinical Classification Loss: 0.08897672593593597\n",
            "Epoch 41 | Clinical Classification Loss: 0.09858907014131546\n",
            "Epoch 42 | Clinical Classification Loss: 0.09436193853616714\n",
            "Epoch 43 | Clinical Classification Loss: 0.08570738136768341\n",
            "Epoch 44 | Clinical Classification Loss: 0.08514674752950668\n",
            "Epoch 45 | Clinical Classification Loss: 0.0823785811662674\n",
            "Epoch 46 | Clinical Classification Loss: 0.06139618903398514\n",
            "Epoch 47 | Clinical Classification Loss: 0.05901036411523819\n",
            "Epoch 48 | Clinical Classification Loss: 0.05535024404525757\n",
            "Epoch 49 | Clinical Classification Loss: 0.061671219766139984\n",
            "Epoch 50 | Clinical Classification Loss: 0.06323401629924774\n",
            "Epoch 51 | Clinical Classification Loss: 0.06459308415651321\n",
            "Epoch 52 | Clinical Classification Loss: 0.05273604393005371\n",
            "Epoch 53 | Clinical Classification Loss: 0.044129081070423126\n",
            "Epoch 54 | Clinical Classification Loss: 0.049419987946748734\n",
            "Epoch 55 | Clinical Classification Loss: 0.04324675351381302\n",
            "Epoch 56 | Clinical Classification Loss: 0.04975631460547447\n",
            "Epoch 57 | Clinical Classification Loss: 0.039065372198820114\n",
            "Epoch 58 | Clinical Classification Loss: 0.045907340943813324\n",
            "Epoch 59 | Clinical Classification Loss: 0.03028509020805359\n",
            "Epoch 60 | Clinical Classification Loss: 0.034709058701992035\n",
            "Epoch 61 | Clinical Classification Loss: 0.03196734935045242\n",
            "Epoch 62 | Clinical Classification Loss: 0.025366151705384254\n",
            "Epoch 63 | Clinical Classification Loss: 0.03370729088783264\n",
            "Epoch 64 | Clinical Classification Loss: 0.021185152232646942\n",
            "Epoch 65 | Clinical Classification Loss: 0.03125537559390068\n",
            "Epoch 66 | Clinical Classification Loss: 0.029263416305184364\n",
            "Epoch 67 | Clinical Classification Loss: 0.031105905771255493\n",
            "Epoch 68 | Clinical Classification Loss: 0.03608360141515732\n",
            "Epoch 69 | Clinical Classification Loss: 0.029780616983771324\n",
            "Epoch 70 | Clinical Classification Loss: 0.027452293783426285\n",
            "Epoch 71 | Clinical Classification Loss: 0.02838008664548397\n",
            "Epoch 72 | Clinical Classification Loss: 0.022871199995279312\n",
            "Epoch 73 | Clinical Classification Loss: 0.023684140294790268\n",
            "Epoch 74 | Clinical Classification Loss: 0.014099955558776855\n",
            "Epoch 75 | Clinical Classification Loss: 0.015487154945731163\n",
            "Epoch 76 | Clinical Classification Loss: 0.028104418888688087\n",
            "Epoch 77 | Clinical Classification Loss: 0.01833023875951767\n",
            "Epoch 78 | Clinical Classification Loss: 0.019308697432279587\n",
            "Epoch 79 | Clinical Classification Loss: 0.014285845682024956\n",
            "Epoch 80 | Clinical Classification Loss: 0.01915092021226883\n",
            "Epoch 81 | Clinical Classification Loss: 0.012306932359933853\n",
            "Epoch 82 | Clinical Classification Loss: 0.013245835900306702\n",
            "Epoch 83 | Clinical Classification Loss: 0.012780104763805866\n",
            "Epoch 84 | Clinical Classification Loss: 0.01496527623385191\n",
            "Epoch 85 | Clinical Classification Loss: 0.013266315683722496\n",
            "Epoch 86 | Clinical Classification Loss: 0.017511216923594475\n",
            "Epoch 87 | Clinical Classification Loss: 0.020065467804670334\n",
            "Epoch 88 | Clinical Classification Loss: 0.011296140030026436\n",
            "Epoch 89 | Clinical Classification Loss: 0.011090929619967937\n",
            "Epoch 90 | Clinical Classification Loss: 0.015617976896464825\n",
            "Epoch 91 | Clinical Classification Loss: 0.010630739852786064\n",
            "Epoch 92 | Clinical Classification Loss: 0.011267177760601044\n",
            "Epoch 93 | Clinical Classification Loss: 0.00907077081501484\n",
            "Epoch 94 | Clinical Classification Loss: 0.011663850396871567\n",
            "Epoch 95 | Clinical Classification Loss: 0.005524204578250647\n",
            "Epoch 96 | Clinical Classification Loss: 0.0068893348798155785\n",
            "Epoch 97 | Clinical Classification Loss: 0.011811691336333752\n",
            "Epoch 98 | Clinical Classification Loss: 0.008031257428228855\n",
            "Epoch 99 | Clinical Classification Loss: 0.010029228404164314\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for pseudo-labeling\n",
        "def pseudo_labeling(model_gene, model_clinical, unlabeled_data_gene, unlabeled_data_clinical, threshold=0.8):\n",
        "    model_gene.eval()\n",
        "    model_clinical.eval()\n",
        "\n",
        "    # Pseudo-labeling for gene model\n",
        "    with torch.no_grad():\n",
        "        gene_preds = model_gene(unlabeled_data_gene)\n",
        "        confidence_gene, predicted_gene = torch.max(gene_preds, 1)\n",
        "        confident_gene_indices = confidence_gene > threshold\n",
        "\n",
        "    # Pseudo-labeling for clinical model\n",
        "    with torch.no_grad():\n",
        "        clinical_preds = model_clinical(unlabeled_data_clinical)\n",
        "        confidence_clinical, predicted_clinical = torch.max(clinical_preds, 1)\n",
        "        confident_clinical_indices = confidence_clinical > threshold\n",
        "\n",
        "    # Augment the labeled data with the confident pseudo-labels\n",
        "    pseudo_labeled_gene = unlabeled_data_gene[confident_gene_indices]\n",
        "    pseudo_labeled_clinical = unlabeled_data_clinical[confident_clinical_indices]\n",
        "\n",
        "    return pseudo_labeled_gene, pseudo_labeled_clinical\n"
      ],
      "metadata": {
        "id": "WTG7jjdXIeZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### other stuff"
      ],
      "metadata": {
        "id": "NpMpw5yQpolF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# # Self-training\n",
        "# confidence_threshold = 0.9\n",
        "\n",
        "# X_labeled = X_train.copy()\n",
        "# X_labeled = np.hstack((np.arange(1, X_labeled.shape[0] + 1).reshape(-1, 1), X_labeled)) # add the row number as first col (start from 1)\n",
        "# y_labeled = y_train_split.copy()\n",
        "\n",
        "# X_unlabeled = combine_features(x_ul, c_ul)\n",
        "# X_unlabeled = np.hstack((np.arange(X_labeled.shape[0] + 1, X_unlabeled.shape[0] + X_labeled.shape[0] + 1).reshape(-1, 1), X_unlabeled)) # add the row number as first col (following labeled data)\n",
        "\n",
        "# confidence_scores_labeled = np.ones(len(y_labeled))  # Confidence for labeled data is 1\n",
        "# pseudo_labels = []\n",
        "# confidence_scores_pseudo = []\n",
        "\n",
        "# total_added = 0  # Counter to track total number of pseudo-labeled data added\n",
        "\n",
        "# while True:\n",
        "#     print(\"Starting new iteration...\")\n",
        "\n",
        "#     # Train the model on the labeled dataset\n",
        "#     base_model.fit(X_labeled, y_labeled)\n",
        "\n",
        "#     # Predict probabilities on the unlabeled dataset\n",
        "#     probs = base_model.predict_proba(X_unlabeled)\n",
        "#     pseudo_labels = np.argmax(probs, axis=1)  # Predicted labels\n",
        "#     confidence_scores = np.max(probs, axis=1)  # Max probabilities\n",
        "\n",
        "#     # Select confident predictions\n",
        "#     confident_indices = np.where(confidence_scores >= confidence_threshold)[0]\n",
        "#     if len(confident_indices) == 0:\n",
        "#         print(\"No confident predictions left.\")\n",
        "\n",
        "#         #TODO: deal with these data somehow\n",
        "#         X_labeled = np.vstack((X_labeled, X_unlabeled))\n",
        "#         y_labeled = np.hstack((y_labeled, pseudo_labels))\n",
        "#         confidence_scores_labeled = np.hstack((confidence_scores_labeled, confidence_scores))\n",
        "\n",
        "#         break\n",
        "\n",
        "#     # Add confident predictions to the labeled dataset\n",
        "#     X_labeled = np.vstack((X_labeled, X_unlabeled[confident_indices]))\n",
        "#     y_labeled = np.hstack((y_labeled, pseudo_labels[confident_indices]))\n",
        "#     confidence_scores_labeled = np.hstack((confidence_scores_labeled, confidence_scores[confident_indices]))\n",
        "#     X_unlabeled = np.delete(X_unlabeled, confident_indices, axis=0)\n",
        "\n",
        "#     total_added += len(confident_indices)  # Update the total added counter\n",
        "\n",
        "#     print(f\"Added {len(confident_indices)} pseudo-labeled samples.\")\n",
        "\n",
        "# # Output the total number of pseudo-labeled data added\n",
        "# print(f\"Data: {X_labeled.shape}\")\n",
        "\n",
        "# # Combine original and pseudo-labeled data\n",
        "# # labeled_data = pd.DataFrame(np.hstack((X_train, y_train_split.reshape(-1, 1), np.ones((len(y_train_split), 1)))),\n",
        "# #                             columns=[*gene_name, *clinical_feature, 'Label', 'Confidence'])\n",
        "\n",
        "# # pseudo_labeled_data = pd.DataFrame(\n",
        "# #     np.hstack((X_labeled[len(X_train):], y_labeled[len(X_train):].reshape(-1, 1), confidence_scores_labeled[len(X_train):].reshape(-1, 1))),\n",
        "# #     columns=['ID', *gene_name, *clinical_feature, 'Label', 'Confidence']\n",
        "# # )\n",
        "\n",
        "# combined_data = pd.DataFrame(\n",
        "#     np.hstack((X_labeled, y_labeled.reshape(-1, 1), confidence_scores_labeled.reshape(-1, 1))),\n",
        "#     columns=['ID', *gene_name, *clinical_feature, 'Label', 'Confidence']\n",
        "# )\n",
        "# print('Combined Data:', combined_data.shape)\n",
        "\n",
        "# # Sort data by 'ID' column\n",
        "# combined_data = combined_data.sort_values(by='ID')\n",
        "# # Delete the 'ID' column\n",
        "# combined_data = combined_data.drop(columns=['ID'])\n",
        "\n",
        "# # Ensure labels are stored as 0/1\n",
        "# labeled_data['Label'] = labeled_data['Label'].astype(int)\n",
        "# pseudo_labeled_data['Label'] = pseudo_labeled_data['Label'].astype(int)\n",
        "\n",
        "# # Save to CSV\n",
        "# output_file = \"/content/drive/My Drive/AIIM/Final/pseudo_labeled_data_rf_full.csv\"\n",
        "# combined_data.to_csv(output_file, index=False)\n",
        "# print(f\"Combined labeled data saved to {output_file}\")"
      ],
      "metadata": {
        "id": "yc069JYMpnLJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}