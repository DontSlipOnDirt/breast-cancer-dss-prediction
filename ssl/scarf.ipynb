{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Prepare the SCARFLightning Module\n",
    "from ts3l.pl_modules import SCARFLightning\n",
    "from ts3l.utils.scarf_utils import SCARFDataset\n",
    "from ts3l.utils import TS3LDataModule\n",
    "from ts3l.utils.scarf_utils import SCARFConfig\n",
    "from ts3l.utils.embedding_utils import IdentityEmbeddingConfig\n",
    "from ts3l.utils.backbone_utils import MLPBackboneConfig\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DATA_PATH = \"../data/test_data.csv\"\n",
    "TRAIN_DATA_PATH = \"../data/train_data.csv\"\n",
    "UNLABELLED_DATA_PATH = \"../data/unlabelled_data.csv\"\n",
    "PSEUDO_LABELLED_DATA_PATH = \"../data/pseudo_labelled_scarf.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chemotherapy</th>\n",
       "      <th>Menopausal State</th>\n",
       "      <th>Radio Therapy</th>\n",
       "      <th>Hormone Therapy</th>\n",
       "      <th>Surgery-breast conserving</th>\n",
       "      <th>Surgery-mastectomy</th>\n",
       "      <th>Neoplasm Histologic Grade</th>\n",
       "      <th>Cellularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Chemotherapy  Menopausal State  Radio Therapy  Hormone Therapy  \\\n",
       "0               0                 1              1                1   \n",
       "1               0                 1              1                1   \n",
       "2               1                 1              1                0   \n",
       "3               0                 1              1                1   \n",
       "4               1                 1              1                0   \n",
       "..            ...               ...            ...              ...   \n",
       "112             0                 1              0                1   \n",
       "113             1                 0              0                1   \n",
       "114             0                 1              0                1   \n",
       "115             0                 1              1                1   \n",
       "116             1                 0              1                1   \n",
       "\n",
       "     Surgery-breast conserving  Surgery-mastectomy  Neoplasm Histologic Grade  \\\n",
       "0                            0                   1                          3   \n",
       "1                            0                   1                          2   \n",
       "2                            0                   1                          3   \n",
       "3                            0                   1                          3   \n",
       "4                            0                   1                          2   \n",
       "..                         ...                 ...                        ...   \n",
       "112                          0                   1                          3   \n",
       "113                          0                   1                          2   \n",
       "114                          0                   1                          3   \n",
       "115                          1                   0                          1   \n",
       "116                          1                   0                          3   \n",
       "\n",
       "     Cellularity  \n",
       "0            0.5  \n",
       "1            0.5  \n",
       "2            1.0  \n",
       "3            1.0  \n",
       "4            1.0  \n",
       "..           ...  \n",
       "112          0.5  \n",
       "113          0.5  \n",
       "114          1.0  \n",
       "115          0.5  \n",
       "116          0.5  \n",
       "\n",
       "[117 rows x 8 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(TEST_DATA_PATH)\n",
    "categorical_cols = ['Chemotherapy', 'Menopausal State', 'Radio Therapy',\n",
    "                            'Hormone Therapy', 'Surgery-breast conserving',\n",
    "                            'Surgery-mastectomy', 'Neoplasm Histologic Grade',\n",
    "                            'Cellularity']\n",
    "test_df[categorical_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframes(test_path, train_path, unlabelled_path, with_clinical=False):\n",
    "    # Load the data\n",
    "    test_df = pd.read_csv(test_path)\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    unlabelled_df = pd.read_csv(unlabelled_path)\n",
    "\n",
    "    # Drop the columns that are not needed\n",
    "    test_df = test_df.drop(columns=['DssTime', 'Event'])\n",
    "    train_df = train_df.drop(columns=['DssTime', 'Event'])\n",
    "\n",
    "    # Extract numerical and categorical columns\n",
    "    # Numerical cols: Gene + Age\n",
    "    numerical_cols = test_df.columns[:21].tolist()\n",
    "    # But also Size\n",
    "    numerical_cols.append('Size')\n",
    "    # Categorical cols: Clinical\n",
    "    categorical_cols = test_df.drop(columns=['Label', 'Size']).columns[21:].tolist()\n",
    "    if not with_clinical:\n",
    "        test_df = test_df.drop(columns=categorical_cols)\n",
    "        train_df = train_df.drop(columns=categorical_cols)\n",
    "        unlabelled_df = unlabelled_df.drop(columns=categorical_cols)\n",
    "        categorical_cols = []\n",
    "    else:\n",
    "        categorical_cols = ['Chemotherapy', 'Menopausal State', 'Radio Therapy',\n",
    "                            'Hormone Therapy', 'Surgery-breast conserving',\n",
    "                            'Surgery-mastectomy', 'Neoplasm Histologic Grade',\n",
    "                            'Cellularity']\n",
    "        not_cols=[]\n",
    "        # The model has problems with these columns\n",
    "        test_df = test_df.drop(columns=not_cols)\n",
    "        train_df = train_df.drop(columns=not_cols)\n",
    "        unlabelled_df = unlabelled_df.drop(columns=not_cols)\n",
    "\n",
    "    print(f'Train data shape: {train_df.shape}')\n",
    "    print(f'Test data shape: {test_df.shape}')\n",
    "    print(f'Unlabelled data shape: {unlabelled_df.shape}')\n",
    "    print(f'Numerical columns: {numerical_cols}')\n",
    "    if with_clinical:\n",
    "        print(f'Categorical columns: {categorical_cols}')\n",
    "    return test_df, train_df, unlabelled_df, numerical_cols, categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (465, 31)\n",
      "Test data shape: (117, 31)\n",
      "Unlabelled data shape: (1168, 30)\n",
      "Numerical columns: ['ESR1', 'PGR', 'ERBB2', 'MKI67', 'PLAU', 'ELAVL1', 'EGFR', 'BTRC', 'FBXO6', 'SHMT2', 'KRAS', 'SRPK2', 'YWHAQ', 'PDHA1', 'EWSR1', 'ZDHHC17', 'ENO1', 'DBN1', 'PLK1', 'GSK3B', 'Age', 'Size']\n",
      "Categorical columns: ['Chemotherapy', 'Menopausal State', 'Radio Therapy', 'Hormone Therapy', 'Surgery-breast conserving', 'Surgery-mastectomy', 'Neoplasm Histologic Grade', 'Cellularity']\n"
     ]
    }
   ],
   "source": [
    "test_data, train_data, unlabelled_data, numerical_cols, categorical_cols = get_dataframes(\n",
    "    TEST_DATA_PATH,\n",
    "    TRAIN_DATA_PATH,\n",
    "    UNLABELLED_DATA_PATH,\n",
    "    with_clinical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ESR1</th>\n",
       "      <th>PGR</th>\n",
       "      <th>ERBB2</th>\n",
       "      <th>MKI67</th>\n",
       "      <th>PLAU</th>\n",
       "      <th>ELAVL1</th>\n",
       "      <th>EGFR</th>\n",
       "      <th>BTRC</th>\n",
       "      <th>FBXO6</th>\n",
       "      <th>SHMT2</th>\n",
       "      <th>...</th>\n",
       "      <th>Menopausal State</th>\n",
       "      <th>Size</th>\n",
       "      <th>Radio Therapy</th>\n",
       "      <th>Chemotherapy</th>\n",
       "      <th>Hormone Therapy</th>\n",
       "      <th>Neoplasm Histologic Grade</th>\n",
       "      <th>Cellularity</th>\n",
       "      <th>Surgery-breast conserving</th>\n",
       "      <th>Surgery-mastectomy</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.239750</td>\n",
       "      <td>5.954311</td>\n",
       "      <td>9.739996</td>\n",
       "      <td>6.046045</td>\n",
       "      <td>10.040187</td>\n",
       "      <td>5.905724</td>\n",
       "      <td>5.881255</td>\n",
       "      <td>6.538235</td>\n",
       "      <td>7.260572</td>\n",
       "      <td>10.774752</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.927313</td>\n",
       "      <td>7.002502</td>\n",
       "      <td>10.033753</td>\n",
       "      <td>5.568993</td>\n",
       "      <td>8.306619</td>\n",
       "      <td>6.547491</td>\n",
       "      <td>5.733367</td>\n",
       "      <td>6.128118</td>\n",
       "      <td>7.917904</td>\n",
       "      <td>9.514045</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.312633</td>\n",
       "      <td>5.305683</td>\n",
       "      <td>9.068778</td>\n",
       "      <td>5.919384</td>\n",
       "      <td>8.210977</td>\n",
       "      <td>5.896152</td>\n",
       "      <td>5.634379</td>\n",
       "      <td>5.625037</td>\n",
       "      <td>7.684047</td>\n",
       "      <td>11.422518</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.185200</td>\n",
       "      <td>5.480888</td>\n",
       "      <td>9.580607</td>\n",
       "      <td>5.655789</td>\n",
       "      <td>7.756504</td>\n",
       "      <td>6.026981</td>\n",
       "      <td>6.008594</td>\n",
       "      <td>6.269051</td>\n",
       "      <td>7.428641</td>\n",
       "      <td>9.478211</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.249462</td>\n",
       "      <td>5.164281</td>\n",
       "      <td>10.233184</td>\n",
       "      <td>5.721403</td>\n",
       "      <td>8.918334</td>\n",
       "      <td>6.392132</td>\n",
       "      <td>5.588450</td>\n",
       "      <td>6.062906</td>\n",
       "      <td>7.968933</td>\n",
       "      <td>9.578638</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ESR1       PGR      ERBB2     MKI67       PLAU    ELAVL1      EGFR  \\\n",
       "0  11.239750  5.954311   9.739996  6.046045  10.040187  5.905724  5.881255   \n",
       "1  10.927313  7.002502  10.033753  5.568993   8.306619  6.547491  5.733367   \n",
       "2   6.312633  5.305683   9.068778  5.919384   8.210977  5.896152  5.634379   \n",
       "3   9.185200  5.480888   9.580607  5.655789   7.756504  6.026981  6.008594   \n",
       "4   7.249462  5.164281  10.233184  5.721403   8.918334  6.392132  5.588450   \n",
       "\n",
       "       BTRC     FBXO6      SHMT2  ...  Menopausal State  Size  Radio Therapy  \\\n",
       "0  6.538235  7.260572  10.774752  ...                 1    31              1   \n",
       "1  6.128118  7.917904   9.514045  ...                 1    22              1   \n",
       "2  5.625037  7.684047  11.422518  ...                 1    40              1   \n",
       "3  6.269051  7.428641   9.478211  ...                 1   150              1   \n",
       "4  6.062906  7.968933   9.578638  ...                 1    45              1   \n",
       "\n",
       "   Chemotherapy  Hormone Therapy  Neoplasm Histologic Grade  Cellularity  \\\n",
       "0             0                1                          3          0.5   \n",
       "1             0                1                          2          0.5   \n",
       "2             1                0                          3          1.0   \n",
       "3             0                1                          3          1.0   \n",
       "4             1                0                          2          1.0   \n",
       "\n",
       "   Surgery-breast conserving  Surgery-mastectomy  Label  \n",
       "0                          0                   1      1  \n",
       "1                          0                   1      0  \n",
       "2                          0                   1      1  \n",
       "3                          0                   1      1  \n",
       "4                          0                   1      1  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_X_train = train_data.drop(columns=['Label'])\n",
    "full_y_train = train_data['Label']\n",
    "\n",
    "X_test = test_data.drop(columns=['Label'])\n",
    "y_test = test_data['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (372, 30)\n",
      "Validation data shape: (93, 30)\n"
     ]
    }
   ],
   "source": [
    "# Split the train_data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    full_X_train,\n",
    "    full_y_train,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=full_y_train)\n",
    "\n",
    "print(f'Training data shape: {X_train.shape}')\n",
    "print(f'Validation data shape: {X_val.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = \"accuracy_score\"\n",
    "input_dim = X_train.shape[1]\n",
    "pretraining_head_dim = 1024\n",
    "output_dim = 2\n",
    "head_depth = 2\n",
    "dropout_rate = 0.04\n",
    "\n",
    "corruption_rate = 0.6\n",
    "\n",
    "batch_size = 128\n",
    "max_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_config = IdentityEmbeddingConfig(input_dim = input_dim)\n",
    "backbone_config = MLPBackboneConfig(input_dim = embedding_config.output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = SCARFConfig( \n",
    "    task=\"classification\",\n",
    "    loss_fn=\"CrossEntropyLoss\",\n",
    "    metric=metric, metric_hparams={},\n",
    "    embedding_config=embedding_config,\n",
    "    backbone_config=backbone_config,\n",
    "    pretraining_head_dim=pretraining_head_dim,\n",
    "    output_dim=output_dim,\n",
    "    head_depth=head_depth,\n",
    "    dropout_rate=dropout_rate,\n",
    "    corruption_rate = corruption_rate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "pl_scarf = SCARFLightning(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "### First Phase Learning\n",
    "train_ds = SCARFDataset(\n",
    "    X_train,\n",
    "    unlabeled_data=unlabelled_data,\n",
    "    config = config,\n",
    "    continuous_cols=numerical_cols,\n",
    "    category_cols=categorical_cols)\n",
    "\n",
    "valid_ds = SCARFDataset(\n",
    "    X_val,\n",
    "    config=config,\n",
    "    continuous_cols=numerical_cols,\n",
    "    category_cols=categorical_cols\n",
    ")\n",
    "\n",
    "datamodule = TS3LDataModule(train_ds, valid_ds, batch_size=batch_size, train_sampler=\"random\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/sonk/envs/pandas/lib/python3.10/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "\n",
      "  | Name             | Type             | Params | Mode \n",
      "--------------------------------------------------------------\n",
      "0 | task_loss_fn     | CrossEntropyLoss | 0      | train\n",
      "1 | contrastive_loss | NTXentLoss       | 0      | train\n",
      "2 | model            | SCARF            | 1.2 M  | train\n",
      "--------------------------------------------------------------\n",
      "1.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 M     Total params\n",
      "4.820     Total estimated model params size (MB)\n",
      "23        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonk/envs/pandas/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  0.75it/s, v_num=69, train_loss=4.940, val_loss=5.180]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:17<00:00,  0.74it/s, v_num=69, train_loss=4.940, val_loss=5.180]\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    accelerator = 'cpu',\n",
    "    max_epochs = max_epochs,\n",
    "    num_sanity_val_steps = 2,\n",
    "    )\n",
    "\n",
    "trainer.fit(pl_scarf, datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Second Phase Learning\n",
    "\n",
    "pl_scarf.set_second_phase()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = SCARFDataset(\n",
    "    X_train,\n",
    "    y_train.values,\n",
    "    continuous_cols=numerical_cols,\n",
    "    category_cols=categorical_cols,\n",
    "    is_second_phase=True)\n",
    "\n",
    "valid_ds = SCARFDataset(\n",
    "    X_val,\n",
    "    y_val.values,\n",
    "    continuous_cols=numerical_cols,\n",
    "    category_cols=categorical_cols,\n",
    "    is_second_phase=True)\n",
    "\n",
    "datamodule = TS3LDataModule(train_ds, valid_ds, batch_size = batch_size, train_sampler=\"weighted\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/sonk/envs/pandas/lib/python3.10/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "\n",
      "  | Name             | Type             | Params | Mode \n",
      "--------------------------------------------------------------\n",
      "0 | task_loss_fn     | CrossEntropyLoss | 0      | train\n",
      "1 | contrastive_loss | NTXentLoss       | 0      | train\n",
      "2 | model            | SCARF            | 1.2 M  | train\n",
      "--------------------------------------------------------------\n",
      "1.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 M     Total params\n",
      "4.820     Total estimated model params size (MB)\n",
      "23        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonk/envs/pandas/lib/python3.10/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/home/sonk/envs/pandas/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (3) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/3 [00:00<?, ?it/s, v_num=70, train_loss=0.912, train_accuracy_score=0.524, val_accuracy_score=0.602, val_loss=0.678]        "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonk/envs/pandas/lib/python3.10/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:   0%|          | 0/3 [00:00<?, ?it/s, v_num=70, train_loss=0.793, train_accuracy_score=0.581, val_accuracy_score=0.613, val_loss=0.662]        "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonk/envs/pandas/lib/python3.10/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:   0%|          | 0/3 [00:00<?, ?it/s, v_num=70, train_loss=0.854, train_accuracy_score=0.511, val_accuracy_score=0.591, val_loss=0.653]        "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonk/envs/pandas/lib/python3.10/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:   0%|          | 0/3 [00:00<?, ?it/s, v_num=70, train_loss=0.846, train_accuracy_score=0.532, val_accuracy_score=0.634, val_loss=0.644]        "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonk/envs/pandas/lib/python3.10/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:   0%|          | 0/3 [00:00<?, ?it/s, v_num=70, train_loss=0.914, train_accuracy_score=0.516, val_accuracy_score=0.645, val_loss=0.639]        "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonk/envs/pandas/lib/python3.10/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:   0%|          | 0/3 [00:00<?, ?it/s, v_num=70, train_loss=0.785, train_accuracy_score=0.586, val_accuracy_score=0.634, val_loss=0.637]        "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonk/envs/pandas/lib/python3.10/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:   0%|          | 0/3 [00:00<?, ?it/s, v_num=70, train_loss=0.832, train_accuracy_score=0.538, val_accuracy_score=0.624, val_loss=0.637]        "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonk/envs/pandas/lib/python3.10/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:   0%|          | 0/3 [00:00<?, ?it/s, v_num=70, train_loss=0.813, train_accuracy_score=0.589, val_accuracy_score=0.624, val_loss=0.636]        "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonk/envs/pandas/lib/python3.10/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:   0%|          | 0/3 [00:00<?, ?it/s, v_num=70, train_loss=0.853, train_accuracy_score=0.559, val_accuracy_score=0.624, val_loss=0.635]        "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonk/envs/pandas/lib/python3.10/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.96it/s, v_num=70, train_loss=0.846, train_accuracy_score=0.546, val_accuracy_score=0.634, val_loss=0.631]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.89it/s, v_num=70, train_loss=0.846, train_accuracy_score=0.546, val_accuracy_score=0.634, val_loss=0.631]\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "                    accelerator = 'cpu',\n",
    "                    max_epochs = max_epochs,\n",
    "                    num_sanity_val_steps = 2,\n",
    "    )\n",
    "\n",
    "trainer.fit(pl_scarf, datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = SCARFDataset(\n",
    "    X_test,\n",
    "    continuous_cols=numerical_cols,\n",
    "    category_cols=categorical_cols,\n",
    "    is_second_phase=True)\n",
    "\n",
    "test_dl = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size,\n",
    "    shuffle=False,\n",
    "    sampler=SequentialSampler(test_ds),\n",
    "    num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonk/envs/pandas/lib/python3.10/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 337.71it/s]\n",
      "Accuracy 0.72\n"
     ]
    }
   ],
   "source": [
    "preds = trainer.predict(pl_scarf, test_dl)\n",
    "        \n",
    "preds = F.softmax(torch.concat([out.cpu() for out in preds]).squeeze(),dim=1)\n",
    "\n",
    "accuracy = accuracy_score(y_test, preds.argmax(1))\n",
    "\n",
    "print(\"Accuracy %.2f\" % accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pandas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
