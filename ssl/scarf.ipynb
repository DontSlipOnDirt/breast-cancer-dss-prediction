{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Prepare the SCARFLightning Module\n",
    "from ts3l.pl_modules import SCARFLightning\n",
    "from ts3l.utils.scarf_utils import SCARFDataset\n",
    "from ts3l.utils import TS3LDataModule\n",
    "from ts3l.utils.scarf_utils import SCARFConfig\n",
    "from ts3l.utils.embedding_utils import IdentityEmbeddingConfig\n",
    "from ts3l.utils.backbone_utils import MLPBackboneConfig\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DATA_PATH = \"../data/test_data.csv\"\n",
    "TRAIN_DATA_PATH = \"../data/train_data.csv\"\n",
    "UNLABELLED_DATA_PATH = \"../data/unlabelled_data.csv\"\n",
    "PSEUDO_LABELLED_DATA_PATH = \"../data/pseudo_labelled_scarf.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframes(test_path, train_path, unlabelled_path, with_clinical=False):\n",
    "    # Load the data\n",
    "    test_df = pd.read_csv(test_path)\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    unlabelled_df = pd.read_csv(unlabelled_path)\n",
    "\n",
    "    # Drop the columns that are not needed\n",
    "    test_df = test_df.drop(columns=['DssTime', 'Event'])\n",
    "    train_df = train_df.drop(columns=['DssTime', 'Event'])\n",
    "\n",
    "    # Extract numerical and categorical columns\n",
    "    # Numerical cols: Gene + Age\n",
    "    numerical_cols = test_df.columns[:21].tolist()\n",
    "    # But also Size\n",
    "    numerical_cols.append('Size')\n",
    "    # Categorical cols: Clinical\n",
    "    categorical_cols = test_df.drop(columns=['Label', 'Size']).columns[21:].tolist()\n",
    "    if not with_clinical:\n",
    "        test_df = test_df.drop(columns=categorical_cols)\n",
    "        train_df = train_df.drop(columns=categorical_cols)\n",
    "        unlabelled_df = unlabelled_df.drop(columns=categorical_cols)\n",
    "        categorical_cols = []\n",
    "    else:\n",
    "        categorical_cols = ['Chemotherapy', 'Menopausal State', 'Radio Therapy', 'Hormone Therapy', 'Surgery-breast conserving', 'Surgery-mastectomy']\n",
    "        # The model has problems with these columns\n",
    "        not_cols = ['Neoplasm Histologic Grade', 'Cellularity']\n",
    "        test_df = test_df.drop(columns=not_cols)\n",
    "        train_df = train_df.drop(columns=not_cols)\n",
    "        unlabelled_df = unlabelled_df.drop(columns=not_cols)\n",
    "\n",
    "    print(f'Train data shape: {train_df.shape}')\n",
    "    print(f'Test data shape: {test_df.shape}')\n",
    "    print(f'Unlabelled data shape: {unlabelled_df.shape}')\n",
    "    print(f'Numerical columns: {numerical_cols}')\n",
    "    if with_clinical:\n",
    "        print(f'Categorical columns: {categorical_cols}')\n",
    "    return test_df, train_df, unlabelled_df, numerical_cols, categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (465, 29)\n",
      "Test data shape: (117, 29)\n",
      "Unlabelled data shape: (1168, 28)\n",
      "Numerical columns: ['ESR1', 'PGR', 'ERBB2', 'MKI67', 'PLAU', 'ELAVL1', 'EGFR', 'BTRC', 'FBXO6', 'SHMT2', 'KRAS', 'SRPK2', 'YWHAQ', 'PDHA1', 'EWSR1', 'ZDHHC17', 'ENO1', 'DBN1', 'PLK1', 'GSK3B', 'Age', 'Size']\n",
      "Categorical columns: ['Chemotherapy', 'Menopausal State', 'Radio Therapy', 'Hormone Therapy', 'Surgery-breast conserving', 'Surgery-mastectomy']\n"
     ]
    }
   ],
   "source": [
    "test_data, train_data, unlabelled_data, numerical_cols, categorical_cols = get_dataframes(\n",
    "    TEST_DATA_PATH,\n",
    "    TRAIN_DATA_PATH,\n",
    "    UNLABELLED_DATA_PATH,\n",
    "    with_clinical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_X_train = train_data.drop(columns=['Label'])\n",
    "full_y_train = train_data['Label']\n",
    "\n",
    "X_test = test_data.drop(columns=['Label'])\n",
    "y_test = test_data['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (372, 28)\n",
      "Validation data shape: (93, 28)\n"
     ]
    }
   ],
   "source": [
    "# Split the train_data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    full_X_train,\n",
    "    full_y_train,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=full_y_train)\n",
    "\n",
    "print(f'Training data shape: {X_train.shape}')\n",
    "print(f'Validation data shape: {X_val.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = \"accuracy_score\"\n",
    "input_dim = X_train.shape[1]\n",
    "pretraining_head_dim = 1024\n",
    "output_dim = 2\n",
    "head_depth = 2\n",
    "dropout_rate = 0.04\n",
    "\n",
    "corruption_rate = 0.6\n",
    "\n",
    "batch_size = 128\n",
    "max_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_config = IdentityEmbeddingConfig(input_dim = input_dim)\n",
    "backbone_config = MLPBackboneConfig(input_dim = embedding_config.output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = SCARFConfig( \n",
    "    task=\"classification\",\n",
    "    loss_fn=\"CrossEntropyLoss\",\n",
    "    metric=metric, metric_hparams={},\n",
    "    embedding_config=embedding_config,\n",
    "    backbone_config=backbone_config,\n",
    "    pretraining_head_dim=pretraining_head_dim,\n",
    "    output_dim=output_dim,\n",
    "    head_depth=head_depth,\n",
    "    dropout_rate=dropout_rate,\n",
    "    corruption_rate = corruption_rate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "pl_scarf = SCARFLightning(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "### First Phase Learning\n",
    "train_ds = SCARFDataset(\n",
    "    X_train,\n",
    "    unlabeled_data=unlabelled_data,\n",
    "    config = config,\n",
    "    continuous_cols=numerical_cols,\n",
    "    category_cols=categorical_cols)\n",
    "\n",
    "valid_ds = SCARFDataset(\n",
    "    X_val,\n",
    "    config=config,\n",
    "    continuous_cols=numerical_cols,\n",
    "    category_cols=categorical_cols\n",
    ")\n",
    "\n",
    "datamodule = TS3LDataModule(train_ds, valid_ds, batch_size=batch_size, train_sampler=\"random\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/sonk/envs/jupyter/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "\n",
      "  | Name             | Type             | Params | Mode \n",
      "--------------------------------------------------------------\n",
      "0 | task_loss_fn     | CrossEntropyLoss | 0      | train\n",
      "1 | contrastive_loss | NTXentLoss       | 0      | train\n",
      "2 | model            | SCARF            | 1.2 M  | train\n",
      "--------------------------------------------------------------\n",
      "1.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 M     Total params\n",
      "4.819     Total estimated model params size (MB)\n",
      "23        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c84f63768335472b822a8eaeeb8ea45b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonk/envs/jupyter/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdfe71cff32e45f38a7e7e883f53e568",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2571917cc6a04e4983ae47e4b5a18ed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6346a8344374933a60604bdb67bb92d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de390f83536849c394c27a1a4cf0eb3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    accelerator = 'cpu',\n",
    "    max_epochs = max_epochs,\n",
    "    num_sanity_val_steps = 2,\n",
    "    )\n",
    "\n",
    "trainer.fit(pl_scarf, datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Second Phase Learning\n",
    "\n",
    "pl_scarf.set_second_phase()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = SCARFDataset(\n",
    "    X_train,\n",
    "    y_train.values,\n",
    "    continuous_cols=numerical_cols,\n",
    "    category_cols=categorical_cols,\n",
    "    is_second_phase=True)\n",
    "\n",
    "valid_ds = SCARFDataset(\n",
    "    X_val,\n",
    "    y_val.values,\n",
    "    continuous_cols=numerical_cols,\n",
    "    category_cols=categorical_cols,\n",
    "    is_second_phase=True)\n",
    "\n",
    "datamodule = TS3LDataModule(train_ds, valid_ds, batch_size = batch_size, train_sampler=\"weighted\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/sonk/envs/jupyter/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "\n",
      "  | Name             | Type             | Params | Mode \n",
      "--------------------------------------------------------------\n",
      "0 | task_loss_fn     | CrossEntropyLoss | 0      | train\n",
      "1 | contrastive_loss | NTXentLoss       | 0      | train\n",
      "2 | model            | SCARF            | 1.2 M  | train\n",
      "--------------------------------------------------------------\n",
      "1.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 M     Total params\n",
      "4.816     Total estimated model params size (MB)\n",
      "23        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01c00a98aa004528b31e2e6d3be4b475",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonk/envs/jupyter/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/sonk/envs/jupyter/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (3) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08b64ebb2ca545eeb2c8c03218cbef90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fda8400d74c4160af63420d96a8d737",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonk/envs/jupyter/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b72adf165454e6a9eaaef7a96010237",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonk/envs/jupyter/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2902483481349c792a5d9d51d0116b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonk/envs/jupyter/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6c255bac5bc40f6adcff4239ee10508",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonk/envs/jupyter/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63c2c2baa7434cc790b210cf0155ac85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonk/envs/jupyter/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "590b9c7062164169873d91d35f66da4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonk/envs/jupyter/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82e25badd7f44ef4a0727be0f8c9c0bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonk/envs/jupyter/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "758da1aec8684b019f6b6686cb5f9aa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonk/envs/jupyter/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "794481bbe2b243548b27c7b2b39accb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonk/envs/jupyter/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb6b41cbc3f54aec84cff68e6fd00f43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "                    accelerator = 'cpu',\n",
    "                    max_epochs = max_epochs,\n",
    "                    num_sanity_val_steps = 2,\n",
    "    )\n",
    "\n",
    "trainer.fit(pl_scarf, datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = SCARFDataset(\n",
    "    X_test,\n",
    "    continuous_cols=numerical_cols,\n",
    "    category_cols=categorical_cols,\n",
    "    is_second_phase=True)\n",
    "\n",
    "test_dl = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size,\n",
    "    shuffle=False,\n",
    "    sampler=SequentialSampler(test_ds),\n",
    "    num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonk/envs/jupyter/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48517d0a0ff143879abc50e00859525d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.55\n"
     ]
    }
   ],
   "source": [
    "preds = trainer.predict(pl_scarf, test_dl)\n",
    "        \n",
    "preds = F.softmax(torch.concat([out.cpu() for out in preds]).squeeze(),dim=1)\n",
    "\n",
    "accuracy = accuracy_score(y_test, preds.argmax(1))\n",
    "\n",
    "print(\"Accuracy %.2f\" % accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
