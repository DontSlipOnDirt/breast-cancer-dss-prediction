{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the VIMELightning Module\n",
    "from ts3l.pl_modules import VIMELightning\n",
    "from ts3l.utils.vime_utils import VIMEDataset\n",
    "from ts3l.utils import TS3LDataModule, get_category_cardinality\n",
    "from ts3l.utils.vime_utils import VIMEConfig\n",
    "from ts3l.utils.embedding_utils import IdentityEmbeddingConfig\n",
    "from ts3l.utils.backbone_utils import MLPBackboneConfig\n",
    "from pytorch_lightning import Trainer\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (465, 33)\n",
      "Test data shape: (117, 33)\n",
      "Unlabelled data shape: (1168, 30)\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv('../data/test_data.csv')\n",
    "train_data = pd.read_csv('../data/train_data.csv')\n",
    "unlabelled_data = pd.read_csv('../data/unlabelled_data.csv')\n",
    "\n",
    "print(f'Train data shape: {train_data.shape}')\n",
    "print(f'Test data shape: {test_data.shape}')\n",
    "print(f'Unlabelled data shape: {unlabelled_data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ESR1</th>\n",
       "      <th>PGR</th>\n",
       "      <th>ERBB2</th>\n",
       "      <th>MKI67</th>\n",
       "      <th>PLAU</th>\n",
       "      <th>ELAVL1</th>\n",
       "      <th>EGFR</th>\n",
       "      <th>BTRC</th>\n",
       "      <th>FBXO6</th>\n",
       "      <th>SHMT2</th>\n",
       "      <th>...</th>\n",
       "      <th>Radio Therapy</th>\n",
       "      <th>Chemotherapy</th>\n",
       "      <th>Hormone Therapy</th>\n",
       "      <th>Neoplasm Histologic Grade</th>\n",
       "      <th>Cellularity</th>\n",
       "      <th>Surgery-breast conserving</th>\n",
       "      <th>Surgery-mastectomy</th>\n",
       "      <th>Label</th>\n",
       "      <th>DssTime</th>\n",
       "      <th>Event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.239750</td>\n",
       "      <td>5.954311</td>\n",
       "      <td>9.739996</td>\n",
       "      <td>6.046045</td>\n",
       "      <td>10.040187</td>\n",
       "      <td>5.905724</td>\n",
       "      <td>5.881255</td>\n",
       "      <td>6.538235</td>\n",
       "      <td>7.260572</td>\n",
       "      <td>10.774752</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.800000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.927313</td>\n",
       "      <td>7.002502</td>\n",
       "      <td>10.033753</td>\n",
       "      <td>5.568993</td>\n",
       "      <td>8.306619</td>\n",
       "      <td>6.547491</td>\n",
       "      <td>5.733367</td>\n",
       "      <td>6.128118</td>\n",
       "      <td>7.917904</td>\n",
       "      <td>9.514045</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>132.033333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.312633</td>\n",
       "      <td>5.305683</td>\n",
       "      <td>9.068778</td>\n",
       "      <td>5.919384</td>\n",
       "      <td>8.210977</td>\n",
       "      <td>5.896152</td>\n",
       "      <td>5.634379</td>\n",
       "      <td>5.625037</td>\n",
       "      <td>7.684047</td>\n",
       "      <td>11.422518</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.185200</td>\n",
       "      <td>5.480888</td>\n",
       "      <td>9.580607</td>\n",
       "      <td>5.655789</td>\n",
       "      <td>7.756504</td>\n",
       "      <td>6.026981</td>\n",
       "      <td>6.008594</td>\n",
       "      <td>6.269051</td>\n",
       "      <td>7.428641</td>\n",
       "      <td>9.478211</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>39.166667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.249462</td>\n",
       "      <td>5.164281</td>\n",
       "      <td>10.233184</td>\n",
       "      <td>5.721403</td>\n",
       "      <td>8.918334</td>\n",
       "      <td>6.392132</td>\n",
       "      <td>5.588450</td>\n",
       "      <td>6.062906</td>\n",
       "      <td>7.968933</td>\n",
       "      <td>9.578638</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>31.300000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ESR1       PGR      ERBB2     MKI67       PLAU    ELAVL1      EGFR  \\\n",
       "0  11.239750  5.954311   9.739996  6.046045  10.040187  5.905724  5.881255   \n",
       "1  10.927313  7.002502  10.033753  5.568993   8.306619  6.547491  5.733367   \n",
       "2   6.312633  5.305683   9.068778  5.919384   8.210977  5.896152  5.634379   \n",
       "3   9.185200  5.480888   9.580607  5.655789   7.756504  6.026981  6.008594   \n",
       "4   7.249462  5.164281  10.233184  5.721403   8.918334  6.392132  5.588450   \n",
       "\n",
       "       BTRC     FBXO6      SHMT2  ...  Radio Therapy  Chemotherapy  \\\n",
       "0  6.538235  7.260572  10.774752  ...              1             0   \n",
       "1  6.128118  7.917904   9.514045  ...              1             0   \n",
       "2  5.625037  7.684047  11.422518  ...              1             1   \n",
       "3  6.269051  7.428641   9.478211  ...              1             0   \n",
       "4  6.062906  7.968933   9.578638  ...              1             1   \n",
       "\n",
       "   Hormone Therapy  Neoplasm Histologic Grade  Cellularity  \\\n",
       "0                1                          3          0.5   \n",
       "1                1                          2          0.5   \n",
       "2                0                          3          1.0   \n",
       "3                1                          3          1.0   \n",
       "4                0                          2          1.0   \n",
       "\n",
       "   Surgery-breast conserving  Surgery-mastectomy  Label     DssTime  Event  \n",
       "0                          0                   1      1    7.800000      1  \n",
       "1                          0                   1      0  132.033333      1  \n",
       "2                          0                   1      1   28.500000      1  \n",
       "3                          0                   1      1   39.166667      1  \n",
       "4                          0                   1      1   31.300000      1  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ESR1</th>\n",
       "      <th>PGR</th>\n",
       "      <th>ERBB2</th>\n",
       "      <th>MKI67</th>\n",
       "      <th>PLAU</th>\n",
       "      <th>ELAVL1</th>\n",
       "      <th>EGFR</th>\n",
       "      <th>BTRC</th>\n",
       "      <th>FBXO6</th>\n",
       "      <th>SHMT2</th>\n",
       "      <th>...</th>\n",
       "      <th>YWHAQ</th>\n",
       "      <th>PDHA1</th>\n",
       "      <th>EWSR1</th>\n",
       "      <th>ZDHHC17</th>\n",
       "      <th>ENO1</th>\n",
       "      <th>DBN1</th>\n",
       "      <th>PLK1</th>\n",
       "      <th>GSK3B</th>\n",
       "      <th>Age</th>\n",
       "      <th>Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.239750</td>\n",
       "      <td>5.954311</td>\n",
       "      <td>9.739996</td>\n",
       "      <td>6.046045</td>\n",
       "      <td>10.040187</td>\n",
       "      <td>5.905724</td>\n",
       "      <td>5.881255</td>\n",
       "      <td>6.538235</td>\n",
       "      <td>7.260572</td>\n",
       "      <td>10.774752</td>\n",
       "      <td>...</td>\n",
       "      <td>12.049173</td>\n",
       "      <td>8.766946</td>\n",
       "      <td>9.710697</td>\n",
       "      <td>7.002427</td>\n",
       "      <td>12.416515</td>\n",
       "      <td>8.881028</td>\n",
       "      <td>6.466387</td>\n",
       "      <td>8.771647</td>\n",
       "      <td>78</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.927313</td>\n",
       "      <td>7.002502</td>\n",
       "      <td>10.033753</td>\n",
       "      <td>5.568993</td>\n",
       "      <td>8.306619</td>\n",
       "      <td>6.547491</td>\n",
       "      <td>5.733367</td>\n",
       "      <td>6.128118</td>\n",
       "      <td>7.917904</td>\n",
       "      <td>9.514045</td>\n",
       "      <td>...</td>\n",
       "      <td>11.475811</td>\n",
       "      <td>8.098890</td>\n",
       "      <td>9.762576</td>\n",
       "      <td>7.122037</td>\n",
       "      <td>12.113516</td>\n",
       "      <td>8.553396</td>\n",
       "      <td>6.575161</td>\n",
       "      <td>8.360427</td>\n",
       "      <td>85</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.312633</td>\n",
       "      <td>5.305683</td>\n",
       "      <td>9.068778</td>\n",
       "      <td>5.919384</td>\n",
       "      <td>8.210977</td>\n",
       "      <td>5.896152</td>\n",
       "      <td>5.634379</td>\n",
       "      <td>5.625037</td>\n",
       "      <td>7.684047</td>\n",
       "      <td>11.422518</td>\n",
       "      <td>...</td>\n",
       "      <td>12.534071</td>\n",
       "      <td>8.553177</td>\n",
       "      <td>9.328939</td>\n",
       "      <td>7.343709</td>\n",
       "      <td>12.022229</td>\n",
       "      <td>7.636171</td>\n",
       "      <td>6.221834</td>\n",
       "      <td>8.027209</td>\n",
       "      <td>50</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.185200</td>\n",
       "      <td>5.480888</td>\n",
       "      <td>9.580607</td>\n",
       "      <td>5.655789</td>\n",
       "      <td>7.756504</td>\n",
       "      <td>6.026981</td>\n",
       "      <td>6.008594</td>\n",
       "      <td>6.269051</td>\n",
       "      <td>7.428641</td>\n",
       "      <td>9.478211</td>\n",
       "      <td>...</td>\n",
       "      <td>12.044500</td>\n",
       "      <td>8.168313</td>\n",
       "      <td>9.644231</td>\n",
       "      <td>7.425378</td>\n",
       "      <td>12.284900</td>\n",
       "      <td>8.701101</td>\n",
       "      <td>6.383001</td>\n",
       "      <td>8.494059</td>\n",
       "      <td>83</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.249462</td>\n",
       "      <td>5.164281</td>\n",
       "      <td>10.233184</td>\n",
       "      <td>5.721403</td>\n",
       "      <td>8.918334</td>\n",
       "      <td>6.392132</td>\n",
       "      <td>5.588450</td>\n",
       "      <td>6.062906</td>\n",
       "      <td>7.968933</td>\n",
       "      <td>9.578638</td>\n",
       "      <td>...</td>\n",
       "      <td>12.989485</td>\n",
       "      <td>8.844283</td>\n",
       "      <td>9.537609</td>\n",
       "      <td>7.272580</td>\n",
       "      <td>12.556723</td>\n",
       "      <td>9.189911</td>\n",
       "      <td>6.909404</td>\n",
       "      <td>8.841997</td>\n",
       "      <td>82</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>12.185732</td>\n",
       "      <td>5.462241</td>\n",
       "      <td>10.359953</td>\n",
       "      <td>6.181130</td>\n",
       "      <td>7.712059</td>\n",
       "      <td>6.827588</td>\n",
       "      <td>5.681641</td>\n",
       "      <td>8.019460</td>\n",
       "      <td>6.743522</td>\n",
       "      <td>9.729085</td>\n",
       "      <td>...</td>\n",
       "      <td>11.318578</td>\n",
       "      <td>7.927799</td>\n",
       "      <td>10.112902</td>\n",
       "      <td>8.180081</td>\n",
       "      <td>11.426533</td>\n",
       "      <td>8.797799</td>\n",
       "      <td>7.082542</td>\n",
       "      <td>8.743363</td>\n",
       "      <td>58</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>9.705585</td>\n",
       "      <td>6.727055</td>\n",
       "      <td>10.990295</td>\n",
       "      <td>5.633936</td>\n",
       "      <td>8.161321</td>\n",
       "      <td>6.180448</td>\n",
       "      <td>5.828184</td>\n",
       "      <td>6.757800</td>\n",
       "      <td>7.328591</td>\n",
       "      <td>9.771554</td>\n",
       "      <td>...</td>\n",
       "      <td>11.543076</td>\n",
       "      <td>7.825238</td>\n",
       "      <td>9.851387</td>\n",
       "      <td>7.315788</td>\n",
       "      <td>12.194310</td>\n",
       "      <td>9.319627</td>\n",
       "      <td>6.282904</td>\n",
       "      <td>8.144959</td>\n",
       "      <td>43</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>10.303005</td>\n",
       "      <td>5.996609</td>\n",
       "      <td>10.523380</td>\n",
       "      <td>5.813295</td>\n",
       "      <td>8.719961</td>\n",
       "      <td>6.190540</td>\n",
       "      <td>6.144548</td>\n",
       "      <td>6.251790</td>\n",
       "      <td>7.811116</td>\n",
       "      <td>10.481299</td>\n",
       "      <td>...</td>\n",
       "      <td>12.045751</td>\n",
       "      <td>8.439066</td>\n",
       "      <td>9.269746</td>\n",
       "      <td>6.885769</td>\n",
       "      <td>12.788076</td>\n",
       "      <td>10.051038</td>\n",
       "      <td>6.588315</td>\n",
       "      <td>8.920050</td>\n",
       "      <td>67</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>11.886409</td>\n",
       "      <td>6.266055</td>\n",
       "      <td>10.260601</td>\n",
       "      <td>5.883065</td>\n",
       "      <td>7.146876</td>\n",
       "      <td>6.430670</td>\n",
       "      <td>5.579551</td>\n",
       "      <td>7.444408</td>\n",
       "      <td>8.435352</td>\n",
       "      <td>9.369971</td>\n",
       "      <td>...</td>\n",
       "      <td>11.325677</td>\n",
       "      <td>7.519622</td>\n",
       "      <td>10.078754</td>\n",
       "      <td>7.805507</td>\n",
       "      <td>11.999126</td>\n",
       "      <td>8.527640</td>\n",
       "      <td>6.587311</td>\n",
       "      <td>8.244960</td>\n",
       "      <td>59</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>7.121643</td>\n",
       "      <td>5.230989</td>\n",
       "      <td>11.532133</td>\n",
       "      <td>6.278672</td>\n",
       "      <td>7.895471</td>\n",
       "      <td>7.797744</td>\n",
       "      <td>7.529075</td>\n",
       "      <td>5.610520</td>\n",
       "      <td>7.458545</td>\n",
       "      <td>10.347599</td>\n",
       "      <td>...</td>\n",
       "      <td>11.529479</td>\n",
       "      <td>9.108374</td>\n",
       "      <td>9.514262</td>\n",
       "      <td>7.140592</td>\n",
       "      <td>13.052452</td>\n",
       "      <td>9.463158</td>\n",
       "      <td>6.744969</td>\n",
       "      <td>9.276387</td>\n",
       "      <td>36</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ESR1       PGR      ERBB2     MKI67       PLAU    ELAVL1      EGFR  \\\n",
       "0    11.239750  5.954311   9.739996  6.046045  10.040187  5.905724  5.881255   \n",
       "1    10.927313  7.002502  10.033753  5.568993   8.306619  6.547491  5.733367   \n",
       "2     6.312633  5.305683   9.068778  5.919384   8.210977  5.896152  5.634379   \n",
       "3     9.185200  5.480888   9.580607  5.655789   7.756504  6.026981  6.008594   \n",
       "4     7.249462  5.164281  10.233184  5.721403   8.918334  6.392132  5.588450   \n",
       "..         ...       ...        ...       ...        ...       ...       ...   \n",
       "112  12.185732  5.462241  10.359953  6.181130   7.712059  6.827588  5.681641   \n",
       "113   9.705585  6.727055  10.990295  5.633936   8.161321  6.180448  5.828184   \n",
       "114  10.303005  5.996609  10.523380  5.813295   8.719961  6.190540  6.144548   \n",
       "115  11.886409  6.266055  10.260601  5.883065   7.146876  6.430670  5.579551   \n",
       "116   7.121643  5.230989  11.532133  6.278672   7.895471  7.797744  7.529075   \n",
       "\n",
       "         BTRC     FBXO6      SHMT2  ...      YWHAQ     PDHA1      EWSR1  \\\n",
       "0    6.538235  7.260572  10.774752  ...  12.049173  8.766946   9.710697   \n",
       "1    6.128118  7.917904   9.514045  ...  11.475811  8.098890   9.762576   \n",
       "2    5.625037  7.684047  11.422518  ...  12.534071  8.553177   9.328939   \n",
       "3    6.269051  7.428641   9.478211  ...  12.044500  8.168313   9.644231   \n",
       "4    6.062906  7.968933   9.578638  ...  12.989485  8.844283   9.537609   \n",
       "..        ...       ...        ...  ...        ...       ...        ...   \n",
       "112  8.019460  6.743522   9.729085  ...  11.318578  7.927799  10.112902   \n",
       "113  6.757800  7.328591   9.771554  ...  11.543076  7.825238   9.851387   \n",
       "114  6.251790  7.811116  10.481299  ...  12.045751  8.439066   9.269746   \n",
       "115  7.444408  8.435352   9.369971  ...  11.325677  7.519622  10.078754   \n",
       "116  5.610520  7.458545  10.347599  ...  11.529479  9.108374   9.514262   \n",
       "\n",
       "      ZDHHC17       ENO1       DBN1      PLK1     GSK3B  Age  Size  \n",
       "0    7.002427  12.416515   8.881028  6.466387  8.771647   78    31  \n",
       "1    7.122037  12.113516   8.553396  6.575161  8.360427   85    22  \n",
       "2    7.343709  12.022229   7.636171  6.221834  8.027209   50    40  \n",
       "3    7.425378  12.284900   8.701101  6.383001  8.494059   83   150  \n",
       "4    7.272580  12.556723   9.189911  6.909404  8.841997   82    45  \n",
       "..        ...        ...        ...       ...       ...  ...   ...  \n",
       "112  8.180081  11.426533   8.797799  7.082542  8.743363   58    60  \n",
       "113  7.315788  12.194310   9.319627  6.282904  8.144959   43    30  \n",
       "114  6.885769  12.788076  10.051038  6.588315  8.920050   67    40  \n",
       "115  7.805507  11.999126   8.527640  6.587311  8.244960   59    40  \n",
       "116  7.140592  13.052452   9.463158  6.744969  9.276387   36    25  \n",
       "\n",
       "[117 rows x 22 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_cols = test_data.columns[:21].tolist() # gene + AGE\n",
    "numerical_cols.append('Size')\n",
    "\n",
    "test_data[numerical_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Menopausal State</th>\n",
       "      <th>Radio Therapy</th>\n",
       "      <th>Chemotherapy</th>\n",
       "      <th>Hormone Therapy</th>\n",
       "      <th>Neoplasm Histologic Grade</th>\n",
       "      <th>Cellularity</th>\n",
       "      <th>Surgery-breast conserving</th>\n",
       "      <th>Surgery-mastectomy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Menopausal State  Radio Therapy  Chemotherapy  Hormone Therapy  \\\n",
       "0                   1              1             0                1   \n",
       "1                   1              1             0                1   \n",
       "2                   1              1             1                0   \n",
       "3                   1              1             0                1   \n",
       "4                   1              1             1                0   \n",
       "..                ...            ...           ...              ...   \n",
       "112                 1              0             0                1   \n",
       "113                 0              0             1                1   \n",
       "114                 1              0             0                1   \n",
       "115                 1              1             0                1   \n",
       "116                 0              1             1                1   \n",
       "\n",
       "     Neoplasm Histologic Grade  Cellularity  Surgery-breast conserving  \\\n",
       "0                            3          0.5                          0   \n",
       "1                            2          0.5                          0   \n",
       "2                            3          1.0                          0   \n",
       "3                            3          1.0                          0   \n",
       "4                            2          1.0                          0   \n",
       "..                         ...          ...                        ...   \n",
       "112                          3          0.5                          0   \n",
       "113                          2          0.5                          0   \n",
       "114                          3          1.0                          0   \n",
       "115                          1          0.5                          1   \n",
       "116                          3          0.5                          1   \n",
       "\n",
       "     Surgery-mastectomy  \n",
       "0                     1  \n",
       "1                     1  \n",
       "2                     1  \n",
       "3                     1  \n",
       "4                     1  \n",
       "..                  ...  \n",
       "112                   1  \n",
       "113                   1  \n",
       "114                   1  \n",
       "115                   0  \n",
       "116                   0  \n",
       "\n",
       "[117 rows x 8 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_cols = test_data.drop(columns=['Label', 'DssTime', 'Event', 'Size']).columns[21:].tolist()\n",
    "\n",
    "test_data[categorical_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(categorical_cols) + len(numerical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_X_train = train_data.drop(columns=['Label', 'DssTime', 'Event'])\n",
    "full_y_train = train_data['Label']\n",
    "\n",
    "X_test = test_data.drop(columns=['Label', 'DssTime', 'Event'])\n",
    "y_test = test_data['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (372, 30)\n",
      "Validation data shape: (93, 30)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the train_data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    full_X_train,\n",
    "    full_y_train,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=full_y_train)\n",
    "\n",
    "print(f'Training data shape: {X_train.shape}')\n",
    "print(f'Validation data shape: {X_val.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = \"accuracy_score\"\n",
    "input_dim = X_train.shape[1]\n",
    "predictor_dim = 1024\n",
    "alpha1 = 2.0\n",
    "alpha2 = 2.0\n",
    "beta = 1.0\n",
    "K = 2\n",
    "p_m = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "max_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_config = IdentityEmbeddingConfig(input_dim = input_dim)\n",
    "backbone_config = MLPBackboneConfig(input_dim = embedding_config.output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = VIMEConfig( \n",
    "                    task=\"classification\",\n",
    "                    loss_fn=\"CrossEntropyLoss\",\n",
    "                    metric=metric,\n",
    "                    metric_hparams={},\n",
    "                    embedding_config=embedding_config,\n",
    "                    backbone_config=backbone_config,\n",
    "                    predictor_dim=predictor_dim,\n",
    "                    output_dim=2,\n",
    "                    alpha1=alpha1,\n",
    "                    alpha2=alpha2, \n",
    "                    beta=beta,\n",
    "                    K=K,\n",
    "                    p_m = p_m,\n",
    "                    cat_cardinality=get_category_cardinality(X_train, categorical_cols),\n",
    "                    num_continuous=len(numerical_cols),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "pl_vime = VIMELightning(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "### First Phase Learning\n",
    "train_ds = VIMEDataset(\n",
    "    X=X_train,\n",
    "    unlabeled_data=None,\n",
    "    config=config,\n",
    "    continuous_cols=numerical_cols,\n",
    "    category_cols=categorical_cols\n",
    ")\n",
    "\n",
    "valid_ds = VIMEDataset(\n",
    "    X=X_train,\n",
    "    config=config,\n",
    "    continuous_cols=numerical_cols,\n",
    "    category_cols=categorical_cols)\n",
    "\n",
    "datamodule = TS3LDataModule(train_ds, valid_ds, batch_size, train_sampler='random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/sonk/envs/pandas/lib/python3.10/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "\n",
      "  | Name                        | Type             | Params | Mode\n",
      "------------------------------------------------------------------------\n",
      "0 | task_loss_fn                | CrossEntropyLoss | 0      | eval\n",
      "1 | mask_loss_fn                | BCELoss          | 0      | eval\n",
      "2 | categorical_feature_loss_fn | CrossEntropyLoss | 0      | eval\n",
      "3 | continuous_feature_loss_fn  | MSELoss          | 0      | eval\n",
      "4 | consistency_loss_fn         | MSELoss          | 0      | eval\n",
      "5 | model                       | VIME             | 1.2 M  | eval\n",
      "------------------------------------------------------------------------\n",
      "1.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 M     Total params\n",
      "4.854     Total estimated model params size (MB)\n",
      "0         Modules in train mode\n",
      "31        Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Target 3 is out of bounds.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m      2\u001b[0m                     accelerator \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      3\u001b[0m                     max_epochs \u001b[38;5;241m=\u001b[39m max_epochs,\n\u001b[1;32m      4\u001b[0m                     num_sanity_val_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m      5\u001b[0m     )\n\u001b[0;32m----> 7\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpl_vime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/envs/pandas/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:538\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 538\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/envs/pandas/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:47\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     50\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/envs/pandas/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:574\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    568\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    570\u001b[0m     ckpt_path,\n\u001b[1;32m    571\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    572\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    573\u001b[0m )\n\u001b[0;32m--> 574\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/envs/pandas/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:981\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    978\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    979\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 981\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    986\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/envs/pandas/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1023\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m-> 1023\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_sanity_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1024\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[1;32m   1025\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_loop\u001b[38;5;241m.\u001b[39mrun()\n",
      "File \u001b[0;32m~/envs/pandas/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1052\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1049\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;66;03m# run eval step\u001b[39;00m\n\u001b[0;32m-> 1052\u001b[0m \u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1054\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;66;03m# reset logger connector\u001b[39;00m\n",
      "File \u001b[0;32m~/envs/pandas/lib/python3.10/site-packages/pytorch_lightning/loops/utilities.py:178\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m     context_manager \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mno_grad\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/envs/pandas/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py:135\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mis_last_batch \u001b[38;5;241m=\u001b[39m data_fetcher\u001b[38;5;241m.\u001b[39mdone\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;66;03m# run step hooks\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;66;03m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/envs/pandas/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py:396\u001b[0m, in \u001b[0;36m_EvaluationLoop._evaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx, dataloader_iter)\u001b[0m\n\u001b[1;32m    390\u001b[0m hook_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_step\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mtesting \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    391\u001b[0m step_args \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_step_args_from_hook_kwargs(hook_kwargs, hook_name)\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_dataloader_iter\n\u001b[1;32m    394\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m (dataloader_iter,)\n\u001b[1;32m    395\u001b[0m )\n\u001b[0;32m--> 396\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstep_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_processed()\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_dataloader_iter:\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;66;03m# update the hook kwargs now that the step method might have consumed the iterator\u001b[39;00m\n",
      "File \u001b[0;32m~/envs/pandas/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:319\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 319\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    322\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/envs/pandas/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py:411\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module:\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_redirection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 411\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/envs/pandas/lib/python3.10/site-packages/ts3l/pl_modules/base_module.py:137\u001b[0m, in \u001b[0;36mTS3LLightining._first_phase_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_first_phase_step\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    124\u001b[0m                   batch: Any,\n\u001b[1;32m    125\u001b[0m                   batch_idx: \u001b[38;5;28mint\u001b[39m\n\u001b[1;32m    126\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[1;32m    127\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"The first phase step of TabularS3L\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;124;03m        Dict[str, Any]: The loss of the first phase step\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_first_phase_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfirst_phase_step_outputs\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m    139\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m : loss\n\u001b[1;32m    140\u001b[0m     })\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m : loss\n\u001b[1;32m    143\u001b[0m     }\n",
      "File \u001b[0;32m~/envs/pandas/lib/python3.10/site-packages/ts3l/pl_modules/vime_lightning.py:62\u001b[0m, in \u001b[0;36mVIMELightning._get_first_phase_loss\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calculate the first phase loss\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \n\u001b[1;32m     53\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;124;03m    torch.FloatTensor: The final loss of first phase step\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     60\u001b[0m mask_preds, cat_preds, cont_preds \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mvime\u001b[38;5;241m.\u001b[39mfirst_phase_step(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, batch)\n\u001b[0;32m---> 62\u001b[0m mask_loss, categorical_feature_loss, continuous_feature_loss \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfirst_phase_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_categoricals\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_categoricals\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcat_preds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcont_preds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask_preds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmask_loss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcategorical_feature_loss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontinuous_feature_loss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mask_loss \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha1 \u001b[38;5;241m*\u001b[39m categorical_feature_loss \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha2 \u001b[38;5;241m*\u001b[39m continuous_feature_loss\n",
      "File \u001b[0;32m~/envs/pandas/lib/python3.10/site-packages/ts3l/functional/vime.py:55\u001b[0m, in \u001b[0;36mfirst_phase_loss\u001b[0;34m(x_cat, x_cont, mask, cat_feature_preds, cont_feature_preds, mask_preds, mask_loss_fn, categorical_loss_fn, continuous_loss_fn)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x_cat\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(x_cat\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]):\n\u001b[0;32m---> 55\u001b[0m         categorical_feature_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mcategorical_loss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcat_feature_preds\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_cat\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x_cont\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     57\u001b[0m     continuous_feature_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m continuous_loss_fn(cont_feature_preds, x_cont)\n",
      "File \u001b[0;32m~/envs/pandas/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/envs/pandas/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/envs/pandas/lib/python3.10/site-packages/torch/nn/modules/loss.py:1293\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1294\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1300\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/envs/pandas/lib/python3.10/site-packages/torch/nn/functional.py:3479\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3478\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3479\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3480\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3482\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3483\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3484\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3485\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3486\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: Target 3 is out of bounds."
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "                    accelerator = 'cpu',\n",
    "                    max_epochs = max_epochs,\n",
    "                    num_sanity_val_steps = 2,\n",
    "    )\n",
    "\n",
    "trainer.fit(pl_vime, datamodule)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pandas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
