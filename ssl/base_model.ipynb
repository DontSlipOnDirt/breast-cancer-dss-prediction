{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSL: VIME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This work is based on the one published by the author of the [TS3L library](https://github.com/Alcoholrithm/TabularS3L).\n",
    "\n",
    "Specifically, this code is implementing [VIME](https://github.com/Alcoholrithm/TabularS3L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the VIMELightning Module\n",
    "from ts3l.pl_modules import VIMELightning\n",
    "from ts3l.utils.vime_utils import VIMEDataset\n",
    "from ts3l.utils import TS3LDataModule, get_category_cardinality\n",
    "from ts3l.utils.vime_utils import VIMEConfig\n",
    "from ts3l.utils.embedding_utils import IdentityEmbeddingConfig\n",
    "from ts3l.utils.backbone_utils import MLPBackboneConfig\n",
    "from pytorch_lightning import Trainer\n",
    "import numpy as np\n",
    "from ts3l.utils.vime_utils import VIMESecondPhaseCollateFN\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, SequentialSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DATA_PATH = \"../data/test_data.csv\"\n",
    "TRAIN_DATA_PATH = \"../data/train_data.csv\"\n",
    "UNLABELLED_DATA_PATH = \"../data/unlabelled_data.csv\"\n",
    "PSEUDO_LABELLED_DATA_PATH = \"../data/pseudo_labelled_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframes(test_path, train_path, unlabelled_path, with_clinical=False):\n",
    "    # Load the data\n",
    "    test_df = pd.read_csv(test_path)\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    unlabelled_df = pd.read_csv(unlabelled_path)\n",
    "\n",
    "    # Drop the columns that are not needed\n",
    "    test_df = test_df.drop(columns=['DssTime', 'Event'])\n",
    "    train_df = train_df.drop(columns=['DssTime', 'Event'])\n",
    "\n",
    "    # Extract numerical and categorical columns\n",
    "    # Numerical cols: Gene + Age\n",
    "    numerical_cols = test_df.columns[:21].tolist()\n",
    "    # But also Size\n",
    "    numerical_cols.append('Size')\n",
    "    # Categorical cols: Clinical\n",
    "    categorical_cols = test_df.drop(columns=['Label', 'Size']).columns[21:].tolist()\n",
    "    if not with_clinical:\n",
    "        test_df = test_df.drop(columns=categorical_cols)\n",
    "        train_df = train_df.drop(columns=categorical_cols)\n",
    "        unlabelled_df = unlabelled_df.drop(columns=categorical_cols)\n",
    "        categorical_cols = []\n",
    "    else:\n",
    "        categorical_cols = ['Chemotherapy', 'Menopausal State', 'Radio Therapy', 'Hormone Therapy', 'Surgery-breast conserving', 'Surgery-mastectomy']\n",
    "        # The model has problems with these columns\n",
    "        not_cols = ['Neoplasm Histologic Grade', 'Cellularity']\n",
    "        test_df = test_df.drop(columns=not_cols)\n",
    "        train_df = train_df.drop(columns=not_cols)\n",
    "        unlabelled_df = unlabelled_df.drop(columns=not_cols)\n",
    "\n",
    "    print(f'Train data shape: {train_df.shape}')\n",
    "    print(f'Test data shape: {test_df.shape}')\n",
    "    print(f'Unlabelled data shape: {unlabelled_df.shape}')\n",
    "    print(f'Numerical columns: {numerical_cols}')\n",
    "    if with_clinical:\n",
    "        print(f'Categorical columns: {categorical_cols}')\n",
    "    return test_df, train_df, unlabelled_df, numerical_cols, categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (465, 23)\n",
      "Test data shape: (117, 23)\n",
      "Unlabelled data shape: (1168, 22)\n",
      "Numerical columns: ['ESR1', 'PGR', 'ERBB2', 'MKI67', 'PLAU', 'ELAVL1', 'EGFR', 'BTRC', 'FBXO6', 'SHMT2', 'KRAS', 'SRPK2', 'YWHAQ', 'PDHA1', 'EWSR1', 'ZDHHC17', 'ENO1', 'DBN1', 'PLK1', 'GSK3B', 'Age', 'Size']\n"
     ]
    }
   ],
   "source": [
    "test_data, train_data, unlabelled_data, numerical_cols, categorical_cols = get_dataframes(\n",
    "    TEST_DATA_PATH,\n",
    "    TRAIN_DATA_PATH,\n",
    "    UNLABELLED_DATA_PATH,\n",
    "    with_clinical=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ESR1</th>\n",
       "      <th>PGR</th>\n",
       "      <th>ERBB2</th>\n",
       "      <th>MKI67</th>\n",
       "      <th>PLAU</th>\n",
       "      <th>ELAVL1</th>\n",
       "      <th>EGFR</th>\n",
       "      <th>BTRC</th>\n",
       "      <th>FBXO6</th>\n",
       "      <th>SHMT2</th>\n",
       "      <th>...</th>\n",
       "      <th>PDHA1</th>\n",
       "      <th>EWSR1</th>\n",
       "      <th>ZDHHC17</th>\n",
       "      <th>ENO1</th>\n",
       "      <th>DBN1</th>\n",
       "      <th>PLK1</th>\n",
       "      <th>GSK3B</th>\n",
       "      <th>Age</th>\n",
       "      <th>Size</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.239750</td>\n",
       "      <td>5.954311</td>\n",
       "      <td>9.739996</td>\n",
       "      <td>6.046045</td>\n",
       "      <td>10.040187</td>\n",
       "      <td>5.905724</td>\n",
       "      <td>5.881255</td>\n",
       "      <td>6.538235</td>\n",
       "      <td>7.260572</td>\n",
       "      <td>10.774752</td>\n",
       "      <td>...</td>\n",
       "      <td>8.766946</td>\n",
       "      <td>9.710697</td>\n",
       "      <td>7.002427</td>\n",
       "      <td>12.416515</td>\n",
       "      <td>8.881028</td>\n",
       "      <td>6.466387</td>\n",
       "      <td>8.771647</td>\n",
       "      <td>78</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.927313</td>\n",
       "      <td>7.002502</td>\n",
       "      <td>10.033753</td>\n",
       "      <td>5.568993</td>\n",
       "      <td>8.306619</td>\n",
       "      <td>6.547491</td>\n",
       "      <td>5.733367</td>\n",
       "      <td>6.128118</td>\n",
       "      <td>7.917904</td>\n",
       "      <td>9.514045</td>\n",
       "      <td>...</td>\n",
       "      <td>8.098890</td>\n",
       "      <td>9.762576</td>\n",
       "      <td>7.122037</td>\n",
       "      <td>12.113516</td>\n",
       "      <td>8.553396</td>\n",
       "      <td>6.575161</td>\n",
       "      <td>8.360427</td>\n",
       "      <td>85</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.312633</td>\n",
       "      <td>5.305683</td>\n",
       "      <td>9.068778</td>\n",
       "      <td>5.919384</td>\n",
       "      <td>8.210977</td>\n",
       "      <td>5.896152</td>\n",
       "      <td>5.634379</td>\n",
       "      <td>5.625037</td>\n",
       "      <td>7.684047</td>\n",
       "      <td>11.422518</td>\n",
       "      <td>...</td>\n",
       "      <td>8.553177</td>\n",
       "      <td>9.328939</td>\n",
       "      <td>7.343709</td>\n",
       "      <td>12.022229</td>\n",
       "      <td>7.636171</td>\n",
       "      <td>6.221834</td>\n",
       "      <td>8.027209</td>\n",
       "      <td>50</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.185200</td>\n",
       "      <td>5.480888</td>\n",
       "      <td>9.580607</td>\n",
       "      <td>5.655789</td>\n",
       "      <td>7.756504</td>\n",
       "      <td>6.026981</td>\n",
       "      <td>6.008594</td>\n",
       "      <td>6.269051</td>\n",
       "      <td>7.428641</td>\n",
       "      <td>9.478211</td>\n",
       "      <td>...</td>\n",
       "      <td>8.168313</td>\n",
       "      <td>9.644231</td>\n",
       "      <td>7.425378</td>\n",
       "      <td>12.284900</td>\n",
       "      <td>8.701101</td>\n",
       "      <td>6.383001</td>\n",
       "      <td>8.494059</td>\n",
       "      <td>83</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.249462</td>\n",
       "      <td>5.164281</td>\n",
       "      <td>10.233184</td>\n",
       "      <td>5.721403</td>\n",
       "      <td>8.918334</td>\n",
       "      <td>6.392132</td>\n",
       "      <td>5.588450</td>\n",
       "      <td>6.062906</td>\n",
       "      <td>7.968933</td>\n",
       "      <td>9.578638</td>\n",
       "      <td>...</td>\n",
       "      <td>8.844283</td>\n",
       "      <td>9.537609</td>\n",
       "      <td>7.272580</td>\n",
       "      <td>12.556723</td>\n",
       "      <td>9.189911</td>\n",
       "      <td>6.909404</td>\n",
       "      <td>8.841997</td>\n",
       "      <td>82</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ESR1       PGR      ERBB2     MKI67       PLAU    ELAVL1      EGFR  \\\n",
       "0  11.239750  5.954311   9.739996  6.046045  10.040187  5.905724  5.881255   \n",
       "1  10.927313  7.002502  10.033753  5.568993   8.306619  6.547491  5.733367   \n",
       "2   6.312633  5.305683   9.068778  5.919384   8.210977  5.896152  5.634379   \n",
       "3   9.185200  5.480888   9.580607  5.655789   7.756504  6.026981  6.008594   \n",
       "4   7.249462  5.164281  10.233184  5.721403   8.918334  6.392132  5.588450   \n",
       "\n",
       "       BTRC     FBXO6      SHMT2  ...     PDHA1     EWSR1   ZDHHC17  \\\n",
       "0  6.538235  7.260572  10.774752  ...  8.766946  9.710697  7.002427   \n",
       "1  6.128118  7.917904   9.514045  ...  8.098890  9.762576  7.122037   \n",
       "2  5.625037  7.684047  11.422518  ...  8.553177  9.328939  7.343709   \n",
       "3  6.269051  7.428641   9.478211  ...  8.168313  9.644231  7.425378   \n",
       "4  6.062906  7.968933   9.578638  ...  8.844283  9.537609  7.272580   \n",
       "\n",
       "        ENO1      DBN1      PLK1     GSK3B  Age  Size  Label  \n",
       "0  12.416515  8.881028  6.466387  8.771647   78    31      1  \n",
       "1  12.113516  8.553396  6.575161  8.360427   85    22      0  \n",
       "2  12.022229  7.636171  6.221834  8.027209   50    40      1  \n",
       "3  12.284900  8.701101  6.383001  8.494059   83   150      1  \n",
       "4  12.556723  9.189911  6.909404  8.841997   82    45      1  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ESR1</th>\n",
       "      <th>PGR</th>\n",
       "      <th>ERBB2</th>\n",
       "      <th>MKI67</th>\n",
       "      <th>PLAU</th>\n",
       "      <th>ELAVL1</th>\n",
       "      <th>EGFR</th>\n",
       "      <th>BTRC</th>\n",
       "      <th>FBXO6</th>\n",
       "      <th>SHMT2</th>\n",
       "      <th>...</th>\n",
       "      <th>YWHAQ</th>\n",
       "      <th>PDHA1</th>\n",
       "      <th>EWSR1</th>\n",
       "      <th>ZDHHC17</th>\n",
       "      <th>ENO1</th>\n",
       "      <th>DBN1</th>\n",
       "      <th>PLK1</th>\n",
       "      <th>GSK3B</th>\n",
       "      <th>Age</th>\n",
       "      <th>Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.047059</td>\n",
       "      <td>7.505424</td>\n",
       "      <td>9.729606</td>\n",
       "      <td>5.451007</td>\n",
       "      <td>8.474830</td>\n",
       "      <td>6.412419</td>\n",
       "      <td>5.899440</td>\n",
       "      <td>7.069394</td>\n",
       "      <td>7.100058</td>\n",
       "      <td>9.102318</td>\n",
       "      <td>...</td>\n",
       "      <td>12.124106</td>\n",
       "      <td>8.234815</td>\n",
       "      <td>9.674483</td>\n",
       "      <td>7.375406</td>\n",
       "      <td>12.024185</td>\n",
       "      <td>7.757081</td>\n",
       "      <td>6.455580</td>\n",
       "      <td>8.385158</td>\n",
       "      <td>43.19</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.404685</td>\n",
       "      <td>6.815637</td>\n",
       "      <td>10.334979</td>\n",
       "      <td>5.488309</td>\n",
       "      <td>9.994894</td>\n",
       "      <td>6.525927</td>\n",
       "      <td>5.585357</td>\n",
       "      <td>6.071653</td>\n",
       "      <td>7.810600</td>\n",
       "      <td>9.431167</td>\n",
       "      <td>...</td>\n",
       "      <td>12.712623</td>\n",
       "      <td>8.242056</td>\n",
       "      <td>9.154340</td>\n",
       "      <td>7.585137</td>\n",
       "      <td>11.844377</td>\n",
       "      <td>8.042064</td>\n",
       "      <td>6.036497</td>\n",
       "      <td>7.464064</td>\n",
       "      <td>47.68</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.793832</td>\n",
       "      <td>7.720952</td>\n",
       "      <td>9.276507</td>\n",
       "      <td>5.478224</td>\n",
       "      <td>8.184773</td>\n",
       "      <td>5.949741</td>\n",
       "      <td>5.743395</td>\n",
       "      <td>7.244882</td>\n",
       "      <td>7.781876</td>\n",
       "      <td>8.716918</td>\n",
       "      <td>...</td>\n",
       "      <td>12.102056</td>\n",
       "      <td>8.105696</td>\n",
       "      <td>9.136500</td>\n",
       "      <td>7.730418</td>\n",
       "      <td>10.790484</td>\n",
       "      <td>7.599985</td>\n",
       "      <td>5.953310</td>\n",
       "      <td>7.229434</td>\n",
       "      <td>56.45</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.440667</td>\n",
       "      <td>5.592522</td>\n",
       "      <td>8.613192</td>\n",
       "      <td>5.436625</td>\n",
       "      <td>8.210389</td>\n",
       "      <td>6.203913</td>\n",
       "      <td>5.852012</td>\n",
       "      <td>6.219653</td>\n",
       "      <td>7.560101</td>\n",
       "      <td>9.600030</td>\n",
       "      <td>...</td>\n",
       "      <td>11.839824</td>\n",
       "      <td>8.376467</td>\n",
       "      <td>9.257898</td>\n",
       "      <td>7.743428</td>\n",
       "      <td>11.212880</td>\n",
       "      <td>7.770462</td>\n",
       "      <td>6.194253</td>\n",
       "      <td>7.289188</td>\n",
       "      <td>89.08</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.521038</td>\n",
       "      <td>5.325554</td>\n",
       "      <td>10.678267</td>\n",
       "      <td>5.623786</td>\n",
       "      <td>7.786509</td>\n",
       "      <td>6.153012</td>\n",
       "      <td>5.502281</td>\n",
       "      <td>7.278257</td>\n",
       "      <td>7.674681</td>\n",
       "      <td>10.367760</td>\n",
       "      <td>...</td>\n",
       "      <td>11.363913</td>\n",
       "      <td>9.031051</td>\n",
       "      <td>9.462490</td>\n",
       "      <td>7.472229</td>\n",
       "      <td>12.955410</td>\n",
       "      <td>8.591434</td>\n",
       "      <td>6.645760</td>\n",
       "      <td>8.737746</td>\n",
       "      <td>86.41</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ESR1       PGR      ERBB2     MKI67      PLAU    ELAVL1      EGFR  \\\n",
       "0  10.047059  7.505424   9.729606  5.451007  8.474830  6.412419  5.899440   \n",
       "1  10.404685  6.815637  10.334979  5.488309  9.994894  6.525927  5.585357   \n",
       "2  10.793832  7.720952   9.276507  5.478224  8.184773  5.949741  5.743395   \n",
       "3  10.440667  5.592522   8.613192  5.436625  8.210389  6.203913  5.852012   \n",
       "4  12.521038  5.325554  10.678267  5.623786  7.786509  6.153012  5.502281   \n",
       "\n",
       "       BTRC     FBXO6      SHMT2  ...      YWHAQ     PDHA1     EWSR1  \\\n",
       "0  7.069394  7.100058   9.102318  ...  12.124106  8.234815  9.674483   \n",
       "1  6.071653  7.810600   9.431167  ...  12.712623  8.242056  9.154340   \n",
       "2  7.244882  7.781876   8.716918  ...  12.102056  8.105696  9.136500   \n",
       "3  6.219653  7.560101   9.600030  ...  11.839824  8.376467  9.257898   \n",
       "4  7.278257  7.674681  10.367760  ...  11.363913  9.031051  9.462490   \n",
       "\n",
       "    ZDHHC17       ENO1      DBN1      PLK1     GSK3B    Age  Size  \n",
       "0  7.375406  12.024185  7.757081  6.455580  8.385158  43.19  10.0  \n",
       "1  7.585137  11.844377  8.042064  6.036497  7.464064  47.68  25.0  \n",
       "2  7.730418  10.790484  7.599985  5.953310  7.229434  56.45  10.0  \n",
       "3  7.743428  11.212880  7.770462  6.194253  7.289188  89.08  29.0  \n",
       "4  7.472229  12.955410  8.591434  6.645760  8.737746  86.41  16.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabelled_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(categorical_cols) + len(numerical_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_X_train = train_data.drop(columns=['Label'])\n",
    "full_y_train = train_data['Label']\n",
    "\n",
    "X_test = test_data.drop(columns=['Label'])\n",
    "y_test = test_data['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (372, 22)\n",
      "Validation data shape: (93, 22)\n"
     ]
    }
   ],
   "source": [
    "# Split the train_data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    full_X_train,\n",
    "    full_y_train,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=full_y_train)\n",
    "\n",
    "print(f'Training data shape: {X_train.shape}')\n",
    "print(f'Validation data shape: {X_val.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = \"accuracy_score\"\n",
    "input_dim = X_train.shape[1]\n",
    "predictor_dim = 1024\n",
    "alpha1 = 2.0\n",
    "alpha2 = 2.0\n",
    "beta = 1.0\n",
    "K = 2\n",
    "p_m = 0.2\n",
    "batch_size = 128\n",
    "max_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_config = IdentityEmbeddingConfig(input_dim = input_dim)\n",
    "backbone_config = MLPBackboneConfig(input_dim = embedding_config.output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cardinality = get_category_cardinality(X_train, categorical_cols)\n",
    "\n",
    "cardinality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = VIMEConfig( \n",
    "                    task=\"classification\",\n",
    "                    loss_fn=\"CrossEntropyLoss\",\n",
    "                    metric=metric,\n",
    "                    metric_hparams={},\n",
    "                    embedding_config=embedding_config,\n",
    "                    backbone_config=backbone_config,\n",
    "                    predictor_dim=predictor_dim,\n",
    "                    output_dim=2,\n",
    "                    alpha1=alpha1,\n",
    "                    alpha2=alpha2, \n",
    "                    beta=beta,\n",
    "                    K=K,\n",
    "                    p_m = p_m,\n",
    "                    cat_cardinality=cardinality,\n",
    "                    num_continuous=len(numerical_cols),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "pl_vime = VIMELightning(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = VIMEDataset(\n",
    "    X=X_train,\n",
    "    unlabeled_data=unlabelled_data,\n",
    "    config=config,\n",
    "    continuous_cols=numerical_cols,\n",
    "    category_cols=categorical_cols\n",
    ")\n",
    "\n",
    "valid_ds = VIMEDataset(\n",
    "    X=X_train,\n",
    "    config=config,\n",
    "    continuous_cols=numerical_cols,\n",
    "    category_cols=categorical_cols\n",
    ")\n",
    "\n",
    "datamodule = TS3LDataModule(train_ds, valid_ds, batch_size, train_sampler='random')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training: 1st phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/sonk/envs/pandas/lib/python3.10/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "\n",
      "  | Name                        | Type             | Params | Mode \n",
      "-------------------------------------------------------------------------\n",
      "0 | task_loss_fn                | CrossEntropyLoss | 0      | train\n",
      "1 | mask_loss_fn                | BCELoss          | 0      | train\n",
      "2 | categorical_feature_loss_fn | CrossEntropyLoss | 0      | train\n",
      "3 | continuous_feature_loss_fn  | MSELoss          | 0      | train\n",
      "4 | consistency_loss_fn         | MSELoss          | 0      | train\n",
      "5 | model                       | VIME             | 1.2 M  | train\n",
      "-------------------------------------------------------------------------\n",
      "1.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 M     Total params\n",
      "4.837     Total estimated model params size (MB)\n",
      "23        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonk/envs/pandas/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 13/13 [00:01<00:00,  6.51it/s, v_num=55, train_loss=276.0, val_loss=280.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 13/13 [00:02<00:00,  6.36it/s, v_num=55, train_loss=276.0, val_loss=280.0]\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "                    accelerator = 'cpu',\n",
    "                    max_epochs = max_epochs,\n",
    "                    num_sanity_val_steps = 2,\n",
    "    )\n",
    "\n",
    "trainer.fit(pl_vime, datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training: 2nd phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ESR1</th>\n",
       "      <th>PGR</th>\n",
       "      <th>ERBB2</th>\n",
       "      <th>MKI67</th>\n",
       "      <th>PLAU</th>\n",
       "      <th>ELAVL1</th>\n",
       "      <th>EGFR</th>\n",
       "      <th>BTRC</th>\n",
       "      <th>FBXO6</th>\n",
       "      <th>SHMT2</th>\n",
       "      <th>...</th>\n",
       "      <th>YWHAQ</th>\n",
       "      <th>PDHA1</th>\n",
       "      <th>EWSR1</th>\n",
       "      <th>ZDHHC17</th>\n",
       "      <th>ENO1</th>\n",
       "      <th>DBN1</th>\n",
       "      <th>PLK1</th>\n",
       "      <th>GSK3B</th>\n",
       "      <th>Age</th>\n",
       "      <th>Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>11.445577</td>\n",
       "      <td>5.383985</td>\n",
       "      <td>10.523773</td>\n",
       "      <td>5.878819</td>\n",
       "      <td>7.376048</td>\n",
       "      <td>6.224054</td>\n",
       "      <td>5.730411</td>\n",
       "      <td>6.937679</td>\n",
       "      <td>7.314421</td>\n",
       "      <td>9.496653</td>\n",
       "      <td>...</td>\n",
       "      <td>12.212333</td>\n",
       "      <td>8.472817</td>\n",
       "      <td>10.014916</td>\n",
       "      <td>8.037095</td>\n",
       "      <td>11.556363</td>\n",
       "      <td>9.697175</td>\n",
       "      <td>6.687842</td>\n",
       "      <td>8.197441</td>\n",
       "      <td>63</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>11.728241</td>\n",
       "      <td>6.853981</td>\n",
       "      <td>9.093163</td>\n",
       "      <td>6.189151</td>\n",
       "      <td>9.775104</td>\n",
       "      <td>5.891141</td>\n",
       "      <td>5.644219</td>\n",
       "      <td>6.445037</td>\n",
       "      <td>7.500848</td>\n",
       "      <td>10.140590</td>\n",
       "      <td>...</td>\n",
       "      <td>11.938529</td>\n",
       "      <td>7.908106</td>\n",
       "      <td>9.290438</td>\n",
       "      <td>7.124771</td>\n",
       "      <td>12.319678</td>\n",
       "      <td>8.687310</td>\n",
       "      <td>6.408426</td>\n",
       "      <td>8.303559</td>\n",
       "      <td>74</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>11.122611</td>\n",
       "      <td>5.322075</td>\n",
       "      <td>11.719898</td>\n",
       "      <td>6.121027</td>\n",
       "      <td>8.733519</td>\n",
       "      <td>6.321382</td>\n",
       "      <td>6.011898</td>\n",
       "      <td>6.702699</td>\n",
       "      <td>7.682648</td>\n",
       "      <td>9.736608</td>\n",
       "      <td>...</td>\n",
       "      <td>12.368506</td>\n",
       "      <td>8.242456</td>\n",
       "      <td>9.763899</td>\n",
       "      <td>8.006279</td>\n",
       "      <td>12.571911</td>\n",
       "      <td>9.236787</td>\n",
       "      <td>6.921407</td>\n",
       "      <td>8.155855</td>\n",
       "      <td>52</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>11.246158</td>\n",
       "      <td>7.200805</td>\n",
       "      <td>10.488210</td>\n",
       "      <td>5.921079</td>\n",
       "      <td>9.480574</td>\n",
       "      <td>5.598995</td>\n",
       "      <td>5.923112</td>\n",
       "      <td>6.411695</td>\n",
       "      <td>7.998787</td>\n",
       "      <td>10.009468</td>\n",
       "      <td>...</td>\n",
       "      <td>10.978177</td>\n",
       "      <td>8.216202</td>\n",
       "      <td>9.566260</td>\n",
       "      <td>7.362756</td>\n",
       "      <td>12.310459</td>\n",
       "      <td>9.304842</td>\n",
       "      <td>6.561758</td>\n",
       "      <td>8.985041</td>\n",
       "      <td>62</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>9.744005</td>\n",
       "      <td>5.481691</td>\n",
       "      <td>11.031849</td>\n",
       "      <td>5.826471</td>\n",
       "      <td>8.732274</td>\n",
       "      <td>5.873227</td>\n",
       "      <td>5.495358</td>\n",
       "      <td>6.243658</td>\n",
       "      <td>7.719020</td>\n",
       "      <td>9.327830</td>\n",
       "      <td>...</td>\n",
       "      <td>12.078461</td>\n",
       "      <td>8.311747</td>\n",
       "      <td>8.969407</td>\n",
       "      <td>7.349488</td>\n",
       "      <td>11.630288</td>\n",
       "      <td>8.838334</td>\n",
       "      <td>6.456821</td>\n",
       "      <td>7.996271</td>\n",
       "      <td>55</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>9.646853</td>\n",
       "      <td>6.867510</td>\n",
       "      <td>11.548091</td>\n",
       "      <td>5.924567</td>\n",
       "      <td>7.296133</td>\n",
       "      <td>8.187168</td>\n",
       "      <td>5.600126</td>\n",
       "      <td>6.898188</td>\n",
       "      <td>7.883845</td>\n",
       "      <td>9.856422</td>\n",
       "      <td>...</td>\n",
       "      <td>10.292150</td>\n",
       "      <td>8.623320</td>\n",
       "      <td>10.110875</td>\n",
       "      <td>6.780786</td>\n",
       "      <td>11.715737</td>\n",
       "      <td>9.178288</td>\n",
       "      <td>6.453299</td>\n",
       "      <td>9.293761</td>\n",
       "      <td>58</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>11.852769</td>\n",
       "      <td>6.062227</td>\n",
       "      <td>10.560881</td>\n",
       "      <td>5.982969</td>\n",
       "      <td>8.425843</td>\n",
       "      <td>6.169082</td>\n",
       "      <td>5.764507</td>\n",
       "      <td>8.075540</td>\n",
       "      <td>7.504144</td>\n",
       "      <td>9.845907</td>\n",
       "      <td>...</td>\n",
       "      <td>11.484319</td>\n",
       "      <td>7.994028</td>\n",
       "      <td>9.499510</td>\n",
       "      <td>7.191114</td>\n",
       "      <td>12.438446</td>\n",
       "      <td>9.333542</td>\n",
       "      <td>6.489902</td>\n",
       "      <td>8.643844</td>\n",
       "      <td>73</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>9.979798</td>\n",
       "      <td>7.154027</td>\n",
       "      <td>11.187826</td>\n",
       "      <td>5.589705</td>\n",
       "      <td>9.142333</td>\n",
       "      <td>6.381046</td>\n",
       "      <td>6.613969</td>\n",
       "      <td>7.102050</td>\n",
       "      <td>7.290591</td>\n",
       "      <td>9.781446</td>\n",
       "      <td>...</td>\n",
       "      <td>11.501904</td>\n",
       "      <td>7.671545</td>\n",
       "      <td>9.797579</td>\n",
       "      <td>7.490341</td>\n",
       "      <td>12.483094</td>\n",
       "      <td>8.166508</td>\n",
       "      <td>6.440541</td>\n",
       "      <td>8.128982</td>\n",
       "      <td>45</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>9.991981</td>\n",
       "      <td>6.927914</td>\n",
       "      <td>11.341993</td>\n",
       "      <td>5.546633</td>\n",
       "      <td>7.917850</td>\n",
       "      <td>6.365073</td>\n",
       "      <td>6.679638</td>\n",
       "      <td>6.406762</td>\n",
       "      <td>6.592135</td>\n",
       "      <td>9.886140</td>\n",
       "      <td>...</td>\n",
       "      <td>12.486510</td>\n",
       "      <td>8.420539</td>\n",
       "      <td>9.735076</td>\n",
       "      <td>7.707661</td>\n",
       "      <td>12.529626</td>\n",
       "      <td>8.877610</td>\n",
       "      <td>6.226765</td>\n",
       "      <td>8.281162</td>\n",
       "      <td>44</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>5.765334</td>\n",
       "      <td>5.133948</td>\n",
       "      <td>14.285093</td>\n",
       "      <td>6.026854</td>\n",
       "      <td>9.427589</td>\n",
       "      <td>7.114799</td>\n",
       "      <td>7.165267</td>\n",
       "      <td>5.954692</td>\n",
       "      <td>6.765162</td>\n",
       "      <td>10.716583</td>\n",
       "      <td>...</td>\n",
       "      <td>12.475688</td>\n",
       "      <td>9.535585</td>\n",
       "      <td>10.469987</td>\n",
       "      <td>7.113511</td>\n",
       "      <td>11.960473</td>\n",
       "      <td>11.074265</td>\n",
       "      <td>6.803329</td>\n",
       "      <td>9.433496</td>\n",
       "      <td>78</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>372 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ESR1       PGR      ERBB2     MKI67      PLAU    ELAVL1      EGFR  \\\n",
       "271  11.445577  5.383985  10.523773  5.878819  7.376048  6.224054  5.730411   \n",
       "50   11.728241  6.853981   9.093163  6.189151  9.775104  5.891141  5.644219   \n",
       "300  11.122611  5.322075  11.719898  6.121027  8.733519  6.321382  6.011898   \n",
       "156  11.246158  7.200805  10.488210  5.921079  9.480574  5.598995  5.923112   \n",
       "458   9.744005  5.481691  11.031849  5.826471  8.732274  5.873227  5.495358   \n",
       "..         ...       ...        ...       ...       ...       ...       ...   \n",
       "175   9.646853  6.867510  11.548091  5.924567  7.296133  8.187168  5.600126   \n",
       "241  11.852769  6.062227  10.560881  5.982969  8.425843  6.169082  5.764507   \n",
       "238   9.979798  7.154027  11.187826  5.589705  9.142333  6.381046  6.613969   \n",
       "205   9.991981  6.927914  11.341993  5.546633  7.917850  6.365073  6.679638   \n",
       "202   5.765334  5.133948  14.285093  6.026854  9.427589  7.114799  7.165267   \n",
       "\n",
       "         BTRC     FBXO6      SHMT2  ...      YWHAQ     PDHA1      EWSR1  \\\n",
       "271  6.937679  7.314421   9.496653  ...  12.212333  8.472817  10.014916   \n",
       "50   6.445037  7.500848  10.140590  ...  11.938529  7.908106   9.290438   \n",
       "300  6.702699  7.682648   9.736608  ...  12.368506  8.242456   9.763899   \n",
       "156  6.411695  7.998787  10.009468  ...  10.978177  8.216202   9.566260   \n",
       "458  6.243658  7.719020   9.327830  ...  12.078461  8.311747   8.969407   \n",
       "..        ...       ...        ...  ...        ...       ...        ...   \n",
       "175  6.898188  7.883845   9.856422  ...  10.292150  8.623320  10.110875   \n",
       "241  8.075540  7.504144   9.845907  ...  11.484319  7.994028   9.499510   \n",
       "238  7.102050  7.290591   9.781446  ...  11.501904  7.671545   9.797579   \n",
       "205  6.406762  6.592135   9.886140  ...  12.486510  8.420539   9.735076   \n",
       "202  5.954692  6.765162  10.716583  ...  12.475688  9.535585  10.469987   \n",
       "\n",
       "      ZDHHC17       ENO1       DBN1      PLK1     GSK3B  Age  Size  \n",
       "271  8.037095  11.556363   9.697175  6.687842  8.197441   63    43  \n",
       "50   7.124771  12.319678   8.687310  6.408426  8.303559   74    43  \n",
       "300  8.006279  12.571911   9.236787  6.921407  8.155855   52    15  \n",
       "156  7.362756  12.310459   9.304842  6.561758  8.985041   62    20  \n",
       "458  7.349488  11.630288   8.838334  6.456821  7.996271   55    30  \n",
       "..        ...        ...        ...       ...       ...  ...   ...  \n",
       "175  6.780786  11.715737   9.178288  6.453299  9.293761   58    15  \n",
       "241  7.191114  12.438446   9.333542  6.489902  8.643844   73    25  \n",
       "238  7.490341  12.483094   8.166508  6.440541  8.128982   45    11  \n",
       "205  7.707661  12.529626   8.877610  6.226765  8.281162   44    31  \n",
       "202  7.113511  11.960473  11.074265  6.803329  9.433496   78    15  \n",
       "\n",
       "[372 rows x 22 columns]"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ESR1</th>\n",
       "      <th>PGR</th>\n",
       "      <th>ERBB2</th>\n",
       "      <th>MKI67</th>\n",
       "      <th>PLAU</th>\n",
       "      <th>ELAVL1</th>\n",
       "      <th>EGFR</th>\n",
       "      <th>BTRC</th>\n",
       "      <th>FBXO6</th>\n",
       "      <th>SHMT2</th>\n",
       "      <th>...</th>\n",
       "      <th>YWHAQ</th>\n",
       "      <th>PDHA1</th>\n",
       "      <th>EWSR1</th>\n",
       "      <th>ZDHHC17</th>\n",
       "      <th>ENO1</th>\n",
       "      <th>DBN1</th>\n",
       "      <th>PLK1</th>\n",
       "      <th>GSK3B</th>\n",
       "      <th>Age</th>\n",
       "      <th>Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.047059</td>\n",
       "      <td>7.505424</td>\n",
       "      <td>9.729606</td>\n",
       "      <td>5.451007</td>\n",
       "      <td>8.474830</td>\n",
       "      <td>6.412419</td>\n",
       "      <td>5.899440</td>\n",
       "      <td>7.069394</td>\n",
       "      <td>7.100058</td>\n",
       "      <td>9.102318</td>\n",
       "      <td>...</td>\n",
       "      <td>12.124106</td>\n",
       "      <td>8.234815</td>\n",
       "      <td>9.674483</td>\n",
       "      <td>7.375406</td>\n",
       "      <td>12.024185</td>\n",
       "      <td>7.757081</td>\n",
       "      <td>6.455580</td>\n",
       "      <td>8.385158</td>\n",
       "      <td>43.19</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.404685</td>\n",
       "      <td>6.815637</td>\n",
       "      <td>10.334979</td>\n",
       "      <td>5.488309</td>\n",
       "      <td>9.994894</td>\n",
       "      <td>6.525927</td>\n",
       "      <td>5.585357</td>\n",
       "      <td>6.071653</td>\n",
       "      <td>7.810600</td>\n",
       "      <td>9.431167</td>\n",
       "      <td>...</td>\n",
       "      <td>12.712623</td>\n",
       "      <td>8.242056</td>\n",
       "      <td>9.154340</td>\n",
       "      <td>7.585137</td>\n",
       "      <td>11.844377</td>\n",
       "      <td>8.042064</td>\n",
       "      <td>6.036497</td>\n",
       "      <td>7.464064</td>\n",
       "      <td>47.68</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.793832</td>\n",
       "      <td>7.720952</td>\n",
       "      <td>9.276507</td>\n",
       "      <td>5.478224</td>\n",
       "      <td>8.184773</td>\n",
       "      <td>5.949741</td>\n",
       "      <td>5.743395</td>\n",
       "      <td>7.244882</td>\n",
       "      <td>7.781876</td>\n",
       "      <td>8.716918</td>\n",
       "      <td>...</td>\n",
       "      <td>12.102056</td>\n",
       "      <td>8.105696</td>\n",
       "      <td>9.136500</td>\n",
       "      <td>7.730418</td>\n",
       "      <td>10.790484</td>\n",
       "      <td>7.599985</td>\n",
       "      <td>5.953310</td>\n",
       "      <td>7.229434</td>\n",
       "      <td>56.45</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.440667</td>\n",
       "      <td>5.592522</td>\n",
       "      <td>8.613192</td>\n",
       "      <td>5.436625</td>\n",
       "      <td>8.210389</td>\n",
       "      <td>6.203913</td>\n",
       "      <td>5.852012</td>\n",
       "      <td>6.219653</td>\n",
       "      <td>7.560101</td>\n",
       "      <td>9.600030</td>\n",
       "      <td>...</td>\n",
       "      <td>11.839824</td>\n",
       "      <td>8.376467</td>\n",
       "      <td>9.257898</td>\n",
       "      <td>7.743428</td>\n",
       "      <td>11.212880</td>\n",
       "      <td>7.770462</td>\n",
       "      <td>6.194253</td>\n",
       "      <td>7.289188</td>\n",
       "      <td>89.08</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.521038</td>\n",
       "      <td>5.325554</td>\n",
       "      <td>10.678267</td>\n",
       "      <td>5.623786</td>\n",
       "      <td>7.786509</td>\n",
       "      <td>6.153012</td>\n",
       "      <td>5.502281</td>\n",
       "      <td>7.278257</td>\n",
       "      <td>7.674681</td>\n",
       "      <td>10.367760</td>\n",
       "      <td>...</td>\n",
       "      <td>11.363913</td>\n",
       "      <td>9.031051</td>\n",
       "      <td>9.462490</td>\n",
       "      <td>7.472229</td>\n",
       "      <td>12.955410</td>\n",
       "      <td>8.591434</td>\n",
       "      <td>6.645760</td>\n",
       "      <td>8.737746</td>\n",
       "      <td>86.41</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1163</th>\n",
       "      <td>11.628490</td>\n",
       "      <td>5.570690</td>\n",
       "      <td>10.475695</td>\n",
       "      <td>6.032211</td>\n",
       "      <td>9.944405</td>\n",
       "      <td>5.865408</td>\n",
       "      <td>5.703147</td>\n",
       "      <td>6.649948</td>\n",
       "      <td>7.272166</td>\n",
       "      <td>9.750208</td>\n",
       "      <td>...</td>\n",
       "      <td>11.184906</td>\n",
       "      <td>7.907846</td>\n",
       "      <td>9.350417</td>\n",
       "      <td>6.902080</td>\n",
       "      <td>11.863881</td>\n",
       "      <td>8.171088</td>\n",
       "      <td>6.401429</td>\n",
       "      <td>7.814694</td>\n",
       "      <td>66.48</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <td>10.879891</td>\n",
       "      <td>6.431113</td>\n",
       "      <td>10.219154</td>\n",
       "      <td>5.435795</td>\n",
       "      <td>9.224122</td>\n",
       "      <td>5.699195</td>\n",
       "      <td>5.825643</td>\n",
       "      <td>6.404899</td>\n",
       "      <td>7.385644</td>\n",
       "      <td>9.271953</td>\n",
       "      <td>...</td>\n",
       "      <td>11.529199</td>\n",
       "      <td>8.334326</td>\n",
       "      <td>9.309069</td>\n",
       "      <td>7.048923</td>\n",
       "      <td>12.041769</td>\n",
       "      <td>8.572415</td>\n",
       "      <td>6.128115</td>\n",
       "      <td>7.682540</td>\n",
       "      <td>56.90</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165</th>\n",
       "      <td>9.591235</td>\n",
       "      <td>7.984515</td>\n",
       "      <td>9.935179</td>\n",
       "      <td>5.605596</td>\n",
       "      <td>9.799519</td>\n",
       "      <td>5.808704</td>\n",
       "      <td>5.905282</td>\n",
       "      <td>6.491419</td>\n",
       "      <td>7.865526</td>\n",
       "      <td>9.741103</td>\n",
       "      <td>...</td>\n",
       "      <td>12.011174</td>\n",
       "      <td>8.173189</td>\n",
       "      <td>9.294825</td>\n",
       "      <td>7.316246</td>\n",
       "      <td>12.540138</td>\n",
       "      <td>8.634905</td>\n",
       "      <td>6.089312</td>\n",
       "      <td>7.838041</td>\n",
       "      <td>43.10</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166</th>\n",
       "      <td>11.055114</td>\n",
       "      <td>8.282737</td>\n",
       "      <td>9.892589</td>\n",
       "      <td>5.753274</td>\n",
       "      <td>8.687667</td>\n",
       "      <td>5.475813</td>\n",
       "      <td>5.587906</td>\n",
       "      <td>6.830579</td>\n",
       "      <td>8.468221</td>\n",
       "      <td>9.482622</td>\n",
       "      <td>...</td>\n",
       "      <td>11.872388</td>\n",
       "      <td>8.245726</td>\n",
       "      <td>9.357164</td>\n",
       "      <td>7.354395</td>\n",
       "      <td>11.980115</td>\n",
       "      <td>8.250034</td>\n",
       "      <td>6.443083</td>\n",
       "      <td>8.319481</td>\n",
       "      <td>61.16</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1167</th>\n",
       "      <td>10.696475</td>\n",
       "      <td>5.533486</td>\n",
       "      <td>10.227787</td>\n",
       "      <td>5.588965</td>\n",
       "      <td>10.212643</td>\n",
       "      <td>6.633792</td>\n",
       "      <td>5.504219</td>\n",
       "      <td>6.468054</td>\n",
       "      <td>8.391464</td>\n",
       "      <td>9.812163</td>\n",
       "      <td>...</td>\n",
       "      <td>11.701313</td>\n",
       "      <td>8.618193</td>\n",
       "      <td>9.742585</td>\n",
       "      <td>7.435703</td>\n",
       "      <td>12.639017</td>\n",
       "      <td>7.710563</td>\n",
       "      <td>6.684053</td>\n",
       "      <td>7.930635</td>\n",
       "      <td>60.02</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1168 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ESR1       PGR      ERBB2     MKI67       PLAU    ELAVL1      EGFR  \\\n",
       "0     10.047059  7.505424   9.729606  5.451007   8.474830  6.412419  5.899440   \n",
       "1     10.404685  6.815637  10.334979  5.488309   9.994894  6.525927  5.585357   \n",
       "2     10.793832  7.720952   9.276507  5.478224   8.184773  5.949741  5.743395   \n",
       "3     10.440667  5.592522   8.613192  5.436625   8.210389  6.203913  5.852012   \n",
       "4     12.521038  5.325554  10.678267  5.623786   7.786509  6.153012  5.502281   \n",
       "...         ...       ...        ...       ...        ...       ...       ...   \n",
       "1163  11.628490  5.570690  10.475695  6.032211   9.944405  5.865408  5.703147   \n",
       "1164  10.879891  6.431113  10.219154  5.435795   9.224122  5.699195  5.825643   \n",
       "1165   9.591235  7.984515   9.935179  5.605596   9.799519  5.808704  5.905282   \n",
       "1166  11.055114  8.282737   9.892589  5.753274   8.687667  5.475813  5.587906   \n",
       "1167  10.696475  5.533486  10.227787  5.588965  10.212643  6.633792  5.504219   \n",
       "\n",
       "          BTRC     FBXO6      SHMT2  ...      YWHAQ     PDHA1     EWSR1  \\\n",
       "0     7.069394  7.100058   9.102318  ...  12.124106  8.234815  9.674483   \n",
       "1     6.071653  7.810600   9.431167  ...  12.712623  8.242056  9.154340   \n",
       "2     7.244882  7.781876   8.716918  ...  12.102056  8.105696  9.136500   \n",
       "3     6.219653  7.560101   9.600030  ...  11.839824  8.376467  9.257898   \n",
       "4     7.278257  7.674681  10.367760  ...  11.363913  9.031051  9.462490   \n",
       "...        ...       ...        ...  ...        ...       ...       ...   \n",
       "1163  6.649948  7.272166   9.750208  ...  11.184906  7.907846  9.350417   \n",
       "1164  6.404899  7.385644   9.271953  ...  11.529199  8.334326  9.309069   \n",
       "1165  6.491419  7.865526   9.741103  ...  12.011174  8.173189  9.294825   \n",
       "1166  6.830579  8.468221   9.482622  ...  11.872388  8.245726  9.357164   \n",
       "1167  6.468054  8.391464   9.812163  ...  11.701313  8.618193  9.742585   \n",
       "\n",
       "       ZDHHC17       ENO1      DBN1      PLK1     GSK3B    Age  Size  \n",
       "0     7.375406  12.024185  7.757081  6.455580  8.385158  43.19  10.0  \n",
       "1     7.585137  11.844377  8.042064  6.036497  7.464064  47.68  25.0  \n",
       "2     7.730418  10.790484  7.599985  5.953310  7.229434  56.45  10.0  \n",
       "3     7.743428  11.212880  7.770462  6.194253  7.289188  89.08  29.0  \n",
       "4     7.472229  12.955410  8.591434  6.645760  8.737746  86.41  16.0  \n",
       "...        ...        ...       ...       ...       ...    ...   ...  \n",
       "1163  6.902080  11.863881  8.171088  6.401429  7.814694  66.48  25.0  \n",
       "1164  7.048923  12.041769  8.572415  6.128115  7.682540  56.90  45.0  \n",
       "1165  7.316246  12.540138  8.634905  6.089312  7.838041  43.10  25.0  \n",
       "1166  7.354395  11.980115  8.250034  6.443083  8.319481  61.16  25.0  \n",
       "1167  7.435703  12.639017  7.710563  6.684053  7.930635  60.02  20.0  \n",
       "\n",
       "[1168 rows x 22 columns]"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabelled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1168, 22)\n",
      "(1164, 22)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ESR1</th>\n",
       "      <th>PGR</th>\n",
       "      <th>ERBB2</th>\n",
       "      <th>MKI67</th>\n",
       "      <th>PLAU</th>\n",
       "      <th>ELAVL1</th>\n",
       "      <th>EGFR</th>\n",
       "      <th>BTRC</th>\n",
       "      <th>FBXO6</th>\n",
       "      <th>SHMT2</th>\n",
       "      <th>...</th>\n",
       "      <th>YWHAQ</th>\n",
       "      <th>PDHA1</th>\n",
       "      <th>EWSR1</th>\n",
       "      <th>ZDHHC17</th>\n",
       "      <th>ENO1</th>\n",
       "      <th>DBN1</th>\n",
       "      <th>PLK1</th>\n",
       "      <th>GSK3B</th>\n",
       "      <th>Age</th>\n",
       "      <th>Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <td>10.879891</td>\n",
       "      <td>6.431113</td>\n",
       "      <td>10.219154</td>\n",
       "      <td>5.435795</td>\n",
       "      <td>9.224122</td>\n",
       "      <td>5.699195</td>\n",
       "      <td>5.825643</td>\n",
       "      <td>6.404899</td>\n",
       "      <td>7.385644</td>\n",
       "      <td>9.271953</td>\n",
       "      <td>...</td>\n",
       "      <td>11.529199</td>\n",
       "      <td>8.334326</td>\n",
       "      <td>9.309069</td>\n",
       "      <td>7.048923</td>\n",
       "      <td>12.041769</td>\n",
       "      <td>8.572415</td>\n",
       "      <td>6.128115</td>\n",
       "      <td>7.682540</td>\n",
       "      <td>56.90</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165</th>\n",
       "      <td>9.591235</td>\n",
       "      <td>7.984515</td>\n",
       "      <td>9.935179</td>\n",
       "      <td>5.605596</td>\n",
       "      <td>9.799519</td>\n",
       "      <td>5.808704</td>\n",
       "      <td>5.905282</td>\n",
       "      <td>6.491419</td>\n",
       "      <td>7.865526</td>\n",
       "      <td>9.741103</td>\n",
       "      <td>...</td>\n",
       "      <td>12.011174</td>\n",
       "      <td>8.173189</td>\n",
       "      <td>9.294825</td>\n",
       "      <td>7.316246</td>\n",
       "      <td>12.540138</td>\n",
       "      <td>8.634905</td>\n",
       "      <td>6.089312</td>\n",
       "      <td>7.838041</td>\n",
       "      <td>43.10</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166</th>\n",
       "      <td>11.055114</td>\n",
       "      <td>8.282737</td>\n",
       "      <td>9.892589</td>\n",
       "      <td>5.753274</td>\n",
       "      <td>8.687667</td>\n",
       "      <td>5.475813</td>\n",
       "      <td>5.587906</td>\n",
       "      <td>6.830579</td>\n",
       "      <td>8.468221</td>\n",
       "      <td>9.482622</td>\n",
       "      <td>...</td>\n",
       "      <td>11.872388</td>\n",
       "      <td>8.245726</td>\n",
       "      <td>9.357164</td>\n",
       "      <td>7.354395</td>\n",
       "      <td>11.980115</td>\n",
       "      <td>8.250034</td>\n",
       "      <td>6.443083</td>\n",
       "      <td>8.319481</td>\n",
       "      <td>61.16</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1167</th>\n",
       "      <td>10.696475</td>\n",
       "      <td>5.533486</td>\n",
       "      <td>10.227787</td>\n",
       "      <td>5.588965</td>\n",
       "      <td>10.212643</td>\n",
       "      <td>6.633792</td>\n",
       "      <td>5.504219</td>\n",
       "      <td>6.468054</td>\n",
       "      <td>8.391464</td>\n",
       "      <td>9.812163</td>\n",
       "      <td>...</td>\n",
       "      <td>11.701313</td>\n",
       "      <td>8.618193</td>\n",
       "      <td>9.742585</td>\n",
       "      <td>7.435703</td>\n",
       "      <td>12.639017</td>\n",
       "      <td>7.710563</td>\n",
       "      <td>6.684053</td>\n",
       "      <td>7.930635</td>\n",
       "      <td>60.02</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ESR1       PGR      ERBB2     MKI67       PLAU    ELAVL1      EGFR  \\\n",
       "1164  10.879891  6.431113  10.219154  5.435795   9.224122  5.699195  5.825643   \n",
       "1165   9.591235  7.984515   9.935179  5.605596   9.799519  5.808704  5.905282   \n",
       "1166  11.055114  8.282737   9.892589  5.753274   8.687667  5.475813  5.587906   \n",
       "1167  10.696475  5.533486  10.227787  5.588965  10.212643  6.633792  5.504219   \n",
       "\n",
       "          BTRC     FBXO6     SHMT2  ...      YWHAQ     PDHA1     EWSR1  \\\n",
       "1164  6.404899  7.385644  9.271953  ...  11.529199  8.334326  9.309069   \n",
       "1165  6.491419  7.865526  9.741103  ...  12.011174  8.173189  9.294825   \n",
       "1166  6.830579  8.468221  9.482622  ...  11.872388  8.245726  9.357164   \n",
       "1167  6.468054  8.391464  9.812163  ...  11.701313  8.618193  9.742585   \n",
       "\n",
       "       ZDHHC17       ENO1      DBN1      PLK1     GSK3B    Age  Size  \n",
       "1164  7.048923  12.041769  8.572415  6.128115  7.682540  56.90  45.0  \n",
       "1165  7.316246  12.540138  8.634905  6.089312  7.838041  43.10  25.0  \n",
       "1166  7.354395  11.980115  8.250034  6.443083  8.319481  61.16  25.0  \n",
       "1167  7.435703  12.639017  7.710563  6.684053  7.930635  60.02  20.0  \n",
       "\n",
       "[4 rows x 22 columns]"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(unlabelled_data.shape)\n",
    "\n",
    "threshold = 1164\n",
    "\n",
    "f_unlabelled_data = unlabelled_data.head(threshold)\n",
    "print(f_unlabelled_data.shape)\n",
    "\n",
    "# Something's wrong with this rows, it make the model crash\n",
    "unlabelled_data.tail(len(unlabelled_data) - threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_vime.set_second_phase()\n",
    "\n",
    "train_ds = VIMEDataset(\n",
    "    X_train,\n",
    "    y_train.values,\n",
    "    config,\n",
    "    unlabeled_data=f_unlabelled_data,\n",
    "    continuous_cols=numerical_cols,\n",
    "    category_cols=categorical_cols,\n",
    "    is_second_phase=True)\n",
    "\n",
    "valid_ds = VIMEDataset(\n",
    "    X_val,\n",
    "    y_val.values,\n",
    "    config,\n",
    "    continuous_cols=numerical_cols,\n",
    "    category_cols=categorical_cols,\n",
    "    is_second_phase=True)\n",
    "\n",
    "datamodule = TS3LDataModule(\n",
    "    train_ds,\n",
    "    valid_ds,\n",
    "    batch_size=batch_size,\n",
    "    train_sampler=\"weighted\",\n",
    "    train_collate_fn=VIMESecondPhaseCollateFN()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/sonk/envs/pandas/lib/python3.10/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "\n",
      "  | Name                        | Type             | Params | Mode \n",
      "-------------------------------------------------------------------------\n",
      "0 | task_loss_fn                | CrossEntropyLoss | 0      | train\n",
      "1 | mask_loss_fn                | BCELoss          | 0      | train\n",
      "2 | categorical_feature_loss_fn | CrossEntropyLoss | 0      | train\n",
      "3 | continuous_feature_loss_fn  | MSELoss          | 0      | train\n",
      "4 | consistency_loss_fn         | MSELoss          | 0      | train\n",
      "5 | model                       | VIME             | 1.2 M  | train\n",
      "-------------------------------------------------------------------------\n",
      "1.2 M     Trainable params\n",
      "19.7 K    Non-trainable params\n",
      "1.2 M     Total params\n",
      "4.837     Total estimated model params size (MB)\n",
      "23        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonk/envs/pandas/lib/python3.10/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/home/sonk/envs/pandas/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (12) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/12 [00:00<?, ?it/s, v_num=56, train_loss=1.810, train_accuracy_score=0.545, val_accuracy_score=0.591, val_loss=0.720]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonk/envs/pandas/lib/python3.10/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:   0%|          | 0/12 [00:00<?, ?it/s, v_num=56, train_loss=1.190, train_accuracy_score=0.591, val_accuracy_score=0.548, val_loss=0.680]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonk/envs/pandas/lib/python3.10/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:   0%|          | 0/12 [00:00<?, ?it/s, v_num=56, train_loss=1.110, train_accuracy_score=0.593, val_accuracy_score=0.559, val_loss=0.670]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonk/envs/pandas/lib/python3.10/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:   0%|          | 0/12 [00:00<?, ?it/s, v_num=56, train_loss=1.020, train_accuracy_score=0.570, val_accuracy_score=0.548, val_loss=0.719]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonk/envs/pandas/lib/python3.10/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:   0%|          | 0/12 [00:00<?, ?it/s, v_num=56, train_loss=0.954, train_accuracy_score=0.597, val_accuracy_score=0.559, val_loss=0.681]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonk/envs/pandas/lib/python3.10/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:   0%|          | 0/12 [00:00<?, ?it/s, v_num=56, train_loss=0.925, train_accuracy_score=0.569, val_accuracy_score=0.581, val_loss=0.671]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonk/envs/pandas/lib/python3.10/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:   0%|          | 0/12 [00:00<?, ?it/s, v_num=56, train_loss=0.857, train_accuracy_score=0.631, val_accuracy_score=0.624, val_loss=0.672]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonk/envs/pandas/lib/python3.10/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:   0%|          | 0/12 [00:00<?, ?it/s, v_num=56, train_loss=0.852, train_accuracy_score=0.618, val_accuracy_score=0.570, val_loss=0.725]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonk/envs/pandas/lib/python3.10/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:   0%|          | 0/12 [00:00<?, ?it/s, v_num=56, train_loss=0.852, train_accuracy_score=0.588, val_accuracy_score=0.634, val_loss=0.650]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonk/envs/pandas/lib/python3.10/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  92%|█████████▏| 12/13 [09:25<00:47,  0.02it/s, v_num=50, train_loss=nan.0, train_accuracy_score=0.624, val_accuracy_score=0.656, val_loss=0.623]\n",
      "Epoch 2:  92%|█████████▏| 12/13 [09:25<00:47,  0.02it/s, v_num=50, train_loss=nan.0, train_accuracy_score=0.624, val_accuracy_score=0.656, val_loss=0.623]\n",
      "Epoch 10:   0%|          | 0/12 [00:00<?, ?it/s, v_num=56, train_loss=0.846, train_accuracy_score=0.603, val_accuracy_score=0.591, val_loss=0.773]        "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonk/envs/pandas/lib/python3.10/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11:   0%|          | 0/12 [00:00<?, ?it/s, v_num=56, train_loss=0.897, train_accuracy_score=0.582, val_accuracy_score=0.581, val_loss=0.659]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonk/envs/pandas/lib/python3.10/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12:   0%|          | 0/12 [00:00<?, ?it/s, v_num=56, train_loss=0.919, train_accuracy_score=0.538, val_accuracy_score=0.613, val_loss=0.653]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonk/envs/pandas/lib/python3.10/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13:   0%|          | 0/12 [00:00<?, ?it/s, v_num=56, train_loss=0.840, train_accuracy_score=0.633, val_accuracy_score=0.645, val_loss=0.658]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonk/envs/pandas/lib/python3.10/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14:   0%|          | 0/12 [00:00<?, ?it/s, v_num=56, train_loss=0.813, train_accuracy_score=0.619, val_accuracy_score=0.667, val_loss=0.640]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonk/envs/pandas/lib/python3.10/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15:   0%|          | 0/12 [00:00<?, ?it/s, v_num=56, train_loss=0.820, train_accuracy_score=0.634, val_accuracy_score=0.624, val_loss=0.638]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonk/envs/pandas/lib/python3.10/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16:   0%|          | 0/12 [00:00<?, ?it/s, v_num=56, train_loss=0.812, train_accuracy_score=0.639, val_accuracy_score=0.570, val_loss=0.706]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonk/envs/pandas/lib/python3.10/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17:   0%|          | 0/12 [00:00<?, ?it/s, v_num=56, train_loss=0.818, train_accuracy_score=0.602, val_accuracy_score=0.656, val_loss=0.654]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonk/envs/pandas/lib/python3.10/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18:   0%|          | 0/12 [00:00<?, ?it/s, v_num=56, train_loss=0.931, train_accuracy_score=0.577, val_accuracy_score=0.473, val_loss=1.050]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonk/envs/pandas/lib/python3.10/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19:   0%|          | 0/12 [00:00<?, ?it/s, v_num=56, train_loss=0.910, train_accuracy_score=0.568, val_accuracy_score=0.613, val_loss=0.632]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonk/envs/pandas/lib/python3.10/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 12/12 [00:02<00:00,  5.63it/s, v_num=56, train_loss=0.812, train_accuracy_score=0.601, val_accuracy_score=0.656, val_loss=0.654]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 12/12 [00:02<00:00,  5.30it/s, v_num=56, train_loss=0.812, train_accuracy_score=0.601, val_accuracy_score=0.656, val_loss=0.654]\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "        accelerator = 'cpu',\n",
    "        max_epochs = max_epochs,\n",
    "        num_sanity_val_steps = 2,\n",
    "    )\n",
    "\n",
    "trainer.fit(pl_vime, datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = VIMEDataset(\n",
    "    X_test,\n",
    "    category_cols=categorical_cols,\n",
    "    continuous_cols=numerical_cols,\n",
    "    is_second_phase=True)\n",
    "\n",
    "test_dl = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size,\n",
    "    shuffle=False,\n",
    "    sampler=SequentialSampler(test_ds)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonk/envs/pandas/lib/python3.10/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/home/sonk/envs/pandas/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 214.24it/s]\n",
      "Accuracy 0.70\n"
     ]
    }
   ],
   "source": [
    "preds = trainer.predict(pl_vime, test_dl)\n",
    "preds = F.softmax(torch.concat([out.cpu() for out in preds]).squeeze(),dim=1)\n",
    "\n",
    "accuracy = accuracy_score(y_test, preds.argmax(1))\n",
    "\n",
    "print(\"Accuracy %.2f\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.525858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.517442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.632501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.955566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.534167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0</td>\n",
       "      <td>0.703786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>1</td>\n",
       "      <td>0.510575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0</td>\n",
       "      <td>0.559650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0</td>\n",
       "      <td>0.551885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>1</td>\n",
       "      <td>0.614850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label  probability\n",
       "0        1     0.525858\n",
       "1        0     0.517442\n",
       "2        1     0.632501\n",
       "3        0     0.955566\n",
       "4        1     0.534167\n",
       "..     ...          ...\n",
       "112      0     0.703786\n",
       "113      1     0.510575\n",
       "114      0     0.559650\n",
       "115      0     0.551885\n",
       "116      1     0.614850\n",
       "\n",
       "[117 rows x 2 columns]"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels = preds.argmax(1)\n",
    "associated_probabilities = preds[np.arange(preds.shape[0]), predicted_labels]\n",
    "pd.DataFrame({'label': predicted_labels, 'probability': associated_probabilities})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabelled_ds = VIMEDataset(\n",
    "    X=unlabelled_data,\n",
    "    config=config,\n",
    "    continuous_cols=numerical_cols,\n",
    "    category_cols=categorical_cols)\n",
    "\n",
    "unlabelled_dl = DataLoader(\n",
    "    unlabelled_ds,\n",
    "    batch_size,\n",
    "    shuffle=False,\n",
    "    sampler=SequentialSampler(unlabelled_ds)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonk/envs/pandas/lib/python3.10/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/home/sonk/envs/pandas/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 10/10 [00:00<00:00, 56.90it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.659109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.590492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.739665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.682598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.541471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1163</th>\n",
       "      <td>0</td>\n",
       "      <td>0.546133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <td>1</td>\n",
       "      <td>0.544064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165</th>\n",
       "      <td>0</td>\n",
       "      <td>0.557837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166</th>\n",
       "      <td>0</td>\n",
       "      <td>0.583897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1167</th>\n",
       "      <td>0</td>\n",
       "      <td>0.656588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1168 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label  confidence\n",
       "0         0    0.659109\n",
       "1         0    0.590492\n",
       "2         0    0.739665\n",
       "3         1    0.682598\n",
       "4         0    0.541471\n",
       "...     ...         ...\n",
       "1163      0    0.546133\n",
       "1164      1    0.544064\n",
       "1165      0    0.557837\n",
       "1166      0    0.583897\n",
       "1167      0    0.656588\n",
       "\n",
       "[1168 rows x 2 columns]"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = trainer.predict(pl_vime, unlabelled_dl)\n",
    "preds = F.softmax(torch.concat([out.cpu() for out in preds]).squeeze(),dim=1)\n",
    "\n",
    "predicted_labels = preds.argmax(1)\n",
    "associated_probabilities = preds[np.arange(preds.shape[0]), predicted_labels]\n",
    "\n",
    "pd.DataFrame({'label': predicted_labels, 'confidence': associated_probabilities})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ESR1</th>\n",
       "      <th>PGR</th>\n",
       "      <th>ERBB2</th>\n",
       "      <th>MKI67</th>\n",
       "      <th>PLAU</th>\n",
       "      <th>ELAVL1</th>\n",
       "      <th>EGFR</th>\n",
       "      <th>BTRC</th>\n",
       "      <th>FBXO6</th>\n",
       "      <th>SHMT2</th>\n",
       "      <th>...</th>\n",
       "      <th>EWSR1</th>\n",
       "      <th>ZDHHC17</th>\n",
       "      <th>ENO1</th>\n",
       "      <th>DBN1</th>\n",
       "      <th>PLK1</th>\n",
       "      <th>GSK3B</th>\n",
       "      <th>Age</th>\n",
       "      <th>Size</th>\n",
       "      <th>Label</th>\n",
       "      <th>Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.047059</td>\n",
       "      <td>7.505424</td>\n",
       "      <td>9.729606</td>\n",
       "      <td>5.451007</td>\n",
       "      <td>8.474830</td>\n",
       "      <td>6.412419</td>\n",
       "      <td>5.899440</td>\n",
       "      <td>7.069394</td>\n",
       "      <td>7.100058</td>\n",
       "      <td>9.102318</td>\n",
       "      <td>...</td>\n",
       "      <td>9.674483</td>\n",
       "      <td>7.375406</td>\n",
       "      <td>12.024185</td>\n",
       "      <td>7.757081</td>\n",
       "      <td>6.455580</td>\n",
       "      <td>8.385158</td>\n",
       "      <td>43.19</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.659109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.404685</td>\n",
       "      <td>6.815637</td>\n",
       "      <td>10.334979</td>\n",
       "      <td>5.488309</td>\n",
       "      <td>9.994894</td>\n",
       "      <td>6.525927</td>\n",
       "      <td>5.585357</td>\n",
       "      <td>6.071653</td>\n",
       "      <td>7.810600</td>\n",
       "      <td>9.431167</td>\n",
       "      <td>...</td>\n",
       "      <td>9.154340</td>\n",
       "      <td>7.585137</td>\n",
       "      <td>11.844377</td>\n",
       "      <td>8.042064</td>\n",
       "      <td>6.036497</td>\n",
       "      <td>7.464064</td>\n",
       "      <td>47.68</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.590492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.793832</td>\n",
       "      <td>7.720952</td>\n",
       "      <td>9.276507</td>\n",
       "      <td>5.478224</td>\n",
       "      <td>8.184773</td>\n",
       "      <td>5.949741</td>\n",
       "      <td>5.743395</td>\n",
       "      <td>7.244882</td>\n",
       "      <td>7.781876</td>\n",
       "      <td>8.716918</td>\n",
       "      <td>...</td>\n",
       "      <td>9.136500</td>\n",
       "      <td>7.730418</td>\n",
       "      <td>10.790484</td>\n",
       "      <td>7.599985</td>\n",
       "      <td>5.953310</td>\n",
       "      <td>7.229434</td>\n",
       "      <td>56.45</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.739665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.440667</td>\n",
       "      <td>5.592522</td>\n",
       "      <td>8.613192</td>\n",
       "      <td>5.436625</td>\n",
       "      <td>8.210389</td>\n",
       "      <td>6.203913</td>\n",
       "      <td>5.852012</td>\n",
       "      <td>6.219653</td>\n",
       "      <td>7.560101</td>\n",
       "      <td>9.600030</td>\n",
       "      <td>...</td>\n",
       "      <td>9.257898</td>\n",
       "      <td>7.743428</td>\n",
       "      <td>11.212880</td>\n",
       "      <td>7.770462</td>\n",
       "      <td>6.194253</td>\n",
       "      <td>7.289188</td>\n",
       "      <td>89.08</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.682598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.521038</td>\n",
       "      <td>5.325554</td>\n",
       "      <td>10.678267</td>\n",
       "      <td>5.623786</td>\n",
       "      <td>7.786509</td>\n",
       "      <td>6.153012</td>\n",
       "      <td>5.502281</td>\n",
       "      <td>7.278257</td>\n",
       "      <td>7.674681</td>\n",
       "      <td>10.367760</td>\n",
       "      <td>...</td>\n",
       "      <td>9.462490</td>\n",
       "      <td>7.472229</td>\n",
       "      <td>12.955410</td>\n",
       "      <td>8.591434</td>\n",
       "      <td>6.645760</td>\n",
       "      <td>8.737746</td>\n",
       "      <td>86.41</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.541471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1163</th>\n",
       "      <td>11.628490</td>\n",
       "      <td>5.570690</td>\n",
       "      <td>10.475695</td>\n",
       "      <td>6.032211</td>\n",
       "      <td>9.944405</td>\n",
       "      <td>5.865408</td>\n",
       "      <td>5.703147</td>\n",
       "      <td>6.649948</td>\n",
       "      <td>7.272166</td>\n",
       "      <td>9.750208</td>\n",
       "      <td>...</td>\n",
       "      <td>9.350417</td>\n",
       "      <td>6.902080</td>\n",
       "      <td>11.863881</td>\n",
       "      <td>8.171088</td>\n",
       "      <td>6.401429</td>\n",
       "      <td>7.814694</td>\n",
       "      <td>66.48</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.546133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <td>10.879891</td>\n",
       "      <td>6.431113</td>\n",
       "      <td>10.219154</td>\n",
       "      <td>5.435795</td>\n",
       "      <td>9.224122</td>\n",
       "      <td>5.699195</td>\n",
       "      <td>5.825643</td>\n",
       "      <td>6.404899</td>\n",
       "      <td>7.385644</td>\n",
       "      <td>9.271953</td>\n",
       "      <td>...</td>\n",
       "      <td>9.309069</td>\n",
       "      <td>7.048923</td>\n",
       "      <td>12.041769</td>\n",
       "      <td>8.572415</td>\n",
       "      <td>6.128115</td>\n",
       "      <td>7.682540</td>\n",
       "      <td>56.90</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.544064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165</th>\n",
       "      <td>9.591235</td>\n",
       "      <td>7.984515</td>\n",
       "      <td>9.935179</td>\n",
       "      <td>5.605596</td>\n",
       "      <td>9.799519</td>\n",
       "      <td>5.808704</td>\n",
       "      <td>5.905282</td>\n",
       "      <td>6.491419</td>\n",
       "      <td>7.865526</td>\n",
       "      <td>9.741103</td>\n",
       "      <td>...</td>\n",
       "      <td>9.294825</td>\n",
       "      <td>7.316246</td>\n",
       "      <td>12.540138</td>\n",
       "      <td>8.634905</td>\n",
       "      <td>6.089312</td>\n",
       "      <td>7.838041</td>\n",
       "      <td>43.10</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.557837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166</th>\n",
       "      <td>11.055114</td>\n",
       "      <td>8.282737</td>\n",
       "      <td>9.892589</td>\n",
       "      <td>5.753274</td>\n",
       "      <td>8.687667</td>\n",
       "      <td>5.475813</td>\n",
       "      <td>5.587906</td>\n",
       "      <td>6.830579</td>\n",
       "      <td>8.468221</td>\n",
       "      <td>9.482622</td>\n",
       "      <td>...</td>\n",
       "      <td>9.357164</td>\n",
       "      <td>7.354395</td>\n",
       "      <td>11.980115</td>\n",
       "      <td>8.250034</td>\n",
       "      <td>6.443083</td>\n",
       "      <td>8.319481</td>\n",
       "      <td>61.16</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.583897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1167</th>\n",
       "      <td>10.696475</td>\n",
       "      <td>5.533486</td>\n",
       "      <td>10.227787</td>\n",
       "      <td>5.588965</td>\n",
       "      <td>10.212643</td>\n",
       "      <td>6.633792</td>\n",
       "      <td>5.504219</td>\n",
       "      <td>6.468054</td>\n",
       "      <td>8.391464</td>\n",
       "      <td>9.812163</td>\n",
       "      <td>...</td>\n",
       "      <td>9.742585</td>\n",
       "      <td>7.435703</td>\n",
       "      <td>12.639017</td>\n",
       "      <td>7.710563</td>\n",
       "      <td>6.684053</td>\n",
       "      <td>7.930635</td>\n",
       "      <td>60.02</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.656588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1168 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ESR1       PGR      ERBB2     MKI67       PLAU    ELAVL1      EGFR  \\\n",
       "0     10.047059  7.505424   9.729606  5.451007   8.474830  6.412419  5.899440   \n",
       "1     10.404685  6.815637  10.334979  5.488309   9.994894  6.525927  5.585357   \n",
       "2     10.793832  7.720952   9.276507  5.478224   8.184773  5.949741  5.743395   \n",
       "3     10.440667  5.592522   8.613192  5.436625   8.210389  6.203913  5.852012   \n",
       "4     12.521038  5.325554  10.678267  5.623786   7.786509  6.153012  5.502281   \n",
       "...         ...       ...        ...       ...        ...       ...       ...   \n",
       "1163  11.628490  5.570690  10.475695  6.032211   9.944405  5.865408  5.703147   \n",
       "1164  10.879891  6.431113  10.219154  5.435795   9.224122  5.699195  5.825643   \n",
       "1165   9.591235  7.984515   9.935179  5.605596   9.799519  5.808704  5.905282   \n",
       "1166  11.055114  8.282737   9.892589  5.753274   8.687667  5.475813  5.587906   \n",
       "1167  10.696475  5.533486  10.227787  5.588965  10.212643  6.633792  5.504219   \n",
       "\n",
       "          BTRC     FBXO6      SHMT2  ...     EWSR1   ZDHHC17       ENO1  \\\n",
       "0     7.069394  7.100058   9.102318  ...  9.674483  7.375406  12.024185   \n",
       "1     6.071653  7.810600   9.431167  ...  9.154340  7.585137  11.844377   \n",
       "2     7.244882  7.781876   8.716918  ...  9.136500  7.730418  10.790484   \n",
       "3     6.219653  7.560101   9.600030  ...  9.257898  7.743428  11.212880   \n",
       "4     7.278257  7.674681  10.367760  ...  9.462490  7.472229  12.955410   \n",
       "...        ...       ...        ...  ...       ...       ...        ...   \n",
       "1163  6.649948  7.272166   9.750208  ...  9.350417  6.902080  11.863881   \n",
       "1164  6.404899  7.385644   9.271953  ...  9.309069  7.048923  12.041769   \n",
       "1165  6.491419  7.865526   9.741103  ...  9.294825  7.316246  12.540138   \n",
       "1166  6.830579  8.468221   9.482622  ...  9.357164  7.354395  11.980115   \n",
       "1167  6.468054  8.391464   9.812163  ...  9.742585  7.435703  12.639017   \n",
       "\n",
       "          DBN1      PLK1     GSK3B    Age  Size  Label  Confidence  \n",
       "0     7.757081  6.455580  8.385158  43.19  10.0      0    0.659109  \n",
       "1     8.042064  6.036497  7.464064  47.68  25.0      0    0.590492  \n",
       "2     7.599985  5.953310  7.229434  56.45  10.0      0    0.739665  \n",
       "3     7.770462  6.194253  7.289188  89.08  29.0      1    0.682598  \n",
       "4     8.591434  6.645760  8.737746  86.41  16.0      0    0.541471  \n",
       "...        ...       ...       ...    ...   ...    ...         ...  \n",
       "1163  8.171088  6.401429  7.814694  66.48  25.0      0    0.546133  \n",
       "1164  8.572415  6.128115  7.682540  56.90  45.0      1    0.544064  \n",
       "1165  8.634905  6.089312  7.838041  43.10  25.0      0    0.557837  \n",
       "1166  8.250034  6.443083  8.319481  61.16  25.0      0    0.583897  \n",
       "1167  7.710563  6.684053  7.930635  60.02  20.0      0    0.656588  \n",
       "\n",
       "[1168 rows x 24 columns]"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabelled_data['Label'] = predicted_labels\n",
    "unlabelled_data['Confidence'] = associated_probabilities\n",
    "\n",
    "unlabelled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabelled_data.to_csv(PSEUDO_LABELLED_DATA_PATH, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pandas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
